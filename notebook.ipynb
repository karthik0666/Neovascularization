{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMjtGXm3oN2T",
    "outputId": "7dabaa67-2473-4af1-f0b4-136151d52814"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3596\\1255118365.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplitfolders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import splitfolders\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPpge-4KoQOo",
    "outputId": "93081415-c40b-4c0e-9302-7b099dc82779"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2176\\667122329.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'p100'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "x=!nvidia-smi\n",
    "count=0\n",
    "for i in x:\n",
    "    if \"============\" in i:\n",
    "        count+=1\n",
    "        break\n",
    "    count+=1\n",
    "if 'p100' in x[count].lower():\n",
    "    print(\"found\")\n",
    "else:\n",
    "    print(x[count])\n",
    "    time.sleep(1)\n",
    "    #os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "   \n",
    "\n",
    "    \n",
    "    data_path = 'Data/'\n",
    "    \n",
    "    path_train = \"./output/train\"\n",
    "    path_test = \"./output/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splitfolders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2176\\2934860330.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msplitfolders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"output\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'splitfolders' is not defined"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio(config.data_path, output=\"output\", seed=101, ratio=(.9, .1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UOO0MaJhoT9P"
   },
   "outputs": [],
   "source": [
    "# Resizinig all the images to (224,224)\n",
    "IMAGE_SIZE = [224,224]\n",
    "\n",
    "train_path = 'output/train'\n",
    "test_path = 'output/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scaling & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f5tJZB8ooZf8"
   },
   "outputs": [],
   "source": [
    "# Scaling all the images between 0 to 1\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=False)\n",
    "\n",
    "# Performing only scaling on the test dataset\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYsJkFJpoalf",
    "outputId": "52e5706b-5d9b-4bcf-8c26-972367fcacd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3294 images belonging to 5 classes.\n",
      "Found 368 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory(train_path,\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size=(224,224),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception ResNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJ4ZpcxPdBHx",
    "outputId": "5ae08b71-5d17-4742-9394-8f7be554e6a3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "inc=InceptionResNetV2(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KJQPRGVGddn-"
   },
   "outputs": [],
   "source": [
    "x31 = Flatten()(inc.output)\n",
    "predictionss = Dense(5, activation='softmax')(x31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47SqEuaydeHL",
    "outputId": "bbf56840-9305-41b0-f2c3-92a42453f519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 96)   18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 64)   12288       average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 96)   288         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 64)   192         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 96)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed_5b (Concatenate)          (None, 25, 25, 320)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 32)   96          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 32)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 48)   13824       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 32)   96          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 48)   144         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 32)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   10240       mixed_5b[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 32)   9216        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 64)   27648       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 32)   96          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 32)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_1 (Lambda)              (None, 25, 25, 320)  0           mixed_5b[0][0]                   \n",
      "                                                                 block35_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_1_ac (Activation)       (None, 25, 25, 320)  0           block35_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 32)   96          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 48)   13824       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 32)   96          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 48)   144         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 32)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 32)   10240       block35_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 32)   9216        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   27648       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 32)   96          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 32)   96          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 32)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 32)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_18[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_2 (Lambda)              (None, 25, 25, 320)  0           block35_1_ac[0][0]               \n",
      "                                                                 block35_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_2_ac (Activation)       (None, 25, 25, 320)  0           block35_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 32)   96          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 32)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 48)   13824       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 32)   96          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 48)   144         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 32)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 48)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 32)   10240       block35_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 32)   9216        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 64)   27648       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 32)   96          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 32)   96          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 64)   192         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 32)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_24[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_3 (Lambda)              (None, 25, 25, 320)  0           block35_2_ac[0][0]               \n",
      "                                                                 block35_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_3_ac (Activation)       (None, 25, 25, 320)  0           block35_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 25, 25, 32)   96          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 25, 25, 32)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 25, 25, 48)   13824       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 25, 25, 32)   96          conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 25, 25, 48)   144         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 25, 25, 32)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 25, 25, 48)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 25, 25, 32)   10240       block35_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 25, 25, 32)   9216        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 25, 25, 64)   27648       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 25, 25, 32)   96          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 25, 25, 32)   96          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 25, 25, 64)   192         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 25, 25, 32)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 25, 25, 32)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 25, 25, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_30[0][0]              \n",
      "                                                                 activation_32[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_4 (Lambda)              (None, 25, 25, 320)  0           block35_3_ac[0][0]               \n",
      "                                                                 block35_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_4_ac (Activation)       (None, 25, 25, 320)  0           block35_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 25, 25, 32)   96          conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 25, 25, 32)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 25, 25, 48)   13824       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 25, 25, 32)   96          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 25, 25, 48)   144         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 25, 25, 32)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 25, 25, 48)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 25, 25, 32)   10240       block35_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 25, 25, 32)   9216        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 25, 25, 64)   27648       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 25, 25, 32)   96          conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 25, 25, 32)   96          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 25, 25, 64)   192         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 25, 25, 32)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 25, 25, 32)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 25, 25, 64)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_36[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_5 (Lambda)              (None, 25, 25, 320)  0           block35_4_ac[0][0]               \n",
      "                                                                 block35_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_5_ac (Activation)       (None, 25, 25, 320)  0           block35_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 25, 25, 32)   96          conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 25, 25, 32)   0           batch_normalization_45[0][0]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 25, 25, 48)   13824       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 25, 25, 32)   96          conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 25, 25, 48)   144         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 25, 25, 32)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 25, 25, 48)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 25, 25, 32)   10240       block35_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 25, 25, 32)   9216        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 25, 25, 64)   27648       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 25, 25, 32)   96          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 25, 25, 32)   96          conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 25, 25, 64)   192         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 25, 25, 32)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 25, 25, 32)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 25, 25, 64)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_42[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_6 (Lambda)              (None, 25, 25, 320)  0           block35_5_ac[0][0]               \n",
      "                                                                 block35_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_6_ac (Activation)       (None, 25, 25, 320)  0           block35_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 25, 25, 32)   96          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 25, 25, 32)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 25, 25, 48)   13824       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 25, 25, 32)   96          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 25, 25, 48)   144         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 25, 25, 32)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 25, 25, 48)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 25, 25, 32)   10240       block35_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 25, 25, 32)   9216        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 25, 25, 64)   27648       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 25, 25, 32)   96          conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 25, 25, 32)   96          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 25, 25, 64)   192         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 25, 25, 32)   0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 25, 25, 32)   0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 25, 25, 64)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_48[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_7_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_7 (Lambda)              (None, 25, 25, 320)  0           block35_6_ac[0][0]               \n",
      "                                                                 block35_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_7_ac (Activation)       (None, 25, 25, 320)  0           block35_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 25, 25, 32)   96          conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 25, 25, 32)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 25, 25, 48)   13824       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 25, 25, 32)   96          conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 25, 25, 48)   144         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 25, 25, 32)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 25, 25, 48)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 25, 25, 32)   10240       block35_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 25, 25, 32)   9216        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 25, 25, 64)   27648       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 25, 25, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 25, 25, 32)   96          conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 25, 25, 64)   192         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 25, 25, 32)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 25, 25, 32)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 25, 25, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_54[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_8 (Lambda)              (None, 25, 25, 320)  0           block35_7_ac[0][0]               \n",
      "                                                                 block35_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_8_ac (Activation)       (None, 25, 25, 320)  0           block35_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 25, 25, 32)   96          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 25, 25, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 25, 25, 48)   13824       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 25, 25, 32)   96          conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 25, 25, 48)   144         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 25, 25, 32)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 25, 25, 48)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 25, 25, 32)   10240       block35_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 25, 25, 32)   9216        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 25, 25, 64)   27648       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 25, 25, 32)   96          conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 25, 25, 32)   96          conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_65 (BatchNo (None, 25, 25, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 25, 25, 32)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 25, 25, 32)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 25, 25, 64)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_mixed (Concatenate)   (None, 25, 25, 128)  0           activation_60[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_conv (Conv2D)         (None, 25, 25, 320)  41280       block35_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_9 (Lambda)              (None, 25, 25, 320)  0           block35_8_ac[0][0]               \n",
      "                                                                 block35_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block35_9_ac (Activation)       (None, 25, 25, 320)  0           block35_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 25, 25, 32)   96          conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 25, 25, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 25, 25, 48)   13824       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 25, 25, 32)   96          conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 25, 25, 48)   144         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 25, 25, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 25, 25, 48)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 25, 25, 32)   10240       block35_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 25, 25, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 25, 25, 64)   27648       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 25, 25, 32)   96          conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 25, 25, 32)   96          conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 25, 25, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 25, 25, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 25, 25, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 25, 25, 64)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_mixed (Concatenate)  (None, 25, 25, 128)  0           activation_66[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_conv (Conv2D)        (None, 25, 25, 320)  41280       block35_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block35_10 (Lambda)             (None, 25, 25, 320)  0           block35_9_ac[0][0]               \n",
      "                                                                 block35_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block35_10_ac (Activation)      (None, 25, 25, 320)  0           block35_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 25, 25, 256)  81920       block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 25, 25, 256)  768         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 25, 25, 256)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 25, 25, 256)  589824      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 25, 25, 256)  768         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 25, 25, 256)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 384)  1105920     block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 384)  884736      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 384)  1152        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 384)  1152        conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 384)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 384)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 320)  0           block35_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mixed_6a (Concatenate)          (None, 12, 12, 1088) 0           activation_72[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 12, 12, 128)  139264      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 12, 12, 128)  384         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 12, 12, 128)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 12, 12, 160)  143360      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 12, 12, 160)  480         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 12, 12, 160)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 12, 12, 192)  208896      mixed_6a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 12, 12, 192)  215040      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 12, 12, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 12, 12, 192)  576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 12, 12, 192)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 12, 12, 192)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_76[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_1_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_1 (Lambda)              (None, 12, 12, 1088) 0           mixed_6a[0][0]                   \n",
      "                                                                 block17_1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_1_ac (Activation)       (None, 12, 12, 1088) 0           block17_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 12, 12, 128)  139264      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 12, 12, 128)  384         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 12, 12, 128)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 12, 12, 160)  143360      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 12, 12, 160)  480         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 12, 12, 160)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 12, 12, 192)  208896      block17_1_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 12, 12, 192)  215040      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 12, 12, 192)  576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 12, 12, 192)  576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 12, 12, 192)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 12, 12, 192)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_80[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_2_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_2 (Lambda)              (None, 12, 12, 1088) 0           block17_1_ac[0][0]               \n",
      "                                                                 block17_2_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_2_ac (Activation)       (None, 12, 12, 1088) 0           block17_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_85 (Conv2D)              (None, 12, 12, 128)  139264      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 12, 12, 128)  384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 12, 12, 128)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 12, 12, 160)  143360      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 12, 12, 160)  480         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 12, 12, 160)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 12, 12, 192)  208896      block17_2_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 12, 12, 192)  215040      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 12, 12, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 12, 12, 192)  576         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 12, 12, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 12, 12, 192)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_84[0][0]              \n",
      "                                                                 activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_3_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_3 (Lambda)              (None, 12, 12, 1088) 0           block17_2_ac[0][0]               \n",
      "                                                                 block17_3_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_3_ac (Activation)       (None, 12, 12, 1088) 0           block17_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 12, 12, 128)  139264      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 12, 12, 128)  384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 12, 12, 128)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 12, 12, 160)  143360      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 12, 12, 160)  480         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 12, 12, 160)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 12, 12, 192)  208896      block17_3_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 12, 12, 192)  215040      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 12, 12, 192)  576         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 12, 12, 192)  576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 12, 12, 192)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 12, 12, 192)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_88[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_4_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_4 (Lambda)              (None, 12, 12, 1088) 0           block17_3_ac[0][0]               \n",
      "                                                                 block17_4_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_4_ac (Activation)       (None, 12, 12, 1088) 0           block17_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 12, 12, 128)  139264      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 12, 12, 128)  384         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 12, 12, 128)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 12, 12, 160)  143360      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 12, 12, 160)  480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 12, 12, 160)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 12, 12, 192)  208896      block17_4_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 12, 12, 192)  215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 12, 12, 192)  576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 12, 12, 192)  576         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 12, 12, 192)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 12, 12, 192)  0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_5_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_5 (Lambda)              (None, 12, 12, 1088) 0           block17_4_ac[0][0]               \n",
      "                                                                 block17_5_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_5_ac (Activation)       (None, 12, 12, 1088) 0           block17_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 12, 12, 128)  139264      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 12, 12, 128)  384         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 12, 12, 128)  0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 12, 12, 160)  143360      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 12, 12, 160)  480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 12, 12, 160)  0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 12, 12, 192)  208896      block17_5_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 12, 12, 192)  215040      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 12, 12, 192)  576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 12, 12, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 12, 12, 192)  0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 12, 12, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_96[0][0]              \n",
      "                                                                 activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_6_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_6 (Lambda)              (None, 12, 12, 1088) 0           block17_5_ac[0][0]               \n",
      "                                                                 block17_6_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_6_ac (Activation)       (None, 12, 12, 1088) 0           block17_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 12, 12, 128)  139264      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 12, 12, 128)  384         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 12, 12, 128)  0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 12, 12, 160)  143360      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 12, 12, 160)  480         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 12, 12, 160)  0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 12, 12, 192)  208896      block17_6_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 12, 12, 192)  215040      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 12, 12, 192)  576         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 12, 12, 192)  576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 12, 12, 192)  0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 12, 12, 192)  0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_100[0][0]             \n",
      "                                                                 activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_7_mixed[0][0]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block17_7 (Lambda)              (None, 12, 12, 1088) 0           block17_6_ac[0][0]               \n",
      "                                                                 block17_7_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_7_ac (Activation)       (None, 12, 12, 1088) 0           block17_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 12, 12, 128)  139264      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 12, 12, 128)  384         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 12, 12, 128)  0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 12, 12, 160)  143360      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 12, 12, 160)  480         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 12, 12, 160)  0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 12, 12, 192)  208896      block17_7_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 12, 12, 192)  215040      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 12, 12, 192)  576         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 12, 12, 192)  576         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 12, 12, 192)  0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 12, 12, 192)  0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_104[0][0]             \n",
      "                                                                 activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_8_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_8 (Lambda)              (None, 12, 12, 1088) 0           block17_7_ac[0][0]               \n",
      "                                                                 block17_8_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_8_ac (Activation)       (None, 12, 12, 1088) 0           block17_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 12, 12, 128)  139264      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 12, 12, 128)  384         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 12, 12, 128)  0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 12, 12, 160)  143360      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 12, 12, 160)  480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 12, 12, 160)  0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 12, 12, 192)  208896      block17_8_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 12, 12, 192)  215040      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 12, 12, 192)  576         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 12, 12, 192)  576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 12, 12, 192)  0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 12, 12, 192)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_mixed (Concatenate)   (None, 12, 12, 384)  0           activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_conv (Conv2D)         (None, 12, 12, 1088) 418880      block17_9_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_9 (Lambda)              (None, 12, 12, 1088) 0           block17_8_ac[0][0]               \n",
      "                                                                 block17_9_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_9_ac (Activation)       (None, 12, 12, 1088) 0           block17_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 12, 12, 128)  139264      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 12, 12, 128)  384         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 12, 12, 128)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 12, 12, 160)  143360      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 12, 12, 160)  480         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 12, 12, 160)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 12, 12, 192)  208896      block17_9_ac[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 12, 12, 192)  215040      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 12, 12, 192)  576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 12, 12, 192)  576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 12, 12, 192)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 12, 12, 192)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_10_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_10 (Lambda)             (None, 12, 12, 1088) 0           block17_9_ac[0][0]               \n",
      "                                                                 block17_10_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_10_ac (Activation)      (None, 12, 12, 1088) 0           block17_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 12, 12, 128)  139264      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 12, 12, 128)  384         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 12, 12, 128)  0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 12, 12, 160)  143360      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 12, 12, 160)  480         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 12, 12, 160)  0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 12, 12, 192)  208896      block17_10_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 12, 12, 192)  215040      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 12, 12, 192)  576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 12, 12, 192)  576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 12, 12, 192)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 12, 12, 192)  0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_11_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_11 (Lambda)             (None, 12, 12, 1088) 0           block17_10_ac[0][0]              \n",
      "                                                                 block17_11_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_11_ac (Activation)      (None, 12, 12, 1088) 0           block17_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 12, 12, 128)  139264      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 12, 12, 128)  384         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 12, 12, 128)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 12, 12, 160)  143360      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 12, 12, 160)  480         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 12, 12, 160)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 12, 12, 192)  208896      block17_11_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 12, 12, 192)  215040      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 12, 12, 192)  576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 12, 12, 192)  576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 12, 12, 192)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_123 (Activation)     (None, 12, 12, 192)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_12_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_12 (Lambda)             (None, 12, 12, 1088) 0           block17_11_ac[0][0]              \n",
      "                                                                 block17_12_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_12_ac (Activation)      (None, 12, 12, 1088) 0           block17_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 12, 12, 128)  139264      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 12, 12, 128)  384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 12, 12, 128)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 12, 12, 160)  143360      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 12, 12, 160)  480         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 12, 12, 160)  0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 12, 12, 192)  208896      block17_12_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 12, 12, 192)  215040      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 12, 12, 192)  576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 12, 12, 192)  576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 12, 12, 192)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 12, 12, 192)  0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_13_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_13 (Lambda)             (None, 12, 12, 1088) 0           block17_12_ac[0][0]              \n",
      "                                                                 block17_13_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_13_ac (Activation)      (None, 12, 12, 1088) 0           block17_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 12, 12, 128)  139264      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 12, 12, 128)  384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 12, 12, 128)  0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 12, 12, 160)  143360      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 12, 12, 160)  480         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 12, 12, 160)  0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 12, 12, 192)  208896      block17_13_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 12, 12, 192)  215040      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 12, 12, 192)  576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 12, 12, 192)  576         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 12, 12, 192)  0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 12, 12, 192)  0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_128[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_14_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_14 (Lambda)             (None, 12, 12, 1088) 0           block17_13_ac[0][0]              \n",
      "                                                                 block17_14_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_14_ac (Activation)      (None, 12, 12, 1088) 0           block17_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 12, 12, 128)  139264      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 12, 12, 128)  384         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 12, 12, 128)  0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 12, 12, 160)  143360      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 12, 12, 160)  480         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 12, 12, 160)  0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 12, 12, 192)  208896      block17_14_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 12, 12, 192)  215040      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 12, 12, 192)  576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 12, 12, 192)  576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 12, 12, 192)  0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 12, 12, 192)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_132[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_15_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_15 (Lambda)             (None, 12, 12, 1088) 0           block17_14_ac[0][0]              \n",
      "                                                                 block17_15_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_15_ac (Activation)      (None, 12, 12, 1088) 0           block17_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 12, 12, 128)  139264      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 12, 12, 128)  384         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 12, 12, 128)  0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 12, 12, 160)  143360      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 12, 12, 160)  480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 12, 12, 160)  0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 12, 12, 192)  208896      block17_15_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 12, 12, 192)  215040      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 12, 12, 192)  576         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 12, 12, 192)  576         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 12, 12, 192)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 12, 12, 192)  0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_136[0][0]             \n",
      "                                                                 activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_16_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_16 (Lambda)             (None, 12, 12, 1088) 0           block17_15_ac[0][0]              \n",
      "                                                                 block17_16_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_16_ac (Activation)      (None, 12, 12, 1088) 0           block17_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 12, 12, 128)  139264      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 12, 12, 128)  384         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 12, 12, 128)  0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 12, 12, 160)  143360      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 12, 12, 160)  480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 12, 12, 160)  0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 12, 12, 192)  208896      block17_16_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 12, 12, 192)  215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_140 (BatchN (None, 12, 12, 192)  576         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 12, 12, 192)  576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 12, 12, 192)  0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 12, 12, 192)  0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_140[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_17_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_17 (Lambda)             (None, 12, 12, 1088) 0           block17_16_ac[0][0]              \n",
      "                                                                 block17_17_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_17_ac (Activation)      (None, 12, 12, 1088) 0           block17_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 12, 12, 128)  139264      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 12, 12, 128)  384         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 12, 12, 128)  0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 12, 12, 160)  143360      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 12, 12, 160)  480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 12, 12, 160)  0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 12, 12, 192)  208896      block17_17_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 12, 12, 192)  215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 12, 12, 192)  576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 12, 12, 192)  576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 12, 12, 192)  0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 12, 12, 192)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_18_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_18 (Lambda)             (None, 12, 12, 1088) 0           block17_17_ac[0][0]              \n",
      "                                                                 block17_18_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_18_ac (Activation)      (None, 12, 12, 1088) 0           block17_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 12, 12, 128)  139264      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 12, 12, 128)  384         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 12, 12, 128)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 12, 12, 160)  143360      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 12, 12, 160)  480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 12, 12, 160)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 12, 12, 192)  208896      block17_18_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 12, 12, 192)  215040      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 12, 12, 192)  576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 12, 12, 192)  576         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 12, 12, 192)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 12, 12, 192)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_148[0][0]             \n",
      "                                                                 activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_19_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_19 (Lambda)             (None, 12, 12, 1088) 0           block17_18_ac[0][0]              \n",
      "                                                                 block17_19_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_19_ac (Activation)      (None, 12, 12, 1088) 0           block17_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 12, 12, 128)  139264      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 12, 12, 128)  384         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 12, 12, 128)  0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 12, 12, 160)  143360      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 12, 12, 160)  480         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 12, 12, 160)  0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 12, 12, 192)  208896      block17_19_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 12, 12, 192)  215040      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 12, 12, 192)  576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 12, 12, 192)  576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 12, 12, 192)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 12, 12, 192)  0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_mixed (Concatenate)  (None, 12, 12, 384)  0           activation_152[0][0]             \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_conv (Conv2D)        (None, 12, 12, 1088) 418880      block17_20_mixed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block17_20 (Lambda)             (None, 12, 12, 1088) 0           block17_19_ac[0][0]              \n",
      "                                                                 block17_20_conv[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block17_20_ac (Activation)      (None, 12, 12, 1088) 0           block17_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 12, 12, 256)  768         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 12, 12, 256)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 12, 12, 256)  278528      block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 12, 12, 288)  663552      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 12, 12, 256)  768         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 12, 12, 256)  768         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 12, 12, 288)  864         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 12, 12, 256)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 12, 12, 256)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 12, 12, 288)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 5, 5, 384)    884736      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 5, 5, 288)    663552      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 5, 5, 320)    829440      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 5, 5, 384)    1152        conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 5, 5, 288)    864         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 5, 5, 320)    960         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 5, 5, 384)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 5, 5, 288)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 5, 5, 320)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 1088)   0           block17_20_ac[0][0]              \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed_7a (Concatenate)          (None, 5, 5, 2080)   0           activation_157[0][0]             \n",
      "                                                                 activation_159[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 5, 5, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 5, 5, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 5, 5, 224)    129024      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 5, 5, 224)    672         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 5, 5, 224)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 5, 5, 192)    399360      mixed_7a[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 5, 5, 256)    172032      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 5, 5, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 5, 5, 256)    768         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 5, 5, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 5, 5, 256)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_163[0][0]             \n",
      "                                                                 activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_1_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_1 (Lambda)               (None, 5, 5, 2080)   0           mixed_7a[0][0]                   \n",
      "                                                                 block8_1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_1_ac (Activation)        (None, 5, 5, 2080)   0           block8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 5, 5, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 5, 5, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 5, 5, 224)    129024      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 5, 5, 224)    672         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 5, 5, 224)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 5, 5, 192)    399360      block8_1_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 5, 5, 256)    172032      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 5, 5, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 5, 5, 256)    768         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 5, 5, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 5, 5, 256)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_167[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_2_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_2 (Lambda)               (None, 5, 5, 2080)   0           block8_1_ac[0][0]                \n",
      "                                                                 block8_2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_2_ac (Activation)        (None, 5, 5, 2080)   0           block8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 5, 5, 192)    576         conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 5, 5, 192)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 5, 5, 224)    129024      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 5, 5, 224)    672         conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 5, 5, 224)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 5, 5, 192)    399360      block8_2_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 5, 5, 256)    172032      activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 5, 5, 192)    576         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 5, 5, 256)    768         conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 5, 5, 192)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 5, 5, 256)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_171[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_3_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_3 (Lambda)               (None, 5, 5, 2080)   0           block8_2_ac[0][0]                \n",
      "                                                                 block8_3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_3_ac (Activation)        (None, 5, 5, 2080)   0           block8_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 5, 5, 192)    576         conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 5, 5, 192)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 5, 5, 224)    129024      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 5, 5, 224)    672         conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 5, 5, 224)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 5, 5, 192)    399360      block8_3_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 5, 5, 256)    172032      activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 5, 5, 192)    576         conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 5, 5, 256)    768         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 5, 5, 192)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 5, 5, 256)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_175[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_4_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_4 (Lambda)               (None, 5, 5, 2080)   0           block8_3_ac[0][0]                \n",
      "                                                                 block8_4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_4_ac (Activation)        (None, 5, 5, 2080)   0           block8_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 5, 5, 192)    576         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 5, 5, 192)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 5, 5, 224)    129024      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 5, 5, 224)    672         conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 5, 5, 224)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 5, 5, 192)    399360      block8_4_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 5, 5, 256)    172032      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 5, 5, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 5, 5, 256)    768         conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 5, 5, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 5, 5, 256)    0           batch_normalization_182[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block8_5_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_179[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_5_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_5 (Lambda)               (None, 5, 5, 2080)   0           block8_4_ac[0][0]                \n",
      "                                                                 block8_5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_5_ac (Activation)        (None, 5, 5, 2080)   0           block8_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 5, 5, 192)    576         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 5, 5, 192)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 5, 5, 224)    129024      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 5, 5, 224)    672         conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 5, 5, 224)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 5, 5, 192)    399360      block8_5_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 5, 5, 256)    172032      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 5, 5, 192)    576         conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 5, 5, 256)    768         conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 5, 5, 192)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 5, 5, 256)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_183[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_6_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_6 (Lambda)               (None, 5, 5, 2080)   0           block8_5_ac[0][0]                \n",
      "                                                                 block8_6_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_6_ac (Activation)        (None, 5, 5, 2080)   0           block8_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 5, 5, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 5, 5, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 5, 5, 224)    129024      activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 5, 5, 224)    672         conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 5, 5, 224)    0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 5, 5, 192)    399360      block8_6_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 5, 5, 256)    172032      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 5, 5, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 5, 5, 256)    768         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 5, 5, 192)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 5, 5, 256)    0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_187[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_7_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_7 (Lambda)               (None, 5, 5, 2080)   0           block8_6_ac[0][0]                \n",
      "                                                                 block8_7_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_7_ac (Activation)        (None, 5, 5, 2080)   0           block8_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 5, 5, 192)    576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 5, 5, 192)    0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 5, 5, 224)    129024      activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 5, 5, 224)    672         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 5, 5, 224)    0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 5, 5, 192)    399360      block8_7_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 5, 5, 256)    172032      activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 5, 5, 192)    576         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 5, 5, 256)    768         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 5, 5, 192)    0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 5, 5, 256)    0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_191[0][0]             \n",
      "                                                                 activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_8_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_8 (Lambda)               (None, 5, 5, 2080)   0           block8_7_ac[0][0]                \n",
      "                                                                 block8_8_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_8_ac (Activation)        (None, 5, 5, 2080)   0           block8_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 5, 5, 192)    576         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 5, 5, 192)    0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 5, 5, 224)    129024      activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 5, 5, 224)    672         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 5, 5, 224)    0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 5, 5, 192)    399360      block8_8_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 5, 5, 256)    172032      activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 5, 5, 192)    576         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 5, 5, 256)    768         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 5, 5, 192)    0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 5, 5, 256)    0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_mixed (Concatenate)    (None, 5, 5, 448)    0           activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_conv (Conv2D)          (None, 5, 5, 2080)   933920      block8_9_mixed[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_9 (Lambda)               (None, 5, 5, 2080)   0           block8_8_ac[0][0]                \n",
      "                                                                 block8_9_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block8_9_ac (Activation)        (None, 5, 5, 2080)   0           block8_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 5, 5, 192)    576         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 5, 5, 192)    0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 5, 5, 224)    129024      activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 5, 5, 224)    672         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 5, 5, 224)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 5, 5, 192)    399360      block8_9_ac[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 5, 5, 256)    172032      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 5, 5, 192)    576         conv2d_199[0][0]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 5, 5, 256)    768         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 5, 5, 192)    0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 5, 5, 256)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_mixed (Concatenate)   (None, 5, 5, 448)    0           activation_199[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block8_10_conv (Conv2D)         (None, 5, 5, 2080)   933920      block8_10_mixed[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_10 (Lambda)              (None, 5, 5, 2080)   0           block8_9_ac[0][0]                \n",
      "                                                                 block8_10_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b (Conv2D)                (None, 5, 5, 1536)   3194880     block8_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_bn (BatchNormalization) (None, 5, 5, 1536)   4608        conv_7b[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_7b_ac (Activation)         (None, 5, 5, 1536)   0           conv_7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 38400)        0           conv_7b_ac[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 5)            192005      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 54,528,741\n",
      "Trainable params: 54,468,197\n",
      "Non-trainable params: 60,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelss = Model(inputs = inc.inputs, outputs = predictionss)\n",
    "modelss.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tqd4h7wYdfzq",
    "outputId": "5096f8d2-4a7d-4dbd-fa2b-6efe44fd14c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-e7e030ea9087>:2: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.6856 - accuracy: 0.25 - ETA: 12:00 - loss: 2.5637 - accuracy: 0.437 - ETA: 15:54 - loss: 3.0212 - accuracy: 0.437 - ETA: 17:42 - loss: 2.9113 - accuracy: 0.437 - ETA: 18:43 - loss: 3.1926 - accuracy: 0.431 - ETA: 19:18 - loss: 2.9815 - accuracy: 0.447 - ETA: 19:38 - loss: 2.6994 - accuracy: 0.473 - ETA: 19:51 - loss: 2.7451 - accuracy: 0.472 - ETA: 19:57 - loss: 2.5447 - accuracy: 0.486 - ETA: 19:59 - loss: 2.3864 - accuracy: 0.506 - ETA: 19:58 - loss: 2.2507 - accuracy: 0.531 - ETA: 19:57 - loss: 2.2552 - accuracy: 0.533 - ETA: 19:57 - loss: 2.1607 - accuracy: 0.548 - ETA: 19:51 - loss: 2.1817 - accuracy: 0.564 - ETA: 19:43 - loss: 2.1499 - accuracy: 0.568 - ETA: 19:34 - loss: 2.0699 - accuracy: 0.574 - ETA: 19:26 - loss: 2.0485 - accuracy: 0.579 - ETA: 19:16 - loss: 1.9658 - accuracy: 0.593 - ETA: 19:05 - loss: 1.9148 - accuracy: 0.593 - ETA: 18:55 - loss: 1.8590 - accuracy: 0.600 - ETA: 18:43 - loss: 1.8698 - accuracy: 0.595 - ETA: 18:32 - loss: 1.8258 - accuracy: 0.595 - ETA: 18:20 - loss: 1.7822 - accuracy: 0.597 - ETA: 18:08 - loss: 1.7299 - accuracy: 0.609 - ETA: 17:57 - loss: 1.7158 - accuracy: 0.613 - ETA: 17:42 - loss: 1.6774 - accuracy: 0.619 - ETA: 17:30 - loss: 1.7342 - accuracy: 0.617 - ETA: 17:18 - loss: 1.6990 - accuracy: 0.620 - ETA: 17:05 - loss: 1.6623 - accuracy: 0.625 - ETA: 16:52 - loss: 1.6720 - accuracy: 0.625 - ETA: 16:39 - loss: 1.6508 - accuracy: 0.622 - ETA: 16:27 - loss: 1.6619 - accuracy: 0.621 - ETA: 16:14 - loss: 1.6357 - accuracy: 0.623 - ETA: 16:02 - loss: 1.6040 - accuracy: 0.629 - ETA: 15:49 - loss: 1.6001 - accuracy: 0.631 - ETA: 15:35 - loss: 1.5795 - accuracy: 0.631 - ETA: 15:22 - loss: 1.5639 - accuracy: 0.628 - ETA: 15:08 - loss: 1.5410 - accuracy: 0.631 - ETA: 14:55 - loss: 1.5206 - accuracy: 0.631 - ETA: 14:41 - loss: 1.5215 - accuracy: 0.631 - ETA: 14:28 - loss: 1.5489 - accuracy: 0.632 - ETA: 14:14 - loss: 1.5305 - accuracy: 0.632 - ETA: 14:00 - loss: 1.5211 - accuracy: 0.632 - ETA: 13:47 - loss: 1.5032 - accuracy: 0.635 - ETA: 13:33 - loss: 1.4912 - accuracy: 0.635 - ETA: 13:19 - loss: 1.4764 - accuracy: 0.638 - ETA: 13:06 - loss: 1.5594 - accuracy: 0.640 - ETA: 12:52 - loss: 1.5656 - accuracy: 0.641 - ETA: 12:38 - loss: 1.6036 - accuracy: 0.645 - ETA: 12:24 - loss: 1.5853 - accuracy: 0.647 - ETA: 12:11 - loss: 1.6098 - accuracy: 0.642 - ETA: 11:57 - loss: 1.6280 - accuracy: 0.643 - ETA: 11:43 - loss: 1.6143 - accuracy: 0.645 - ETA: 11:29 - loss: 1.6024 - accuracy: 0.645 - ETA: 11:15 - loss: 1.5882 - accuracy: 0.646 - ETA: 11:01 - loss: 1.5709 - accuracy: 0.649 - ETA: 10:47 - loss: 1.5753 - accuracy: 0.650 - ETA: 10:33 - loss: 1.5585 - accuracy: 0.653 - ETA: 10:19 - loss: 1.5905 - accuracy: 0.652 - ETA: 10:05 - loss: 1.6161 - accuracy: 0.653 - ETA: 9:50 - loss: 1.6527 - accuracy: 0.653 - ETA: 9:36 - loss: 1.6458 - accuracy: 0.65 - ETA: 9:22 - loss: 1.6302 - accuracy: 0.65 - ETA: 9:08 - loss: 1.6136 - accuracy: 0.65 - ETA: 8:54 - loss: 1.6047 - accuracy: 0.65 - ETA: 8:40 - loss: 1.5895 - accuracy: 0.66 - ETA: 8:26 - loss: 1.5764 - accuracy: 0.66 - ETA: 8:12 - loss: 1.5649 - accuracy: 0.66 - ETA: 7:58 - loss: 1.6049 - accuracy: 0.66 - ETA: 7:44 - loss: 1.5920 - accuracy: 0.66 - ETA: 7:30 - loss: 1.6964 - accuracy: 0.66 - ETA: 7:16 - loss: 1.6802 - accuracy: 0.66 - ETA: 7:02 - loss: 1.6665 - accuracy: 0.66 - ETA: 6:48 - loss: 1.6531 - accuracy: 0.66 - ETA: 6:33 - loss: 1.6389 - accuracy: 0.67 - ETA: 6:19 - loss: 1.6598 - accuracy: 0.67 - ETA: 6:05 - loss: 1.6471 - accuracy: 0.67 - ETA: 5:51 - loss: 1.6497 - accuracy: 0.67 - ETA: 5:37 - loss: 1.6358 - accuracy: 0.67 - ETA: 5:23 - loss: 1.6276 - accuracy: 0.67 - ETA: 5:09 - loss: 1.6152 - accuracy: 0.67 - ETA: 4:55 - loss: 1.6081 - accuracy: 0.67 - ETA: 4:41 - loss: 1.5948 - accuracy: 0.67 - ETA: 4:27 - loss: 1.5834 - accuracy: 0.67 - ETA: 4:13 - loss: 1.5723 - accuracy: 0.67 - ETA: 3:59 - loss: 1.5612 - accuracy: 0.67 - ETA: 3:45 - loss: 1.5733 - accuracy: 0.67 - ETA: 3:31 - loss: 1.5675 - accuracy: 0.67 - ETA: 3:17 - loss: 1.5578 - accuracy: 0.67 - ETA: 3:02 - loss: 1.5486 - accuracy: 0.67 - ETA: 2:48 - loss: 1.5401 - accuracy: 0.67 - ETA: 2:34 - loss: 1.5307 - accuracy: 0.67 - ETA: 2:20 - loss: 1.5196 - accuracy: 0.68 - ETA: 2:06 - loss: 1.5165 - accuracy: 0.67 - ETA: 1:52 - loss: 1.5101 - accuracy: 0.67 - ETA: 1:38 - loss: 1.5006 - accuracy: 0.67 - ETA: 1:24 - loss: 1.4905 - accuracy: 0.68 - ETA: 1:10 - loss: 1.4805 - accuracy: 0.68 - ETA: 56s - loss: 1.4719 - accuracy: 0.6829 - ETA: 42s - loss: 1.4926 - accuracy: 0.683 - ETA: 28s - loss: 1.4831 - accuracy: 0.684 - ETA: 14s - loss: 1.4762 - accuracy: 0.685 - ETA: 0s - loss: 1.4702 - accuracy: 0.685 - 1476s 14s/step - loss: 1.4702 - accuracy: 0.6852 - val_loss: 8.4914 - val_accuracy: 0.7391\n",
      "Epoch 2/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8344 - accuracy: 0.62 - ETA: 11:48 - loss: 0.7100 - accuracy: 0.703 - ETA: 15:31 - loss: 0.7332 - accuracy: 0.697 - ETA: 17:13 - loss: 0.6879 - accuracy: 0.718 - ETA: 18:14 - loss: 0.7471 - accuracy: 0.712 - ETA: 18:48 - loss: 0.7306 - accuracy: 0.713 - ETA: 19:08 - loss: 0.7113 - accuracy: 0.709 - ETA: 19:20 - loss: 0.7219 - accuracy: 0.703 - ETA: 19:27 - loss: 0.7214 - accuracy: 0.697 - ETA: 19:30 - loss: 0.7235 - accuracy: 0.706 - ETA: 19:29 - loss: 0.7270 - accuracy: 0.707 - ETA: 19:27 - loss: 0.7100 - accuracy: 0.718 - ETA: 19:22 - loss: 0.7136 - accuracy: 0.721 - ETA: 19:16 - loss: 0.6880 - accuracy: 0.729 - ETA: 19:09 - loss: 0.6884 - accuracy: 0.729 - ETA: 19:01 - loss: 0.6785 - accuracy: 0.734 - ETA: 18:52 - loss: 0.6731 - accuracy: 0.739 - ETA: 18:43 - loss: 0.7104 - accuracy: 0.739 - ETA: 18:33 - loss: 0.7143 - accuracy: 0.736 - ETA: 18:23 - loss: 0.7099 - accuracy: 0.739 - ETA: 18:12 - loss: 0.7143 - accuracy: 0.736 - ETA: 18:02 - loss: 0.7430 - accuracy: 0.740 - ETA: 17:50 - loss: 0.7425 - accuracy: 0.739 - ETA: 17:39 - loss: 0.7534 - accuracy: 0.738 - ETA: 17:27 - loss: 0.7400 - accuracy: 0.741 - ETA: 17:16 - loss: 0.7395 - accuracy: 0.739 - ETA: 17:04 - loss: 0.7325 - accuracy: 0.740 - ETA: 16:52 - loss: 0.7293 - accuracy: 0.742 - ETA: 16:40 - loss: 0.7247 - accuracy: 0.744 - ETA: 16:27 - loss: 0.7152 - accuracy: 0.747 - ETA: 16:15 - loss: 0.7068 - accuracy: 0.752 - ETA: 16:03 - loss: 0.7059 - accuracy: 0.752 - ETA: 15:50 - loss: 0.7058 - accuracy: 0.751 - ETA: 15:38 - loss: 0.7024 - accuracy: 0.751 - ETA: 15:25 - loss: 0.6924 - accuracy: 0.755 - ETA: 15:13 - loss: 0.6878 - accuracy: 0.756 - ETA: 15:00 - loss: 0.6857 - accuracy: 0.755 - ETA: 14:47 - loss: 0.6894 - accuracy: 0.756 - ETA: 14:34 - loss: 0.6860 - accuracy: 0.757 - ETA: 14:21 - loss: 0.6783 - accuracy: 0.759 - ETA: 14:08 - loss: 0.6943 - accuracy: 0.753 - ETA: 13:54 - loss: 0.6903 - accuracy: 0.755 - ETA: 13:41 - loss: 0.7110 - accuracy: 0.755 - ETA: 13:29 - loss: 0.7080 - accuracy: 0.754 - ETA: 13:16 - loss: 0.7091 - accuracy: 0.751 - ETA: 13:02 - loss: 0.7038 - accuracy: 0.752 - ETA: 12:49 - loss: 0.6998 - accuracy: 0.754 - ETA: 12:36 - loss: 0.7032 - accuracy: 0.750 - ETA: 12:22 - loss: 0.6977 - accuracy: 0.753 - ETA: 12:09 - loss: 0.6930 - accuracy: 0.754 - ETA: 11:55 - loss: 0.6877 - accuracy: 0.757 - ETA: 11:42 - loss: 0.6874 - accuracy: 0.756 - ETA: 11:28 - loss: 0.6930 - accuracy: 0.755 - ETA: 11:14 - loss: 0.6874 - accuracy: 0.757 - ETA: 11:01 - loss: 0.6957 - accuracy: 0.758 - ETA: 10:47 - loss: 0.7326 - accuracy: 0.757 - ETA: 10:34 - loss: 0.7289 - accuracy: 0.757 - ETA: 10:20 - loss: 0.7227 - accuracy: 0.759 - ETA: 10:07 - loss: 0.7311 - accuracy: 0.756 - ETA: 9:53 - loss: 0.7662 - accuracy: 0.752 - ETA: 9:40 - loss: 0.7653 - accuracy: 0.75 - ETA: 9:27 - loss: 0.7600 - accuracy: 0.75 - ETA: 9:13 - loss: 0.7566 - accuracy: 0.75 - ETA: 9:00 - loss: 0.7535 - accuracy: 0.75 - ETA: 8:46 - loss: 0.7540 - accuracy: 0.75 - ETA: 8:33 - loss: 0.7496 - accuracy: 0.75 - ETA: 8:19 - loss: 0.7891 - accuracy: 0.75 - ETA: 8:05 - loss: 0.7875 - accuracy: 0.75 - ETA: 7:52 - loss: 0.8082 - accuracy: 0.75 - ETA: 7:38 - loss: 0.8058 - accuracy: 0.75 - ETA: 7:24 - loss: 0.8030 - accuracy: 0.75 - ETA: 7:11 - loss: 0.8051 - accuracy: 0.75 - ETA: 6:57 - loss: 0.8126 - accuracy: 0.75 - ETA: 6:43 - loss: 0.8073 - accuracy: 0.75 - ETA: 6:29 - loss: 0.8043 - accuracy: 0.75 - ETA: 6:15 - loss: 0.8007 - accuracy: 0.75 - ETA: 6:02 - loss: 0.7996 - accuracy: 0.75 - ETA: 5:48 - loss: 0.7958 - accuracy: 0.75 - ETA: 5:34 - loss: 0.7930 - accuracy: 0.75 - ETA: 5:20 - loss: 0.7918 - accuracy: 0.75 - ETA: 5:06 - loss: 0.7891 - accuracy: 0.75 - ETA: 4:52 - loss: 0.7878 - accuracy: 0.75 - ETA: 4:38 - loss: 0.7873 - accuracy: 0.75 - ETA: 4:24 - loss: 0.7858 - accuracy: 0.75 - ETA: 4:10 - loss: 0.7840 - accuracy: 0.75 - ETA: 3:56 - loss: 0.7819 - accuracy: 0.75 - ETA: 3:43 - loss: 0.7824 - accuracy: 0.75 - ETA: 3:29 - loss: 0.7815 - accuracy: 0.75 - ETA: 3:15 - loss: 0.7790 - accuracy: 0.75 - ETA: 3:01 - loss: 0.7763 - accuracy: 0.75 - ETA: 2:47 - loss: 0.7723 - accuracy: 0.75 - ETA: 2:33 - loss: 0.7680 - accuracy: 0.75 - ETA: 2:19 - loss: 0.7661 - accuracy: 0.75 - ETA: 2:05 - loss: 0.7643 - accuracy: 0.75 - ETA: 1:51 - loss: 0.7615 - accuracy: 0.75 - ETA: 1:37 - loss: 0.7600 - accuracy: 0.75 - ETA: 1:23 - loss: 0.7589 - accuracy: 0.75 - ETA: 1:09 - loss: 0.7576 - accuracy: 0.75 - ETA: 55s - loss: 0.7550 - accuracy: 0.7574 - ETA: 41s - loss: 0.7520 - accuracy: 0.757 - ETA: 27s - loss: 0.7485 - accuracy: 0.757 - ETA: 13s - loss: 0.7484 - accuracy: 0.756 - ETA: 0s - loss: 0.7460 - accuracy: 0.756 - 1462s 14s/step - loss: 0.7460 - accuracy: 0.7568 - val_loss: 0.6353 - val_accuracy: 0.7853\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.8865 - accuracy: 0.62 - ETA: 11:47 - loss: 0.8056 - accuracy: 0.671 - ETA: 15:34 - loss: 0.7145 - accuracy: 0.697 - ETA: 17:20 - loss: 0.6707 - accuracy: 0.726 - ETA: 18:18 - loss: 0.6526 - accuracy: 0.743 - ETA: 18:52 - loss: 0.6637 - accuracy: 0.744 - ETA: 19:12 - loss: 0.6438 - accuracy: 0.741 - ETA: 19:24 - loss: 0.6232 - accuracy: 0.746 - ETA: 19:29 - loss: 0.6100 - accuracy: 0.760 - ETA: 19:32 - loss: 0.6021 - accuracy: 0.765 - ETA: 19:34 - loss: 0.5983 - accuracy: 0.772 - ETA: 19:31 - loss: 0.5861 - accuracy: 0.776 - ETA: 19:26 - loss: 0.5817 - accuracy: 0.778 - ETA: 19:20 - loss: 0.5806 - accuracy: 0.783 - ETA: 19:13 - loss: 0.5626 - accuracy: 0.793 - ETA: 19:07 - loss: 0.5488 - accuracy: 0.798 - ETA: 18:58 - loss: 0.5348 - accuracy: 0.801 - ETA: 18:50 - loss: 0.5926 - accuracy: 0.788 - ETA: 18:41 - loss: 0.6079 - accuracy: 0.784 - ETA: 18:32 - loss: 0.6300 - accuracy: 0.776 - ETA: 18:22 - loss: 0.6267 - accuracy: 0.775 - ETA: 18:11 - loss: 0.6179 - accuracy: 0.778 - ETA: 18:01 - loss: 0.6261 - accuracy: 0.774 - ETA: 17:50 - loss: 0.6247 - accuracy: 0.774 - ETA: 17:39 - loss: 0.6284 - accuracy: 0.770 - ETA: 17:28 - loss: 0.6241 - accuracy: 0.774 - ETA: 17:16 - loss: 0.6203 - accuracy: 0.775 - ETA: 17:05 - loss: 0.6248 - accuracy: 0.775 - ETA: 16:53 - loss: 0.6245 - accuracy: 0.775 - ETA: 16:41 - loss: 0.7491 - accuracy: 0.775 - ETA: 16:29 - loss: 0.7439 - accuracy: 0.775 - ETA: 16:16 - loss: 0.7436 - accuracy: 0.774 - ETA: 16:04 - loss: 0.7460 - accuracy: 0.773 - ETA: 15:53 - loss: 0.7444 - accuracy: 0.773 - ETA: 15:46 - loss: 0.7416 - accuracy: 0.771 - ETA: 15:37 - loss: 0.7361 - accuracy: 0.770 - ETA: 15:29 - loss: 0.7373 - accuracy: 0.771 - ETA: 15:20 - loss: 0.7333 - accuracy: 0.772 - ETA: 15:09 - loss: 0.7284 - accuracy: 0.774 - ETA: 14:56 - loss: 0.7230 - accuracy: 0.775 - ETA: 14:42 - loss: 0.7247 - accuracy: 0.774 - ETA: 14:28 - loss: 0.7261 - accuracy: 0.772 - ETA: 14:14 - loss: 0.7224 - accuracy: 0.773 - ETA: 14:00 - loss: 0.7204 - accuracy: 0.773 - ETA: 13:46 - loss: 0.7165 - accuracy: 0.772 - ETA: 13:32 - loss: 0.7100 - accuracy: 0.774 - ETA: 13:18 - loss: 0.7017 - accuracy: 0.775 - ETA: 13:04 - loss: 0.6986 - accuracy: 0.777 - ETA: 12:50 - loss: 0.6892 - accuracy: 0.780 - ETA: 12:36 - loss: 0.6912 - accuracy: 0.778 - ETA: 12:22 - loss: 0.7010 - accuracy: 0.775 - ETA: 12:08 - loss: 0.6952 - accuracy: 0.777 - ETA: 11:53 - loss: 0.6925 - accuracy: 0.775 - ETA: 11:39 - loss: 0.6940 - accuracy: 0.774 - ETA: 11:25 - loss: 0.7029 - accuracy: 0.773 - ETA: 11:12 - loss: 0.7011 - accuracy: 0.774 - ETA: 10:58 - loss: 0.6981 - accuracy: 0.774 - ETA: 10:44 - loss: 0.6960 - accuracy: 0.774 - ETA: 10:30 - loss: 0.6912 - accuracy: 0.775 - ETA: 10:17 - loss: 0.6989 - accuracy: 0.773 - ETA: 10:03 - loss: 0.7045 - accuracy: 0.770 - ETA: 9:49 - loss: 0.7042 - accuracy: 0.770 - ETA: 9:35 - loss: 0.6991 - accuracy: 0.77 - ETA: 9:21 - loss: 0.7014 - accuracy: 0.77 - ETA: 9:07 - loss: 0.7018 - accuracy: 0.76 - ETA: 8:53 - loss: 0.7094 - accuracy: 0.76 - ETA: 8:39 - loss: 0.7272 - accuracy: 0.76 - ETA: 8:26 - loss: 0.7294 - accuracy: 0.76 - ETA: 8:12 - loss: 0.7291 - accuracy: 0.76 - ETA: 7:58 - loss: 0.7270 - accuracy: 0.76 - ETA: 7:44 - loss: 0.7247 - accuracy: 0.76 - ETA: 7:30 - loss: 0.7241 - accuracy: 0.76 - ETA: 7:16 - loss: 0.7225 - accuracy: 0.76 - ETA: 7:02 - loss: 0.7189 - accuracy: 0.76 - ETA: 6:48 - loss: 0.7206 - accuracy: 0.76 - ETA: 6:33 - loss: 0.7152 - accuracy: 0.76 - ETA: 6:19 - loss: 0.7133 - accuracy: 0.76 - ETA: 6:05 - loss: 0.7149 - accuracy: 0.76 - ETA: 5:51 - loss: 0.7156 - accuracy: 0.76 - ETA: 5:36 - loss: 0.7115 - accuracy: 0.76 - ETA: 5:22 - loss: 0.7101 - accuracy: 0.76 - ETA: 5:07 - loss: 0.7077 - accuracy: 0.76 - ETA: 4:53 - loss: 0.7056 - accuracy: 0.76 - ETA: 4:39 - loss: 0.7017 - accuracy: 0.76 - ETA: 4:24 - loss: 0.7006 - accuracy: 0.76 - ETA: 4:10 - loss: 0.6995 - accuracy: 0.76 - ETA: 3:55 - loss: 0.6983 - accuracy: 0.76 - ETA: 3:40 - loss: 0.6964 - accuracy: 0.76 - ETA: 3:26 - loss: 0.6951 - accuracy: 0.76 - ETA: 3:11 - loss: 0.6947 - accuracy: 0.76 - ETA: 2:57 - loss: 0.6949 - accuracy: 0.76 - ETA: 2:42 - loss: 0.6951 - accuracy: 0.76 - ETA: 2:27 - loss: 0.6930 - accuracy: 0.76 - ETA: 2:13 - loss: 0.6915 - accuracy: 0.76 - ETA: 1:58 - loss: 0.6910 - accuracy: 0.76 - ETA: 1:43 - loss: 0.6918 - accuracy: 0.76 - ETA: 1:28 - loss: 0.6897 - accuracy: 0.76 - ETA: 1:14 - loss: 0.6886 - accuracy: 0.76 - ETA: 59s - loss: 0.6882 - accuracy: 0.7660 - ETA: 44s - loss: 0.6872 - accuracy: 0.766 - ETA: 29s - loss: 0.6895 - accuracy: 0.764 - ETA: 14s - loss: 0.6880 - accuracy: 0.765 - ETA: 0s - loss: 0.6878 - accuracy: 0.765 - 1559s 15s/step - loss: 0.6878 - accuracy: 0.7659 - val_loss: 0.8315 - val_accuracy: 0.6766\n",
      "Epoch 4/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.87 - ETA: 13:37 - loss: 0.4970 - accuracy: 0.765 - ETA: 18:05 - loss: 0.5402 - accuracy: 0.760 - ETA: 20:14 - loss: 0.5712 - accuracy: 0.726 - ETA: 21:18 - loss: 0.5747 - accuracy: 0.743 - ETA: 21:57 - loss: 0.6006 - accuracy: 0.750 - ETA: 22:23 - loss: 0.6249 - accuracy: 0.745 - ETA: 22:39 - loss: 0.6109 - accuracy: 0.753 - ETA: 22:53 - loss: 0.6015 - accuracy: 0.756 - ETA: 22:57 - loss: 0.5976 - accuracy: 0.765 - ETA: 22:58 - loss: 0.5869 - accuracy: 0.772 - ETA: 22:56 - loss: 0.5701 - accuracy: 0.776 - ETA: 22:50 - loss: 0.5856 - accuracy: 0.766 - ETA: 22:44 - loss: 0.5757 - accuracy: 0.770 - ETA: 22:36 - loss: 0.5683 - accuracy: 0.775 - ETA: 22:28 - loss: 0.5530 - accuracy: 0.781 - ETA: 22:18 - loss: 0.5530 - accuracy: 0.777 - ETA: 22:08 - loss: 0.5351 - accuracy: 0.786 - ETA: 21:57 - loss: 0.5360 - accuracy: 0.786 - ETA: 21:43 - loss: 0.5275 - accuracy: 0.792 - ETA: 21:30 - loss: 0.5212 - accuracy: 0.791 - ETA: 21:18 - loss: 0.5907 - accuracy: 0.788 - ETA: 21:06 - loss: 0.5893 - accuracy: 0.788 - ETA: 20:51 - loss: 0.5828 - accuracy: 0.789 - ETA: 20:37 - loss: 0.5746 - accuracy: 0.792 - ETA: 20:23 - loss: 0.5870 - accuracy: 0.786 - ETA: 20:09 - loss: 0.5817 - accuracy: 0.787 - ETA: 19:55 - loss: 0.5745 - accuracy: 0.789 - ETA: 19:40 - loss: 0.5695 - accuracy: 0.788 - ETA: 19:26 - loss: 0.5760 - accuracy: 0.782 - ETA: 19:11 - loss: 0.5778 - accuracy: 0.783 - ETA: 18:56 - loss: 0.5848 - accuracy: 0.782 - ETA: 18:41 - loss: 0.5832 - accuracy: 0.781 - ETA: 18:26 - loss: 0.5864 - accuracy: 0.782 - ETA: 18:12 - loss: 0.5878 - accuracy: 0.782 - ETA: 17:57 - loss: 0.7244 - accuracy: 0.776 - ETA: 17:42 - loss: 0.7245 - accuracy: 0.779 - ETA: 17:27 - loss: 0.7289 - accuracy: 0.778 - ETA: 17:11 - loss: 0.7344 - accuracy: 0.778 - ETA: 16:56 - loss: 0.7629 - accuracy: 0.771 - ETA: 16:41 - loss: 0.7605 - accuracy: 0.772 - ETA: 16:25 - loss: 0.7612 - accuracy: 0.772 - ETA: 16:09 - loss: 0.7566 - accuracy: 0.772 - ETA: 15:53 - loss: 0.7830 - accuracy: 0.772 - ETA: 15:37 - loss: 0.7804 - accuracy: 0.770 - ETA: 15:22 - loss: 0.7850 - accuracy: 0.768 - ETA: 15:06 - loss: 0.8225 - accuracy: 0.761 - ETA: 14:51 - loss: 0.8185 - accuracy: 0.761 - ETA: 14:35 - loss: 0.8187 - accuracy: 0.758 - ETA: 14:19 - loss: 0.8425 - accuracy: 0.759 - ETA: 14:03 - loss: 0.8546 - accuracy: 0.758 - ETA: 13:48 - loss: 0.8577 - accuracy: 0.758 - ETA: 13:32 - loss: 0.8555 - accuracy: 0.757 - ETA: 13:16 - loss: 0.8492 - accuracy: 0.759 - ETA: 13:00 - loss: 0.8431 - accuracy: 0.761 - ETA: 12:44 - loss: 0.8884 - accuracy: 0.759 - ETA: 12:28 - loss: 0.8859 - accuracy: 0.757 - ETA: 12:12 - loss: 0.8796 - accuracy: 0.757 - ETA: 11:56 - loss: 0.8738 - accuracy: 0.757 - ETA: 11:40 - loss: 0.8667 - accuracy: 0.758 - ETA: 11:23 - loss: 0.8622 - accuracy: 0.758 - ETA: 11:07 - loss: 0.8558 - accuracy: 0.759 - ETA: 10:51 - loss: 0.8513 - accuracy: 0.759 - ETA: 10:35 - loss: 0.8446 - accuracy: 0.761 - ETA: 10:19 - loss: 0.8500 - accuracy: 0.758 - ETA: 10:03 - loss: 0.8444 - accuracy: 0.759 - ETA: 9:47 - loss: 0.8872 - accuracy: 0.757 - ETA: 9:30 - loss: 0.8811 - accuracy: 0.75 - ETA: 9:14 - loss: 0.8771 - accuracy: 0.75 - ETA: 8:58 - loss: 0.8727 - accuracy: 0.75 - ETA: 8:41 - loss: 0.8702 - accuracy: 0.75 - ETA: 8:25 - loss: 0.8637 - accuracy: 0.75 - ETA: 8:09 - loss: 0.8575 - accuracy: 0.76 - ETA: 7:52 - loss: 0.8587 - accuracy: 0.75 - ETA: 7:36 - loss: 0.8555 - accuracy: 0.75 - ETA: 7:20 - loss: 0.8563 - accuracy: 0.75 - ETA: 7:04 - loss: 0.8526 - accuracy: 0.75 - ETA: 6:48 - loss: 0.8487 - accuracy: 0.75 - ETA: 6:31 - loss: 0.8457 - accuracy: 0.75 - ETA: 6:15 - loss: 0.8439 - accuracy: 0.75 - ETA: 5:59 - loss: 0.8391 - accuracy: 0.75 - ETA: 5:43 - loss: 0.8413 - accuracy: 0.75 - ETA: 5:26 - loss: 0.8513 - accuracy: 0.75 - ETA: 5:10 - loss: 0.8464 - accuracy: 0.75 - ETA: 4:54 - loss: 0.8428 - accuracy: 0.75 - ETA: 4:38 - loss: 0.8403 - accuracy: 0.75 - ETA: 4:21 - loss: 0.8383 - accuracy: 0.75 - ETA: 4:05 - loss: 0.8367 - accuracy: 0.75 - ETA: 3:49 - loss: 0.8314 - accuracy: 0.75 - ETA: 3:32 - loss: 0.8279 - accuracy: 0.75 - ETA: 3:16 - loss: 0.8231 - accuracy: 0.75 - ETA: 2:59 - loss: 0.8245 - accuracy: 0.75 - ETA: 2:43 - loss: 0.8251 - accuracy: 0.75 - ETA: 2:27 - loss: 0.8238 - accuracy: 0.75 - ETA: 2:10 - loss: 0.8202 - accuracy: 0.75 - ETA: 1:54 - loss: 0.8219 - accuracy: 0.75 - ETA: 1:38 - loss: 0.8184 - accuracy: 0.75 - ETA: 1:21 - loss: 0.8173 - accuracy: 0.75 - ETA: 1:05 - loss: 0.8157 - accuracy: 0.75 - ETA: 49s - loss: 0.8121 - accuracy: 0.7592 - ETA: 32s - loss: 0.8079 - accuracy: 0.759 - ETA: 16s - loss: 0.8044 - accuracy: 0.760 - ETA: 0s - loss: 0.8017 - accuracy: 0.761 - 1710s 17s/step - loss: 0.8017 - accuracy: 0.7614 - val_loss: 57.8903 - val_accuracy: 0.4239\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.9895 - accuracy: 0.71 - ETA: 12:51 - loss: 0.8394 - accuracy: 0.734 - ETA: 16:59 - loss: 0.7311 - accuracy: 0.770 - ETA: 18:57 - loss: 0.6902 - accuracy: 0.765 - ETA: 20:05 - loss: 0.6632 - accuracy: 0.787 - ETA: 20:53 - loss: 0.6570 - accuracy: 0.781 - ETA: 21:18 - loss: 0.6363 - accuracy: 0.781 - ETA: 21:33 - loss: 0.6219 - accuracy: 0.773 - ETA: 21:39 - loss: 0.6214 - accuracy: 0.763 - ETA: 21:45 - loss: 0.6203 - accuracy: 0.765 - ETA: 21:42 - loss: 0.5989 - accuracy: 0.778 - ETA: 21:36 - loss: 0.5828 - accuracy: 0.786 - ETA: 21:28 - loss: 0.5877 - accuracy: 0.781 - ETA: 21:20 - loss: 0.5839 - accuracy: 0.783 - ETA: 21:10 - loss: 0.6003 - accuracy: 0.772 - ETA: 21:00 - loss: 0.6078 - accuracy: 0.769 - ETA: 20:47 - loss: 0.6052 - accuracy: 0.772 - ETA: 20:37 - loss: 0.6103 - accuracy: 0.767 - ETA: 20:28 - loss: 0.6047 - accuracy: 0.769 - ETA: 20:19 - loss: 0.5856 - accuracy: 0.779 - ETA: 20:09 - loss: 0.5814 - accuracy: 0.781 - ETA: 19:57 - loss: 0.5812 - accuracy: 0.778 - ETA: 19:46 - loss: 0.5734 - accuracy: 0.784 - ETA: 19:34 - loss: 0.6888 - accuracy: 0.783 - ETA: 19:21 - loss: 0.6801 - accuracy: 0.786 - ETA: 19:08 - loss: 0.6812 - accuracy: 0.787 - ETA: 18:56 - loss: 0.6892 - accuracy: 0.787 - ETA: 18:42 - loss: 0.6918 - accuracy: 0.786 - ETA: 18:30 - loss: 0.6856 - accuracy: 0.787 - ETA: 18:16 - loss: 0.6775 - accuracy: 0.789 - ETA: 18:03 - loss: 0.6789 - accuracy: 0.788 - ETA: 17:49 - loss: 0.6728 - accuracy: 0.790 - ETA: 17:36 - loss: 0.6649 - accuracy: 0.790 - ETA: 17:23 - loss: 0.6614 - accuracy: 0.791 - ETA: 17:09 - loss: 0.6638 - accuracy: 0.786 - ETA: 16:54 - loss: 0.6595 - accuracy: 0.783 - ETA: 16:41 - loss: 0.6581 - accuracy: 0.784 - ETA: 16:27 - loss: 0.6686 - accuracy: 0.784 - ETA: 16:12 - loss: 0.6631 - accuracy: 0.785 - ETA: 15:58 - loss: 0.6576 - accuracy: 0.785 - ETA: 15:43 - loss: 0.6528 - accuracy: 0.786 - ETA: 15:29 - loss: 0.6428 - accuracy: 0.788 - ETA: 15:14 - loss: 0.6383 - accuracy: 0.791 - ETA: 14:59 - loss: 0.6834 - accuracy: 0.791 - ETA: 14:44 - loss: 0.6797 - accuracy: 0.792 - ETA: 14:29 - loss: 0.6842 - accuracy: 0.789 - ETA: 14:13 - loss: 0.6790 - accuracy: 0.790 - ETA: 13:57 - loss: 0.6830 - accuracy: 0.790 - ETA: 13:42 - loss: 0.6797 - accuracy: 0.791 - ETA: 13:26 - loss: 0.6773 - accuracy: 0.791 - ETA: 13:10 - loss: 0.6773 - accuracy: 0.789 - ETA: 12:55 - loss: 0.6707 - accuracy: 0.792 - ETA: 12:39 - loss: 0.6649 - accuracy: 0.793 - ETA: 12:23 - loss: 0.7312 - accuracy: 0.791 - ETA: 12:07 - loss: 0.7256 - accuracy: 0.793 - ETA: 11:51 - loss: 0.7192 - accuracy: 0.795 - ETA: 11:35 - loss: 0.7233 - accuracy: 0.792 - ETA: 11:20 - loss: 0.7225 - accuracy: 0.792 - ETA: 11:04 - loss: 0.7222 - accuracy: 0.792 - ETA: 10:48 - loss: 0.7179 - accuracy: 0.794 - ETA: 10:33 - loss: 0.7132 - accuracy: 0.795 - ETA: 10:17 - loss: 0.7083 - accuracy: 0.796 - ETA: 10:02 - loss: 0.7337 - accuracy: 0.796 - ETA: 9:46 - loss: 0.7294 - accuracy: 0.797 - ETA: 9:31 - loss: 0.7255 - accuracy: 0.79 - ETA: 9:15 - loss: 0.7226 - accuracy: 0.79 - ETA: 9:00 - loss: 0.7212 - accuracy: 0.79 - ETA: 8:44 - loss: 0.7295 - accuracy: 0.79 - ETA: 8:29 - loss: 0.7276 - accuracy: 0.79 - ETA: 8:14 - loss: 0.7269 - accuracy: 0.79 - ETA: 7:59 - loss: 0.7240 - accuracy: 0.79 - ETA: 7:43 - loss: 0.7222 - accuracy: 0.79 - ETA: 7:28 - loss: 0.7201 - accuracy: 0.79 - ETA: 7:13 - loss: 0.7179 - accuracy: 0.79 - ETA: 6:58 - loss: 0.7144 - accuracy: 0.79 - ETA: 6:43 - loss: 0.7109 - accuracy: 0.79 - ETA: 6:27 - loss: 0.7113 - accuracy: 0.79 - ETA: 6:12 - loss: 0.7099 - accuracy: 0.79 - ETA: 5:57 - loss: 0.7073 - accuracy: 0.79 - ETA: 5:42 - loss: 0.7152 - accuracy: 0.79 - ETA: 5:27 - loss: 0.7129 - accuracy: 0.79 - ETA: 5:12 - loss: 0.7160 - accuracy: 0.79 - ETA: 4:57 - loss: 0.7135 - accuracy: 0.79 - ETA: 4:42 - loss: 0.7097 - accuracy: 0.79 - ETA: 4:27 - loss: 0.7099 - accuracy: 0.79 - ETA: 4:12 - loss: 0.7090 - accuracy: 0.79 - ETA: 3:57 - loss: 0.7045 - accuracy: 0.79 - ETA: 3:42 - loss: 0.7027 - accuracy: 0.79 - ETA: 3:27 - loss: 0.7016 - accuracy: 0.79 - ETA: 3:12 - loss: 0.7031 - accuracy: 0.79 - ETA: 2:57 - loss: 0.7010 - accuracy: 0.79 - ETA: 2:42 - loss: 0.6997 - accuracy: 0.79 - ETA: 2:27 - loss: 0.6970 - accuracy: 0.79 - ETA: 2:12 - loss: 0.6947 - accuracy: 0.79 - ETA: 1:58 - loss: 0.6924 - accuracy: 0.79 - ETA: 1:43 - loss: 0.6881 - accuracy: 0.79 - ETA: 1:28 - loss: 0.6867 - accuracy: 0.79 - ETA: 1:13 - loss: 0.6854 - accuracy: 0.79 - ETA: 58s - loss: 0.6876 - accuracy: 0.7969 - ETA: 44s - loss: 0.6874 - accuracy: 0.797 - ETA: 29s - loss: 0.6860 - accuracy: 0.796 - ETA: 14s - loss: 0.6838 - accuracy: 0.797 - ETA: 0s - loss: 0.6841 - accuracy: 0.797 - 1539s 15s/step - loss: 0.6841 - accuracy: 0.7975 - val_loss: 0.5160 - val_accuracy: 0.8071\n",
      "Epoch 6/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3599 - accuracy: 0.87 - ETA: 11:51 - loss: 0.7069 - accuracy: 0.765 - ETA: 15:37 - loss: 0.5832 - accuracy: 0.802 - ETA: 17:28 - loss: 0.5673 - accuracy: 0.781 - ETA: 18:26 - loss: 0.5748 - accuracy: 0.781 - ETA: 18:59 - loss: 1.1665 - accuracy: 0.755 - ETA: 19:20 - loss: 1.9323 - accuracy: 0.758 - ETA: 19:31 - loss: 1.7607 - accuracy: 0.769 - ETA: 19:37 - loss: 1.5822 - accuracy: 0.795 - ETA: 19:39 - loss: 1.4868 - accuracy: 0.793 - ETA: 19:38 - loss: 1.4255 - accuracy: 0.781 - ETA: 19:34 - loss: 1.3589 - accuracy: 0.778 - ETA: 19:30 - loss: 1.2831 - accuracy: 0.788 - ETA: 19:24 - loss: 1.2138 - accuracy: 0.801 - ETA: 19:16 - loss: 1.1688 - accuracy: 0.804 - ETA: 19:09 - loss: 1.1275 - accuracy: 0.800 - ETA: 19:00 - loss: 1.1291 - accuracy: 0.794 - ETA: 18:51 - loss: 1.0885 - accuracy: 0.800 - ETA: 18:40 - loss: 1.0665 - accuracy: 0.797 - ETA: 18:30 - loss: 1.0281 - accuracy: 0.803 - ETA: 18:20 - loss: 0.9956 - accuracy: 0.806 - ETA: 18:09 - loss: 0.9812 - accuracy: 0.802 - ETA: 17:57 - loss: 0.9555 - accuracy: 0.803 - ETA: 17:46 - loss: 0.9357 - accuracy: 0.800 - ETA: 17:34 - loss: 0.9304 - accuracy: 0.800 - ETA: 17:22 - loss: 0.9138 - accuracy: 0.795 - ETA: 17:10 - loss: 0.8957 - accuracy: 0.796 - ETA: 16:58 - loss: 0.8857 - accuracy: 0.793 - ETA: 16:46 - loss: 0.8774 - accuracy: 0.792 - ETA: 16:34 - loss: 0.8897 - accuracy: 0.787 - ETA: 16:21 - loss: 0.8753 - accuracy: 0.788 - ETA: 16:08 - loss: 0.8703 - accuracy: 0.786 - ETA: 15:55 - loss: 0.8586 - accuracy: 0.784 - ETA: 15:43 - loss: 0.8447 - accuracy: 0.784 - ETA: 15:30 - loss: 0.8357 - accuracy: 0.783 - ETA: 15:17 - loss: 0.8238 - accuracy: 0.786 - ETA: 15:04 - loss: 0.8439 - accuracy: 0.782 - ETA: 14:50 - loss: 0.8476 - accuracy: 0.778 - ETA: 14:37 - loss: 0.8347 - accuracy: 0.780 - ETA: 14:24 - loss: 0.8325 - accuracy: 0.778 - ETA: 14:11 - loss: 0.8210 - accuracy: 0.780 - ETA: 13:58 - loss: 0.8152 - accuracy: 0.779 - ETA: 13:45 - loss: 0.8140 - accuracy: 0.779 - ETA: 13:31 - loss: 0.8134 - accuracy: 0.778 - ETA: 13:18 - loss: 0.8071 - accuracy: 0.778 - ETA: 13:05 - loss: 0.7988 - accuracy: 0.780 - ETA: 12:51 - loss: 0.7921 - accuracy: 0.781 - ETA: 12:38 - loss: 0.7849 - accuracy: 0.781 - ETA: 12:24 - loss: 0.7832 - accuracy: 0.779 - ETA: 12:11 - loss: 0.7761 - accuracy: 0.781 - ETA: 11:57 - loss: 0.7715 - accuracy: 0.780 - ETA: 11:44 - loss: 0.7674 - accuracy: 0.780 - ETA: 11:30 - loss: 0.7963 - accuracy: 0.781 - ETA: 11:17 - loss: 0.7916 - accuracy: 0.781 - ETA: 11:03 - loss: 0.7886 - accuracy: 0.780 - ETA: 10:50 - loss: 0.7845 - accuracy: 0.780 - ETA: 10:36 - loss: 0.7843 - accuracy: 0.778 - ETA: 10:22 - loss: 0.7803 - accuracy: 0.778 - ETA: 10:09 - loss: 0.7786 - accuracy: 0.778 - ETA: 9:55 - loss: 0.7755 - accuracy: 0.779 - ETA: 9:41 - loss: 0.7714 - accuracy: 0.78 - ETA: 9:28 - loss: 0.7720 - accuracy: 0.78 - ETA: 9:14 - loss: 0.7696 - accuracy: 0.78 - ETA: 9:00 - loss: 0.7699 - accuracy: 0.77 - ETA: 8:46 - loss: 0.7696 - accuracy: 0.77 - ETA: 8:32 - loss: 0.7662 - accuracy: 0.77 - ETA: 8:19 - loss: 0.7650 - accuracy: 0.77 - ETA: 8:05 - loss: 0.7620 - accuracy: 0.77 - ETA: 7:51 - loss: 0.7650 - accuracy: 0.77 - ETA: 7:37 - loss: 0.7645 - accuracy: 0.77 - ETA: 7:24 - loss: 0.7627 - accuracy: 0.77 - ETA: 7:10 - loss: 0.7819 - accuracy: 0.77 - ETA: 6:56 - loss: 0.7786 - accuracy: 0.77 - ETA: 6:42 - loss: 0.7769 - accuracy: 0.77 - ETA: 6:29 - loss: 0.7730 - accuracy: 0.77 - ETA: 6:15 - loss: 0.7696 - accuracy: 0.77 - ETA: 6:01 - loss: 0.7684 - accuracy: 0.77 - ETA: 5:47 - loss: 0.7652 - accuracy: 0.77 - ETA: 5:33 - loss: 0.7656 - accuracy: 0.77 - ETA: 5:19 - loss: 0.7624 - accuracy: 0.77 - ETA: 5:05 - loss: 0.7595 - accuracy: 0.77 - ETA: 4:52 - loss: 0.7551 - accuracy: 0.77 - ETA: 4:38 - loss: 0.7538 - accuracy: 0.77 - ETA: 4:24 - loss: 0.7502 - accuracy: 0.77 - ETA: 4:10 - loss: 0.7504 - accuracy: 0.77 - ETA: 3:56 - loss: 0.7487 - accuracy: 0.77 - ETA: 3:42 - loss: 0.7479 - accuracy: 0.77 - ETA: 3:28 - loss: 0.7474 - accuracy: 0.77 - ETA: 3:14 - loss: 0.7444 - accuracy: 0.77 - ETA: 3:01 - loss: 0.7444 - accuracy: 0.77 - ETA: 2:47 - loss: 0.7408 - accuracy: 0.77 - ETA: 2:33 - loss: 0.7397 - accuracy: 0.77 - ETA: 2:19 - loss: 0.7377 - accuracy: 0.78 - ETA: 2:05 - loss: 0.7359 - accuracy: 0.77 - ETA: 1:51 - loss: 0.7366 - accuracy: 0.77 - ETA: 1:37 - loss: 0.7351 - accuracy: 0.77 - ETA: 1:23 - loss: 0.7359 - accuracy: 0.77 - ETA: 1:09 - loss: 0.7333 - accuracy: 0.77 - ETA: 55s - loss: 0.7330 - accuracy: 0.7770 - ETA: 41s - loss: 0.7334 - accuracy: 0.776 - ETA: 27s - loss: 0.7312 - accuracy: 0.776 - ETA: 13s - loss: 0.7294 - accuracy: 0.776 - ETA: 0s - loss: 0.7283 - accuracy: 0.776 - 1461s 14s/step - loss: 0.7283 - accuracy: 0.7766 - val_loss: 18292.5957 - val_accuracy: 0.5353\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.7003 - accuracy: 0.68 - ETA: 11:57 - loss: 0.5417 - accuracy: 0.750 - ETA: 15:39 - loss: 0.5082 - accuracy: 0.781 - ETA: 17:26 - loss: 0.5285 - accuracy: 0.757 - ETA: 18:24 - loss: 0.5365 - accuracy: 0.768 - ETA: 18:59 - loss: 0.5874 - accuracy: 0.755 - ETA: 19:19 - loss: 0.5788 - accuracy: 0.758 - ETA: 19:30 - loss: 0.5629 - accuracy: 0.765 - ETA: 19:36 - loss: 0.5597 - accuracy: 0.770 - ETA: 19:38 - loss: 0.5564 - accuracy: 0.775 - ETA: 19:37 - loss: 0.5561 - accuracy: 0.775 - ETA: 19:35 - loss: 0.5407 - accuracy: 0.783 - ETA: 19:31 - loss: 0.5359 - accuracy: 0.786 - ETA: 19:24 - loss: 0.5332 - accuracy: 0.790 - ETA: 19:16 - loss: 0.5410 - accuracy: 0.787 - ETA: 19:08 - loss: 0.5377 - accuracy: 0.789 - ETA: 18:59 - loss: 0.5405 - accuracy: 0.784 - ETA: 18:50 - loss: 0.5267 - accuracy: 0.791 - ETA: 18:41 - loss: 0.5312 - accuracy: 0.791 - ETA: 18:31 - loss: 0.5245 - accuracy: 0.792 - ETA: 18:20 - loss: 0.5347 - accuracy: 0.788 - ETA: 18:09 - loss: 0.5345 - accuracy: 0.789 - ETA: 17:58 - loss: 0.5327 - accuracy: 0.790 - ETA: 17:46 - loss: 0.5623 - accuracy: 0.786 - ETA: 17:35 - loss: 0.5561 - accuracy: 0.788 - ETA: 17:23 - loss: 0.5490 - accuracy: 0.790 - ETA: 17:11 - loss: 0.5471 - accuracy: 0.788 - ETA: 16:59 - loss: 0.5510 - accuracy: 0.787 - ETA: 16:46 - loss: 0.5444 - accuracy: 0.790 - ETA: 16:34 - loss: 0.5402 - accuracy: 0.793 - ETA: 16:21 - loss: 0.5401 - accuracy: 0.792 - ETA: 16:09 - loss: 0.5435 - accuracy: 0.791 - ETA: 15:56 - loss: 0.5534 - accuracy: 0.787 - ETA: 15:43 - loss: 0.5459 - accuracy: 0.789 - ETA: 15:31 - loss: 0.5416 - accuracy: 0.791 - ETA: 15:18 - loss: 0.5380 - accuracy: 0.791 - ETA: 15:05 - loss: 0.5424 - accuracy: 0.790 - ETA: 14:51 - loss: 0.5411 - accuracy: 0.789 - ETA: 14:38 - loss: 0.5357 - accuracy: 0.792 - ETA: 14:25 - loss: 0.5348 - accuracy: 0.792 - ETA: 14:12 - loss: 0.5410 - accuracy: 0.789 - ETA: 13:59 - loss: 0.5438 - accuracy: 0.787 - ETA: 13:46 - loss: 0.5413 - accuracy: 0.789 - ETA: 13:32 - loss: 0.5357 - accuracy: 0.791 - ETA: 13:19 - loss: 0.5357 - accuracy: 0.791 - ETA: 13:06 - loss: 0.5361 - accuracy: 0.792 - ETA: 12:52 - loss: 0.5313 - accuracy: 0.793 - ETA: 12:39 - loss: 0.5292 - accuracy: 0.793 - ETA: 12:25 - loss: 0.5283 - accuracy: 0.794 - ETA: 12:12 - loss: 0.5265 - accuracy: 0.795 - ETA: 11:58 - loss: 0.5292 - accuracy: 0.794 - ETA: 11:45 - loss: 0.5288 - accuracy: 0.795 - ETA: 11:31 - loss: 0.5348 - accuracy: 0.791 - ETA: 11:17 - loss: 0.5452 - accuracy: 0.790 - ETA: 11:04 - loss: 0.5435 - accuracy: 0.792 - ETA: 10:50 - loss: 0.5389 - accuracy: 0.794 - ETA: 10:37 - loss: 0.5370 - accuracy: 0.795 - ETA: 10:23 - loss: 0.5353 - accuracy: 0.794 - ETA: 10:09 - loss: 0.5394 - accuracy: 0.794 - ETA: 9:55 - loss: 0.5402 - accuracy: 0.792 - ETA: 9:42 - loss: 0.5394 - accuracy: 0.79 - ETA: 9:28 - loss: 0.5376 - accuracy: 0.79 - ETA: 9:14 - loss: 0.5353 - accuracy: 0.79 - ETA: 9:01 - loss: 0.5373 - accuracy: 0.79 - ETA: 8:47 - loss: 0.5341 - accuracy: 0.79 - ETA: 8:33 - loss: 0.5332 - accuracy: 0.79 - ETA: 8:19 - loss: 0.5313 - accuracy: 0.79 - ETA: 8:06 - loss: 0.5309 - accuracy: 0.79 - ETA: 7:52 - loss: 0.5345 - accuracy: 0.79 - ETA: 7:38 - loss: 0.5330 - accuracy: 0.79 - ETA: 7:24 - loss: 0.5352 - accuracy: 0.79 - ETA: 7:10 - loss: 0.5317 - accuracy: 0.79 - ETA: 6:57 - loss: 0.5302 - accuracy: 0.79 - ETA: 6:43 - loss: 0.5309 - accuracy: 0.79 - ETA: 6:29 - loss: 0.5331 - accuracy: 0.79 - ETA: 6:15 - loss: 0.5300 - accuracy: 0.79 - ETA: 6:01 - loss: 0.5289 - accuracy: 0.79 - ETA: 5:47 - loss: 0.5290 - accuracy: 0.79 - ETA: 5:33 - loss: 0.5285 - accuracy: 0.79 - ETA: 5:20 - loss: 0.5304 - accuracy: 0.79 - ETA: 5:06 - loss: 0.5298 - accuracy: 0.79 - ETA: 4:52 - loss: 0.5284 - accuracy: 0.79 - ETA: 4:38 - loss: 0.5293 - accuracy: 0.79 - ETA: 4:24 - loss: 0.5293 - accuracy: 0.79 - ETA: 4:10 - loss: 0.5296 - accuracy: 0.79 - ETA: 3:56 - loss: 0.5303 - accuracy: 0.79 - ETA: 3:42 - loss: 0.5301 - accuracy: 0.79 - ETA: 3:29 - loss: 0.5312 - accuracy: 0.79 - ETA: 3:15 - loss: 0.5305 - accuracy: 0.79 - ETA: 3:01 - loss: 0.5283 - accuracy: 0.79 - ETA: 2:47 - loss: 0.5304 - accuracy: 0.79 - ETA: 2:33 - loss: 0.5293 - accuracy: 0.79 - ETA: 2:19 - loss: 0.5304 - accuracy: 0.79 - ETA: 2:05 - loss: 0.5282 - accuracy: 0.79 - ETA: 1:51 - loss: 0.5274 - accuracy: 0.79 - ETA: 1:37 - loss: 0.5261 - accuracy: 0.79 - ETA: 1:23 - loss: 0.5262 - accuracy: 0.79 - ETA: 1:09 - loss: 0.5237 - accuracy: 0.79 - ETA: 55s - loss: 0.5249 - accuracy: 0.7997 - ETA: 41s - loss: 0.5233 - accuracy: 0.800 - ETA: 27s - loss: 0.5225 - accuracy: 0.800 - ETA: 13s - loss: 0.5226 - accuracy: 0.799 - ETA: 0s - loss: 0.5230 - accuracy: 0.800 - 1462s 14s/step - loss: 0.5230 - accuracy: 0.8002 - val_loss: 0.8445 - val_accuracy: 0.7418\n",
      "Epoch 8/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.81 - ETA: 11:54 - loss: 0.4943 - accuracy: 0.828 - ETA: 15:42 - loss: 0.4582 - accuracy: 0.833 - ETA: 17:31 - loss: 0.4291 - accuracy: 0.859 - ETA: 18:28 - loss: 0.4686 - accuracy: 0.837 - ETA: 19:01 - loss: 0.4752 - accuracy: 0.833 - ETA: 19:22 - loss: 0.5047 - accuracy: 0.817 - ETA: 19:33 - loss: 0.5042 - accuracy: 0.820 - ETA: 19:39 - loss: 0.4947 - accuracy: 0.819 - ETA: 19:40 - loss: 0.4903 - accuracy: 0.821 - ETA: 19:41 - loss: 0.4844 - accuracy: 0.821 - ETA: 19:37 - loss: 0.4730 - accuracy: 0.825 - ETA: 19:33 - loss: 0.4622 - accuracy: 0.834 - ETA: 19:27 - loss: 0.4599 - accuracy: 0.837 - ETA: 19:15 - loss: 0.4535 - accuracy: 0.841 - ETA: 19:07 - loss: 0.4484 - accuracy: 0.841 - ETA: 18:58 - loss: 0.4428 - accuracy: 0.843 - ETA: 18:49 - loss: 0.4521 - accuracy: 0.839 - ETA: 18:39 - loss: 0.4478 - accuracy: 0.841 - ETA: 18:29 - loss: 0.4445 - accuracy: 0.844 - ETA: 18:18 - loss: 0.4480 - accuracy: 0.843 - ETA: 18:08 - loss: 0.4470 - accuracy: 0.844 - ETA: 17:56 - loss: 0.4425 - accuracy: 0.842 - ETA: 17:45 - loss: 0.4375 - accuracy: 0.842 - ETA: 17:34 - loss: 0.4403 - accuracy: 0.840 - ETA: 17:22 - loss: 0.4365 - accuracy: 0.842 - ETA: 17:10 - loss: 0.4339 - accuracy: 0.843 - ETA: 16:58 - loss: 0.5185 - accuracy: 0.837 - ETA: 16:46 - loss: 0.5143 - accuracy: 0.838 - ETA: 16:34 - loss: 0.5108 - accuracy: 0.838 - ETA: 16:21 - loss: 0.5132 - accuracy: 0.836 - ETA: 16:09 - loss: 0.5122 - accuracy: 0.837 - ETA: 15:56 - loss: 0.5179 - accuracy: 0.834 - ETA: 15:43 - loss: 0.5144 - accuracy: 0.836 - ETA: 15:30 - loss: 0.5130 - accuracy: 0.834 - ETA: 15:18 - loss: 0.5148 - accuracy: 0.833 - ETA: 15:05 - loss: 0.5165 - accuracy: 0.832 - ETA: 14:52 - loss: 0.5183 - accuracy: 0.830 - ETA: 14:39 - loss: 0.5150 - accuracy: 0.831 - ETA: 14:25 - loss: 0.5156 - accuracy: 0.830 - ETA: 14:12 - loss: 0.5159 - accuracy: 0.829 - ETA: 13:59 - loss: 0.5174 - accuracy: 0.827 - ETA: 13:46 - loss: 0.5168 - accuracy: 0.826 - ETA: 13:32 - loss: 0.5134 - accuracy: 0.827 - ETA: 13:19 - loss: 0.5114 - accuracy: 0.827 - ETA: 13:06 - loss: 0.5138 - accuracy: 0.825 - ETA: 12:52 - loss: 0.5105 - accuracy: 0.824 - ETA: 12:39 - loss: 0.5102 - accuracy: 0.823 - ETA: 12:25 - loss: 0.5065 - accuracy: 0.824 - ETA: 12:12 - loss: 0.5086 - accuracy: 0.823 - ETA: 11:58 - loss: 0.5050 - accuracy: 0.825 - ETA: 11:45 - loss: 0.5033 - accuracy: 0.824 - ETA: 11:31 - loss: 0.5028 - accuracy: 0.824 - ETA: 11:18 - loss: 0.5023 - accuracy: 0.824 - ETA: 11:04 - loss: 0.5043 - accuracy: 0.823 - ETA: 10:50 - loss: 0.5025 - accuracy: 0.823 - ETA: 10:37 - loss: 0.5001 - accuracy: 0.823 - ETA: 10:23 - loss: 0.4956 - accuracy: 0.824 - ETA: 10:09 - loss: 0.4964 - accuracy: 0.824 - ETA: 9:56 - loss: 0.4936 - accuracy: 0.824 - ETA: 9:42 - loss: 0.4961 - accuracy: 0.82 - ETA: 9:28 - loss: 0.4935 - accuracy: 0.82 - ETA: 9:15 - loss: 0.4935 - accuracy: 0.82 - ETA: 9:01 - loss: 0.4954 - accuracy: 0.82 - ETA: 8:47 - loss: 0.4934 - accuracy: 0.82 - ETA: 8:33 - loss: 0.4925 - accuracy: 0.82 - ETA: 8:20 - loss: 0.4915 - accuracy: 0.82 - ETA: 8:06 - loss: 0.4927 - accuracy: 0.82 - ETA: 7:52 - loss: 0.4913 - accuracy: 0.82 - ETA: 7:38 - loss: 0.4945 - accuracy: 0.82 - ETA: 7:24 - loss: 0.4970 - accuracy: 0.82 - ETA: 7:11 - loss: 0.4960 - accuracy: 0.82 - ETA: 6:57 - loss: 0.4969 - accuracy: 0.82 - ETA: 6:43 - loss: 0.4975 - accuracy: 0.82 - ETA: 6:29 - loss: 0.4972 - accuracy: 0.82 - ETA: 6:15 - loss: 0.4965 - accuracy: 0.82 - ETA: 6:01 - loss: 0.5006 - accuracy: 0.82 - ETA: 5:47 - loss: 0.5015 - accuracy: 0.82 - ETA: 5:34 - loss: 0.5024 - accuracy: 0.82 - ETA: 5:20 - loss: 0.5026 - accuracy: 0.82 - ETA: 5:06 - loss: 0.5033 - accuracy: 0.82 - ETA: 4:52 - loss: 0.5020 - accuracy: 0.82 - ETA: 4:39 - loss: 0.5050 - accuracy: 0.82 - ETA: 4:25 - loss: 0.5031 - accuracy: 0.82 - ETA: 4:11 - loss: 0.5236 - accuracy: 0.82 - ETA: 3:57 - loss: 0.5244 - accuracy: 0.81 - ETA: 3:43 - loss: 0.5277 - accuracy: 0.81 - ETA: 3:29 - loss: 0.5306 - accuracy: 0.81 - ETA: 3:15 - loss: 0.5326 - accuracy: 0.81 - ETA: 3:01 - loss: 0.5323 - accuracy: 0.81 - ETA: 2:47 - loss: 0.5318 - accuracy: 0.81 - ETA: 2:34 - loss: 0.5298 - accuracy: 0.81 - ETA: 2:20 - loss: 0.5272 - accuracy: 0.81 - ETA: 2:06 - loss: 0.5267 - accuracy: 0.81 - ETA: 1:52 - loss: 0.5283 - accuracy: 0.81 - ETA: 1:38 - loss: 0.5319 - accuracy: 0.81 - ETA: 1:24 - loss: 0.5318 - accuracy: 0.81 - ETA: 1:10 - loss: 0.5306 - accuracy: 0.81 - ETA: 56s - loss: 0.5279 - accuracy: 0.8146 - ETA: 42s - loss: 0.5280 - accuracy: 0.814 - ETA: 28s - loss: 0.5267 - accuracy: 0.814 - ETA: 14s - loss: 0.5285 - accuracy: 0.813 - ETA: 0s - loss: 0.5282 - accuracy: 0.813 - 1472s 14s/step - loss: 0.5282 - accuracy: 0.8133 - val_loss: 0.5623 - val_accuracy: 0.8179\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.84 - ETA: 12:21 - loss: 0.4541 - accuracy: 0.843 - ETA: 16:07 - loss: 0.4297 - accuracy: 0.854 - ETA: 17:55 - loss: 0.4679 - accuracy: 0.820 - ETA: 18:52 - loss: 0.4753 - accuracy: 0.818 - ETA: 19:25 - loss: 0.4678 - accuracy: 0.817 - ETA: 19:47 - loss: 1.1845 - accuracy: 0.812 - ETA: 19:58 - loss: 1.0596 - accuracy: 0.824 - ETA: 20:03 - loss: 0.9872 - accuracy: 0.826 - ETA: 20:04 - loss: 0.9683 - accuracy: 0.815 - ETA: 20:03 - loss: 0.9151 - accuracy: 0.818 - ETA: 19:59 - loss: 0.8613 - accuracy: 0.828 - ETA: 19:54 - loss: 0.8193 - accuracy: 0.836 - ETA: 19:47 - loss: 0.7905 - accuracy: 0.837 - ETA: 19:40 - loss: 0.8337 - accuracy: 0.831 - ETA: 19:32 - loss: 0.9228 - accuracy: 0.820 - ETA: 19:23 - loss: 0.8928 - accuracy: 0.818 - ETA: 19:14 - loss: 0.8614 - accuracy: 0.819 - ETA: 19:02 - loss: 0.8753 - accuracy: 0.815 - ETA: 18:50 - loss: 0.8533 - accuracy: 0.818 - ETA: 18:38 - loss: 0.8347 - accuracy: 0.819 - ETA: 18:26 - loss: 0.8075 - accuracy: 0.823 - ETA: 18:14 - loss: 0.8006 - accuracy: 0.822 - ETA: 18:02 - loss: 0.7836 - accuracy: 0.824 - ETA: 17:50 - loss: 0.7700 - accuracy: 0.826 - ETA: 17:39 - loss: 0.7567 - accuracy: 0.826 - ETA: 17:28 - loss: 0.7498 - accuracy: 0.824 - ETA: 17:17 - loss: 0.7414 - accuracy: 0.825 - ETA: 17:05 - loss: 0.7229 - accuracy: 0.828 - ETA: 16:51 - loss: 0.7170 - accuracy: 0.828 - ETA: 16:38 - loss: 0.7063 - accuracy: 0.828 - ETA: 16:25 - loss: 0.6959 - accuracy: 0.831 - ETA: 16:11 - loss: 0.6820 - accuracy: 0.835 - ETA: 15:58 - loss: 0.6828 - accuracy: 0.830 - ETA: 15:44 - loss: 0.6838 - accuracy: 0.827 - ETA: 15:31 - loss: 0.6748 - accuracy: 0.829 - ETA: 15:17 - loss: 0.6708 - accuracy: 0.828 - ETA: 15:04 - loss: 0.6684 - accuracy: 0.826 - ETA: 14:50 - loss: 0.6657 - accuracy: 0.824 - ETA: 14:37 - loss: 0.6605 - accuracy: 0.824 - ETA: 14:23 - loss: 0.6500 - accuracy: 0.827 - ETA: 14:10 - loss: 0.6508 - accuracy: 0.827 - ETA: 13:56 - loss: 0.6416 - accuracy: 0.829 - ETA: 13:42 - loss: 0.6400 - accuracy: 0.826 - ETA: 13:29 - loss: 0.6346 - accuracy: 0.826 - ETA: 13:15 - loss: 0.6309 - accuracy: 0.825 - ETA: 13:02 - loss: 0.6252 - accuracy: 0.826 - ETA: 12:49 - loss: 0.6166 - accuracy: 0.829 - ETA: 12:35 - loss: 0.6094 - accuracy: 0.831 - ETA: 12:21 - loss: 0.6029 - accuracy: 0.833 - ETA: 12:07 - loss: 0.5968 - accuracy: 0.834 - ETA: 11:53 - loss: 0.5913 - accuracy: 0.834 - ETA: 11:40 - loss: 0.5865 - accuracy: 0.834 - ETA: 11:27 - loss: 0.5832 - accuracy: 0.835 - ETA: 11:13 - loss: 0.5833 - accuracy: 0.834 - ETA: 10:59 - loss: 0.5810 - accuracy: 0.833 - ETA: 10:45 - loss: 0.5826 - accuracy: 0.832 - ETA: 10:31 - loss: 0.5802 - accuracy: 0.833 - ETA: 10:17 - loss: 0.5803 - accuracy: 0.832 - ETA: 10:03 - loss: 0.5753 - accuracy: 0.833 - ETA: 9:49 - loss: 0.5770 - accuracy: 0.833 - ETA: 9:35 - loss: 0.5754 - accuracy: 0.83 - ETA: 9:21 - loss: 0.5810 - accuracy: 0.83 - ETA: 9:07 - loss: 0.5803 - accuracy: 0.83 - ETA: 8:53 - loss: 0.5759 - accuracy: 0.83 - ETA: 8:39 - loss: 0.5732 - accuracy: 0.83 - ETA: 8:25 - loss: 0.5706 - accuracy: 0.83 - ETA: 8:11 - loss: 0.5738 - accuracy: 0.83 - ETA: 7:57 - loss: 0.5705 - accuracy: 0.83 - ETA: 7:43 - loss: 0.5687 - accuracy: 0.83 - ETA: 7:30 - loss: 0.5661 - accuracy: 0.83 - ETA: 7:16 - loss: 0.5649 - accuracy: 0.83 - ETA: 7:02 - loss: 0.5656 - accuracy: 0.82 - ETA: 6:48 - loss: 0.5641 - accuracy: 0.82 - ETA: 6:34 - loss: 0.5635 - accuracy: 0.82 - ETA: 6:20 - loss: 0.5618 - accuracy: 0.82 - ETA: 6:06 - loss: 0.5628 - accuracy: 0.82 - ETA: 5:52 - loss: 0.5606 - accuracy: 0.82 - ETA: 5:38 - loss: 0.5603 - accuracy: 0.82 - ETA: 5:24 - loss: 0.5569 - accuracy: 0.82 - ETA: 5:10 - loss: 0.5572 - accuracy: 0.82 - ETA: 4:56 - loss: 0.5550 - accuracy: 0.82 - ETA: 4:42 - loss: 0.5526 - accuracy: 0.82 - ETA: 4:28 - loss: 0.5510 - accuracy: 0.82 - ETA: 4:14 - loss: 0.5484 - accuracy: 0.82 - ETA: 3:59 - loss: 0.5466 - accuracy: 0.82 - ETA: 3:45 - loss: 0.5452 - accuracy: 0.82 - ETA: 3:31 - loss: 0.5430 - accuracy: 0.82 - ETA: 3:17 - loss: 0.5410 - accuracy: 0.82 - ETA: 3:03 - loss: 0.5370 - accuracy: 0.82 - ETA: 2:49 - loss: 0.5404 - accuracy: 0.82 - ETA: 2:35 - loss: 0.5399 - accuracy: 0.82 - ETA: 2:21 - loss: 0.5410 - accuracy: 0.82 - ETA: 2:06 - loss: 0.5445 - accuracy: 0.82 - ETA: 1:52 - loss: 0.5461 - accuracy: 0.82 - ETA: 1:38 - loss: 0.5439 - accuracy: 0.82 - ETA: 1:24 - loss: 0.5432 - accuracy: 0.82 - ETA: 1:10 - loss: 0.5418 - accuracy: 0.82 - ETA: 56s - loss: 0.5421 - accuracy: 0.8250 - ETA: 42s - loss: 0.5423 - accuracy: 0.824 - ETA: 28s - loss: 0.5423 - accuracy: 0.824 - ETA: 14s - loss: 0.5411 - accuracy: 0.824 - ETA: 0s - loss: 0.5390 - accuracy: 0.825 - 1477s 14s/step - loss: 0.5390 - accuracy: 0.8257 - val_loss: 0.5000 - val_accuracy: 0.8288\n",
      "Epoch 10/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.96 - ETA: 11:48 - loss: 0.3543 - accuracy: 0.843 - ETA: 15:36 - loss: 0.3401 - accuracy: 0.854 - ETA: 17:20 - loss: 0.3940 - accuracy: 0.835 - ETA: 18:19 - loss: 0.3902 - accuracy: 0.837 - ETA: 18:54 - loss: 0.3866 - accuracy: 0.843 - ETA: 19:14 - loss: 0.3967 - accuracy: 0.830 - ETA: 19:25 - loss: 0.4081 - accuracy: 0.839 - ETA: 19:32 - loss: 0.4105 - accuracy: 0.836 - ETA: 19:35 - loss: 0.4112 - accuracy: 0.837 - ETA: 19:34 - loss: 0.4202 - accuracy: 0.835 - ETA: 19:31 - loss: 0.4104 - accuracy: 0.841 - ETA: 19:26 - loss: 0.4037 - accuracy: 0.846 - ETA: 19:19 - loss: 0.3909 - accuracy: 0.848 - ETA: 19:12 - loss: 0.3925 - accuracy: 0.847 - ETA: 19:04 - loss: 0.3810 - accuracy: 0.851 - ETA: 18:51 - loss: 0.3917 - accuracy: 0.846 - ETA: 18:42 - loss: 0.3885 - accuracy: 0.848 - ETA: 18:33 - loss: 0.3919 - accuracy: 0.843 - ETA: 18:22 - loss: 0.3839 - accuracy: 0.848 - ETA: 18:12 - loss: 0.3832 - accuracy: 0.852 - ETA: 18:02 - loss: 0.3724 - accuracy: 0.856 - ETA: 17:51 - loss: 0.3629 - accuracy: 0.858 - ETA: 17:40 - loss: 0.3604 - accuracy: 0.860 - ETA: 17:28 - loss: 0.3658 - accuracy: 0.858 - ETA: 17:17 - loss: 0.3588 - accuracy: 0.861 - ETA: 17:05 - loss: 0.3560 - accuracy: 0.861 - ETA: 16:53 - loss: 0.3498 - accuracy: 0.864 - ETA: 16:41 - loss: 0.3535 - accuracy: 0.862 - ETA: 16:29 - loss: 0.3491 - accuracy: 0.865 - ETA: 16:17 - loss: 0.3534 - accuracy: 0.864 - ETA: 16:04 - loss: 0.3540 - accuracy: 0.864 - ETA: 15:52 - loss: 0.3522 - accuracy: 0.865 - ETA: 15:39 - loss: 0.3506 - accuracy: 0.865 - ETA: 15:27 - loss: 0.4555 - accuracy: 0.864 - ETA: 15:14 - loss: 0.4552 - accuracy: 0.864 - ETA: 15:01 - loss: 0.4588 - accuracy: 0.862 - ETA: 14:48 - loss: 0.4527 - accuracy: 0.865 - ETA: 14:35 - loss: 0.4538 - accuracy: 0.864 - ETA: 14:22 - loss: 0.4605 - accuracy: 0.859 - ETA: 14:09 - loss: 0.4622 - accuracy: 0.858 - ETA: 13:56 - loss: 0.4633 - accuracy: 0.857 - ETA: 13:42 - loss: 0.4634 - accuracy: 0.856 - ETA: 13:29 - loss: 0.4630 - accuracy: 0.857 - ETA: 13:16 - loss: 0.4612 - accuracy: 0.855 - ETA: 13:02 - loss: 0.4624 - accuracy: 0.854 - ETA: 12:49 - loss: 0.4634 - accuracy: 0.853 - ETA: 12:36 - loss: 0.4606 - accuracy: 0.854 - ETA: 12:22 - loss: 0.4590 - accuracy: 0.854 - ETA: 12:09 - loss: 0.4555 - accuracy: 0.854 - ETA: 11:55 - loss: 0.4582 - accuracy: 0.853 - ETA: 11:42 - loss: 0.4549 - accuracy: 0.854 - ETA: 11:28 - loss: 0.4552 - accuracy: 0.853 - ETA: 11:15 - loss: 0.4553 - accuracy: 0.852 - ETA: 11:01 - loss: 0.4568 - accuracy: 0.851 - ETA: 10:48 - loss: 0.4576 - accuracy: 0.850 - ETA: 10:34 - loss: 0.4558 - accuracy: 0.849 - ETA: 10:20 - loss: 0.4542 - accuracy: 0.850 - ETA: 10:07 - loss: 0.4550 - accuracy: 0.849 - ETA: 9:53 - loss: 0.4567 - accuracy: 0.848 - ETA: 9:40 - loss: 0.4566 - accuracy: 0.84 - ETA: 9:26 - loss: 0.4538 - accuracy: 0.84 - ETA: 9:12 - loss: 0.4524 - accuracy: 0.84 - ETA: 8:58 - loss: 0.4545 - accuracy: 0.84 - ETA: 8:45 - loss: 0.4518 - accuracy: 0.84 - ETA: 8:31 - loss: 0.4529 - accuracy: 0.84 - ETA: 8:17 - loss: 0.4553 - accuracy: 0.84 - ETA: 8:04 - loss: 0.4535 - accuracy: 0.84 - ETA: 7:50 - loss: 0.4529 - accuracy: 0.84 - ETA: 7:36 - loss: 0.4523 - accuracy: 0.84 - ETA: 7:22 - loss: 0.4535 - accuracy: 0.84 - ETA: 7:09 - loss: 0.4536 - accuracy: 0.84 - ETA: 6:55 - loss: 0.4506 - accuracy: 0.84 - ETA: 6:41 - loss: 0.4496 - accuracy: 0.84 - ETA: 6:27 - loss: 0.4489 - accuracy: 0.84 - ETA: 6:14 - loss: 0.4495 - accuracy: 0.84 - ETA: 6:00 - loss: 0.4493 - accuracy: 0.84 - ETA: 5:46 - loss: 0.4466 - accuracy: 0.84 - ETA: 5:32 - loss: 0.4485 - accuracy: 0.84 - ETA: 5:18 - loss: 0.4464 - accuracy: 0.84 - ETA: 5:05 - loss: 0.4461 - accuracy: 0.84 - ETA: 4:51 - loss: 0.4456 - accuracy: 0.84 - ETA: 4:37 - loss: 0.4437 - accuracy: 0.84 - ETA: 4:23 - loss: 0.4426 - accuracy: 0.84 - ETA: 4:09 - loss: 0.4396 - accuracy: 0.84 - ETA: 3:55 - loss: 0.4382 - accuracy: 0.84 - ETA: 3:42 - loss: 0.4431 - accuracy: 0.84 - ETA: 3:28 - loss: 0.4417 - accuracy: 0.84 - ETA: 3:14 - loss: 0.4433 - accuracy: 0.84 - ETA: 3:00 - loss: 0.4430 - accuracy: 0.84 - ETA: 2:46 - loss: 0.4464 - accuracy: 0.84 - ETA: 2:32 - loss: 0.4459 - accuracy: 0.84 - ETA: 2:18 - loss: 0.4455 - accuracy: 0.84 - ETA: 2:05 - loss: 0.4459 - accuracy: 0.84 - ETA: 1:51 - loss: 0.4438 - accuracy: 0.84 - ETA: 1:37 - loss: 0.4424 - accuracy: 0.84 - ETA: 1:23 - loss: 0.4429 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4421 - accuracy: 0.84 - ETA: 55s - loss: 0.4419 - accuracy: 0.8424 - ETA: 41s - loss: 0.4415 - accuracy: 0.843 - ETA: 27s - loss: 0.4409 - accuracy: 0.843 - ETA: 13s - loss: 0.4386 - accuracy: 0.844 - ETA: 0s - loss: 0.4391 - accuracy: 0.844 - 1457s 14s/step - loss: 0.4391 - accuracy: 0.8449 - val_loss: 0.5627 - val_accuracy: 0.8071\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.4169 - accuracy: 0.93 - ETA: 11:45 - loss: 0.3135 - accuracy: 0.921 - ETA: 15:30 - loss: 0.3177 - accuracy: 0.906 - ETA: 17:20 - loss: 0.3861 - accuracy: 0.875 - ETA: 18:18 - loss: 0.3540 - accuracy: 0.875 - ETA: 18:53 - loss: 0.5219 - accuracy: 0.875 - ETA: 19:15 - loss: 0.4924 - accuracy: 0.870 - ETA: 19:27 - loss: 0.4604 - accuracy: 0.878 - ETA: 19:32 - loss: 0.5114 - accuracy: 0.861 - ETA: 19:34 - loss: 0.4980 - accuracy: 0.856 - ETA: 19:33 - loss: 0.4939 - accuracy: 0.860 - ETA: 19:31 - loss: 0.4737 - accuracy: 0.862 - ETA: 19:26 - loss: 0.4555 - accuracy: 0.865 - ETA: 19:20 - loss: 0.4587 - accuracy: 0.863 - ETA: 19:13 - loss: 0.4399 - accuracy: 0.868 - ETA: 19:05 - loss: 0.4347 - accuracy: 0.867 - ETA: 18:56 - loss: 0.4351 - accuracy: 0.865 - ETA: 18:47 - loss: 0.4296 - accuracy: 0.864 - ETA: 18:38 - loss: 0.4361 - accuracy: 0.866 - ETA: 18:28 - loss: 0.4340 - accuracy: 0.864 - ETA: 18:17 - loss: 0.4423 - accuracy: 0.863 - ETA: 18:06 - loss: 0.4399 - accuracy: 0.862 - ETA: 17:55 - loss: 0.4395 - accuracy: 0.860 - ETA: 17:43 - loss: 0.4345 - accuracy: 0.859 - ETA: 17:31 - loss: 0.4255 - accuracy: 0.863 - ETA: 17:19 - loss: 0.4248 - accuracy: 0.860 - ETA: 17:07 - loss: 0.4313 - accuracy: 0.856 - ETA: 16:55 - loss: 0.4408 - accuracy: 0.852 - ETA: 16:43 - loss: 0.4382 - accuracy: 0.853 - ETA: 16:31 - loss: 0.4362 - accuracy: 0.851 - ETA: 16:18 - loss: 0.4535 - accuracy: 0.848 - ETA: 16:05 - loss: 0.4520 - accuracy: 0.849 - ETA: 15:52 - loss: 0.4492 - accuracy: 0.852 - ETA: 15:40 - loss: 0.4531 - accuracy: 0.850 - ETA: 15:27 - loss: 0.4466 - accuracy: 0.851 - ETA: 15:14 - loss: 0.4441 - accuracy: 0.851 - ETA: 15:01 - loss: 0.4467 - accuracy: 0.851 - ETA: 14:48 - loss: 0.4476 - accuracy: 0.849 - ETA: 14:34 - loss: 0.4436 - accuracy: 0.850 - ETA: 14:21 - loss: 0.4445 - accuracy: 0.850 - ETA: 14:07 - loss: 0.4455 - accuracy: 0.849 - ETA: 13:54 - loss: 0.4474 - accuracy: 0.847 - ETA: 13:41 - loss: 0.4455 - accuracy: 0.847 - ETA: 13:28 - loss: 0.4462 - accuracy: 0.847 - ETA: 13:15 - loss: 0.4421 - accuracy: 0.849 - ETA: 13:01 - loss: 0.4422 - accuracy: 0.846 - ETA: 12:48 - loss: 0.4397 - accuracy: 0.848 - ETA: 12:35 - loss: 0.4394 - accuracy: 0.848 - ETA: 12:21 - loss: 0.4382 - accuracy: 0.849 - ETA: 12:08 - loss: 0.4362 - accuracy: 0.849 - ETA: 11:55 - loss: 0.4377 - accuracy: 0.848 - ETA: 11:41 - loss: 0.4369 - accuracy: 0.848 - ETA: 11:28 - loss: 0.4336 - accuracy: 0.848 - ETA: 11:14 - loss: 0.4519 - accuracy: 0.845 - ETA: 11:01 - loss: 0.4553 - accuracy: 0.846 - ETA: 10:47 - loss: 0.4544 - accuracy: 0.846 - ETA: 10:34 - loss: 0.4572 - accuracy: 0.844 - ETA: 10:20 - loss: 0.4597 - accuracy: 0.845 - ETA: 10:07 - loss: 0.4589 - accuracy: 0.845 - ETA: 9:53 - loss: 0.4582 - accuracy: 0.845 - ETA: 9:39 - loss: 0.4592 - accuracy: 0.84 - ETA: 9:26 - loss: 0.4609 - accuracy: 0.84 - ETA: 9:12 - loss: 0.4581 - accuracy: 0.84 - ETA: 8:58 - loss: 0.4588 - accuracy: 0.84 - ETA: 8:45 - loss: 0.4596 - accuracy: 0.84 - ETA: 8:31 - loss: 0.4591 - accuracy: 0.84 - ETA: 8:17 - loss: 0.4577 - accuracy: 0.84 - ETA: 8:04 - loss: 0.4623 - accuracy: 0.83 - ETA: 7:50 - loss: 0.4607 - accuracy: 0.84 - ETA: 7:36 - loss: 0.4589 - accuracy: 0.84 - ETA: 7:22 - loss: 0.4553 - accuracy: 0.84 - ETA: 7:09 - loss: 0.4580 - accuracy: 0.83 - ETA: 6:55 - loss: 0.4591 - accuracy: 0.83 - ETA: 6:41 - loss: 0.4597 - accuracy: 0.83 - ETA: 6:27 - loss: 0.4589 - accuracy: 0.83 - ETA: 6:14 - loss: 0.4586 - accuracy: 0.83 - ETA: 6:00 - loss: 0.4605 - accuracy: 0.83 - ETA: 5:46 - loss: 0.4608 - accuracy: 0.83 - ETA: 5:32 - loss: 0.4667 - accuracy: 0.83 - ETA: 5:18 - loss: 0.4658 - accuracy: 0.83 - ETA: 5:05 - loss: 0.4651 - accuracy: 0.83 - ETA: 4:51 - loss: 0.4634 - accuracy: 0.83 - ETA: 4:37 - loss: 0.4615 - accuracy: 0.83 - ETA: 4:23 - loss: 0.4608 - accuracy: 0.83 - ETA: 4:09 - loss: 0.4587 - accuracy: 0.83 - ETA: 3:55 - loss: 0.4579 - accuracy: 0.83 - ETA: 3:42 - loss: 0.4560 - accuracy: 0.83 - ETA: 3:28 - loss: 0.4559 - accuracy: 0.83 - ETA: 3:14 - loss: 0.4543 - accuracy: 0.83 - ETA: 3:00 - loss: 0.4538 - accuracy: 0.83 - ETA: 2:46 - loss: 0.4556 - accuracy: 0.83 - ETA: 2:32 - loss: 0.4568 - accuracy: 0.83 - ETA: 2:18 - loss: 0.4544 - accuracy: 0.83 - ETA: 2:05 - loss: 0.4551 - accuracy: 0.83 - ETA: 1:51 - loss: 0.4549 - accuracy: 0.83 - ETA: 1:37 - loss: 0.4533 - accuracy: 0.83 - ETA: 1:23 - loss: 0.4569 - accuracy: 0.83 - ETA: 1:09 - loss: 0.4563 - accuracy: 0.83 - ETA: 55s - loss: 0.4579 - accuracy: 0.8358 - ETA: 41s - loss: 0.4560 - accuracy: 0.835 - ETA: 27s - loss: 0.4564 - accuracy: 0.835 - ETA: 13s - loss: 0.4561 - accuracy: 0.836 - ETA: 0s - loss: 0.4541 - accuracy: 0.836 - 1457s 14s/step - loss: 0.4541 - accuracy: 0.8367 - val_loss: 0.5663 - val_accuracy: 0.8043\n",
      "Epoch 12/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3454 - accuracy: 0.84 - ETA: 11:50 - loss: 0.2564 - accuracy: 0.890 - ETA: 15:39 - loss: 0.2941 - accuracy: 0.885 - ETA: 17:27 - loss: 0.3230 - accuracy: 0.875 - ETA: 18:24 - loss: 0.3237 - accuracy: 0.887 - ETA: 18:59 - loss: 0.3275 - accuracy: 0.885 - ETA: 19:19 - loss: 0.3360 - accuracy: 0.875 - ETA: 19:31 - loss: 0.3622 - accuracy: 0.875 - ETA: 19:37 - loss: 0.3840 - accuracy: 0.861 - ETA: 19:39 - loss: 0.3683 - accuracy: 0.868 - ETA: 19:38 - loss: 0.3657 - accuracy: 0.869 - ETA: 19:37 - loss: 0.3683 - accuracy: 0.872 - ETA: 19:31 - loss: 0.3629 - accuracy: 0.872 - ETA: 19:25 - loss: 0.3656 - accuracy: 0.870 - ETA: 19:17 - loss: 0.3636 - accuracy: 0.870 - ETA: 19:09 - loss: 0.3686 - accuracy: 0.869 - ETA: 19:02 - loss: 0.3718 - accuracy: 0.867 - ETA: 18:53 - loss: 0.3803 - accuracy: 0.864 - ETA: 18:42 - loss: 0.3705 - accuracy: 0.866 - ETA: 18:32 - loss: 0.3733 - accuracy: 0.865 - ETA: 18:18 - loss: 0.3693 - accuracy: 0.865 - ETA: 18:07 - loss: 0.3643 - accuracy: 0.866 - ETA: 17:56 - loss: 0.4853 - accuracy: 0.862 - ETA: 17:44 - loss: 0.4767 - accuracy: 0.864 - ETA: 17:33 - loss: 0.4738 - accuracy: 0.863 - ETA: 17:21 - loss: 0.4681 - accuracy: 0.863 - ETA: 17:09 - loss: 0.4661 - accuracy: 0.863 - ETA: 16:56 - loss: 0.4551 - accuracy: 0.866 - ETA: 16:44 - loss: 0.4550 - accuracy: 0.862 - ETA: 16:32 - loss: 0.4467 - accuracy: 0.865 - ETA: 16:19 - loss: 0.4452 - accuracy: 0.863 - ETA: 16:07 - loss: 0.4457 - accuracy: 0.865 - ETA: 15:54 - loss: 0.4420 - accuracy: 0.866 - ETA: 15:42 - loss: 0.4374 - accuracy: 0.868 - ETA: 15:29 - loss: 0.4293 - accuracy: 0.870 - ETA: 15:16 - loss: 0.4269 - accuracy: 0.869 - ETA: 15:03 - loss: 0.4222 - accuracy: 0.869 - ETA: 14:50 - loss: 0.4229 - accuracy: 0.868 - ETA: 14:37 - loss: 0.4200 - accuracy: 0.870 - ETA: 14:24 - loss: 0.4169 - accuracy: 0.868 - ETA: 14:10 - loss: 0.4124 - accuracy: 0.869 - ETA: 13:57 - loss: 0.4146 - accuracy: 0.867 - ETA: 13:44 - loss: 0.4139 - accuracy: 0.867 - ETA: 13:31 - loss: 0.4228 - accuracy: 0.867 - ETA: 13:17 - loss: 0.4184 - accuracy: 0.867 - ETA: 13:04 - loss: 0.4177 - accuracy: 0.866 - ETA: 12:51 - loss: 0.4187 - accuracy: 0.864 - ETA: 12:37 - loss: 0.4156 - accuracy: 0.865 - ETA: 12:24 - loss: 0.4141 - accuracy: 0.865 - ETA: 12:10 - loss: 0.4130 - accuracy: 0.864 - ETA: 11:57 - loss: 0.4144 - accuracy: 0.863 - ETA: 11:43 - loss: 0.4146 - accuracy: 0.862 - ETA: 11:30 - loss: 0.4261 - accuracy: 0.857 - ETA: 11:16 - loss: 0.4222 - accuracy: 0.858 - ETA: 11:03 - loss: 0.4212 - accuracy: 0.858 - ETA: 10:49 - loss: 0.4194 - accuracy: 0.858 - ETA: 10:35 - loss: 0.4165 - accuracy: 0.859 - ETA: 10:22 - loss: 0.4191 - accuracy: 0.857 - ETA: 10:08 - loss: 0.4154 - accuracy: 0.858 - ETA: 9:54 - loss: 0.4147 - accuracy: 0.858 - ETA: 9:41 - loss: 0.4128 - accuracy: 0.85 - ETA: 9:27 - loss: 0.4111 - accuracy: 0.86 - ETA: 9:13 - loss: 0.4096 - accuracy: 0.86 - ETA: 9:00 - loss: 0.4115 - accuracy: 0.85 - ETA: 8:46 - loss: 0.4101 - accuracy: 0.86 - ETA: 8:32 - loss: 0.4111 - accuracy: 0.85 - ETA: 8:18 - loss: 0.4626 - accuracy: 0.85 - ETA: 8:05 - loss: 0.4667 - accuracy: 0.85 - ETA: 7:51 - loss: 0.4695 - accuracy: 0.85 - ETA: 7:37 - loss: 0.4671 - accuracy: 0.85 - ETA: 7:23 - loss: 0.4643 - accuracy: 0.85 - ETA: 7:10 - loss: 0.4646 - accuracy: 0.85 - ETA: 6:56 - loss: 0.4634 - accuracy: 0.85 - ETA: 6:42 - loss: 0.4632 - accuracy: 0.85 - ETA: 6:28 - loss: 0.4621 - accuracy: 0.85 - ETA: 6:14 - loss: 0.4607 - accuracy: 0.85 - ETA: 6:00 - loss: 0.4603 - accuracy: 0.85 - ETA: 5:47 - loss: 0.4606 - accuracy: 0.85 - ETA: 5:33 - loss: 0.4582 - accuracy: 0.85 - ETA: 5:19 - loss: 0.4571 - accuracy: 0.85 - ETA: 5:05 - loss: 0.4571 - accuracy: 0.85 - ETA: 4:51 - loss: 0.4538 - accuracy: 0.85 - ETA: 4:37 - loss: 0.4502 - accuracy: 0.85 - ETA: 4:24 - loss: 0.4501 - accuracy: 0.85 - ETA: 4:10 - loss: 0.4491 - accuracy: 0.85 - ETA: 3:56 - loss: 0.4549 - accuracy: 0.85 - ETA: 3:42 - loss: 0.4564 - accuracy: 0.85 - ETA: 3:28 - loss: 0.4555 - accuracy: 0.85 - ETA: 3:14 - loss: 0.4537 - accuracy: 0.85 - ETA: 3:00 - loss: 0.4529 - accuracy: 0.85 - ETA: 2:46 - loss: 0.4538 - accuracy: 0.85 - ETA: 2:33 - loss: 0.4526 - accuracy: 0.85 - ETA: 2:19 - loss: 0.4509 - accuracy: 0.85 - ETA: 2:05 - loss: 0.4479 - accuracy: 0.85 - ETA: 1:51 - loss: 0.4448 - accuracy: 0.85 - ETA: 1:37 - loss: 0.4451 - accuracy: 0.85 - ETA: 1:23 - loss: 0.4435 - accuracy: 0.85 - ETA: 1:09 - loss: 0.4425 - accuracy: 0.85 - ETA: 55s - loss: 0.4436 - accuracy: 0.8550 - ETA: 41s - loss: 0.4427 - accuracy: 0.854 - ETA: 27s - loss: 0.4415 - accuracy: 0.855 - ETA: 13s - loss: 0.4411 - accuracy: 0.854 - ETA: 0s - loss: 0.4450 - accuracy: 0.854 - 1459s 14s/step - loss: 0.4450 - accuracy: 0.8543 - val_loss: 0.6149 - val_accuracy: 0.7690\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.81 - ETA: 11:52 - loss: 0.3315 - accuracy: 0.843 - ETA: 15:38 - loss: 0.3721 - accuracy: 0.833 - ETA: 17:23 - loss: 0.3612 - accuracy: 0.843 - ETA: 18:23 - loss: 0.3644 - accuracy: 0.843 - ETA: 18:58 - loss: 0.3624 - accuracy: 0.843 - ETA: 19:19 - loss: 0.3484 - accuracy: 0.852 - ETA: 19:30 - loss: 0.3962 - accuracy: 0.835 - ETA: 19:36 - loss: 0.3865 - accuracy: 0.836 - ETA: 19:38 - loss: 0.3762 - accuracy: 0.846 - ETA: 19:37 - loss: 0.3649 - accuracy: 0.852 - ETA: 19:33 - loss: 0.3784 - accuracy: 0.846 - ETA: 19:28 - loss: 0.3789 - accuracy: 0.843 - ETA: 19:22 - loss: 0.3867 - accuracy: 0.841 - ETA: 19:15 - loss: 0.3754 - accuracy: 0.847 - ETA: 19:07 - loss: 0.3762 - accuracy: 0.851 - ETA: 18:58 - loss: 0.3682 - accuracy: 0.858 - ETA: 18:49 - loss: 0.3690 - accuracy: 0.859 - ETA: 18:39 - loss: 0.3664 - accuracy: 0.863 - ETA: 18:28 - loss: 0.3734 - accuracy: 0.864 - ETA: 18:18 - loss: 0.3841 - accuracy: 0.861 - ETA: 18:07 - loss: 0.3743 - accuracy: 0.866 - ETA: 17:56 - loss: 0.3672 - accuracy: 0.868 - ETA: 17:44 - loss: 0.3618 - accuracy: 0.868 - ETA: 17:32 - loss: 0.3750 - accuracy: 0.866 - ETA: 17:20 - loss: 0.3704 - accuracy: 0.869 - ETA: 17:08 - loss: 0.3686 - accuracy: 0.869 - ETA: 16:56 - loss: 0.3620 - accuracy: 0.871 - ETA: 16:44 - loss: 0.3626 - accuracy: 0.868 - ETA: 16:31 - loss: 0.3554 - accuracy: 0.870 - ETA: 16:19 - loss: 0.3515 - accuracy: 0.873 - ETA: 16:06 - loss: 0.3493 - accuracy: 0.873 - ETA: 15:53 - loss: 0.3514 - accuracy: 0.873 - ETA: 15:41 - loss: 0.3502 - accuracy: 0.872 - ETA: 15:28 - loss: 0.3454 - accuracy: 0.874 - ETA: 15:15 - loss: 0.3439 - accuracy: 0.874 - ETA: 15:02 - loss: 0.3421 - accuracy: 0.875 - ETA: 14:49 - loss: 0.3397 - accuracy: 0.875 - ETA: 14:36 - loss: 0.3396 - accuracy: 0.875 - ETA: 14:23 - loss: 0.3361 - accuracy: 0.877 - ETA: 14:10 - loss: 0.3333 - accuracy: 0.878 - ETA: 13:57 - loss: 0.3327 - accuracy: 0.879 - ETA: 13:44 - loss: 0.3294 - accuracy: 0.880 - ETA: 13:30 - loss: 0.3284 - accuracy: 0.880 - ETA: 13:17 - loss: 0.3358 - accuracy: 0.877 - ETA: 13:04 - loss: 0.3337 - accuracy: 0.878 - ETA: 12:50 - loss: 0.3344 - accuracy: 0.878 - ETA: 12:36 - loss: 0.3343 - accuracy: 0.878 - ETA: 12:23 - loss: 0.3332 - accuracy: 0.878 - ETA: 12:09 - loss: 0.3334 - accuracy: 0.878 - ETA: 11:56 - loss: 0.3313 - accuracy: 0.877 - ETA: 11:42 - loss: 0.3297 - accuracy: 0.877 - ETA: 11:29 - loss: 0.3297 - accuracy: 0.878 - ETA: 11:15 - loss: 0.3341 - accuracy: 0.876 - ETA: 11:01 - loss: 0.3320 - accuracy: 0.876 - ETA: 10:48 - loss: 0.3310 - accuracy: 0.876 - ETA: 10:34 - loss: 0.3314 - accuracy: 0.876 - ETA: 10:21 - loss: 0.3713 - accuracy: 0.876 - ETA: 10:07 - loss: 0.3689 - accuracy: 0.877 - ETA: 9:53 - loss: 0.3678 - accuracy: 0.877 - ETA: 9:40 - loss: 0.3678 - accuracy: 0.87 - ETA: 9:26 - loss: 0.3698 - accuracy: 0.87 - ETA: 9:12 - loss: 0.3683 - accuracy: 0.87 - ETA: 8:59 - loss: 0.3665 - accuracy: 0.87 - ETA: 8:45 - loss: 0.3650 - accuracy: 0.87 - ETA: 8:31 - loss: 0.3633 - accuracy: 0.87 - ETA: 8:18 - loss: 0.3605 - accuracy: 0.87 - ETA: 8:04 - loss: 0.3600 - accuracy: 0.87 - ETA: 7:50 - loss: 0.3615 - accuracy: 0.87 - ETA: 7:36 - loss: 0.3621 - accuracy: 0.87 - ETA: 7:23 - loss: 0.3643 - accuracy: 0.87 - ETA: 7:09 - loss: 0.3629 - accuracy: 0.87 - ETA: 6:55 - loss: 0.3613 - accuracy: 0.87 - ETA: 6:41 - loss: 0.3601 - accuracy: 0.87 - ETA: 6:28 - loss: 0.3602 - accuracy: 0.87 - ETA: 6:14 - loss: 0.3615 - accuracy: 0.87 - ETA: 6:00 - loss: 0.3608 - accuracy: 0.87 - ETA: 5:46 - loss: 0.3593 - accuracy: 0.87 - ETA: 5:32 - loss: 0.3607 - accuracy: 0.87 - ETA: 5:19 - loss: 0.3590 - accuracy: 0.87 - ETA: 5:05 - loss: 0.3581 - accuracy: 0.87 - ETA: 4:51 - loss: 0.3559 - accuracy: 0.87 - ETA: 4:37 - loss: 0.3555 - accuracy: 0.87 - ETA: 4:23 - loss: 0.3544 - accuracy: 0.87 - ETA: 4:09 - loss: 0.3531 - accuracy: 0.87 - ETA: 3:56 - loss: 0.3536 - accuracy: 0.87 - ETA: 3:42 - loss: 0.3522 - accuracy: 0.87 - ETA: 3:28 - loss: 0.3545 - accuracy: 0.87 - ETA: 3:14 - loss: 0.3555 - accuracy: 0.87 - ETA: 3:00 - loss: 0.3532 - accuracy: 0.87 - ETA: 2:46 - loss: 0.3522 - accuracy: 0.87 - ETA: 2:32 - loss: 0.3537 - accuracy: 0.87 - ETA: 2:18 - loss: 0.3521 - accuracy: 0.87 - ETA: 2:05 - loss: 0.3537 - accuracy: 0.87 - ETA: 1:51 - loss: 0.3520 - accuracy: 0.87 - ETA: 1:37 - loss: 0.3522 - accuracy: 0.87 - ETA: 1:23 - loss: 0.3496 - accuracy: 0.87 - ETA: 1:09 - loss: 0.3477 - accuracy: 0.87 - ETA: 55s - loss: 0.3498 - accuracy: 0.8743 - ETA: 41s - loss: 0.3501 - accuracy: 0.874 - ETA: 27s - loss: 0.3493 - accuracy: 0.874 - ETA: 13s - loss: 0.3486 - accuracy: 0.874 - ETA: 0s - loss: 0.3516 - accuracy: 0.873 - 1457s 14s/step - loss: 0.3516 - accuracy: 0.8737 - val_loss: 0.5662 - val_accuracy: 0.8288\n",
      "Epoch 14/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.93 - ETA: 11:50 - loss: 0.2852 - accuracy: 0.921 - ETA: 15:38 - loss: 0.2419 - accuracy: 0.937 - ETA: 17:23 - loss: 0.2034 - accuracy: 0.953 - ETA: 18:24 - loss: 0.2150 - accuracy: 0.943 - ETA: 18:57 - loss: 0.2673 - accuracy: 0.916 - ETA: 19:19 - loss: 0.2688 - accuracy: 0.919 - ETA: 19:30 - loss: 0.2521 - accuracy: 0.929 - ETA: 19:37 - loss: 0.2716 - accuracy: 0.923 - ETA: 19:39 - loss: 0.2570 - accuracy: 0.925 - ETA: 19:38 - loss: 0.2487 - accuracy: 0.929 - ETA: 19:35 - loss: 0.2539 - accuracy: 0.924 - ETA: 19:30 - loss: 0.2502 - accuracy: 0.925 - ETA: 19:24 - loss: 0.2431 - accuracy: 0.928 - ETA: 19:17 - loss: 0.2608 - accuracy: 0.922 - ETA: 19:09 - loss: 0.2586 - accuracy: 0.921 - ETA: 19:00 - loss: 0.2537 - accuracy: 0.922 - ETA: 18:50 - loss: 0.2459 - accuracy: 0.925 - ETA: 18:40 - loss: 0.2433 - accuracy: 0.924 - ETA: 18:30 - loss: 0.2507 - accuracy: 0.917 - ETA: 18:20 - loss: 0.2476 - accuracy: 0.918 - ETA: 18:09 - loss: 0.2443 - accuracy: 0.920 - ETA: 17:58 - loss: 0.2398 - accuracy: 0.922 - ETA: 17:46 - loss: 0.2367 - accuracy: 0.925 - ETA: 17:35 - loss: 0.2348 - accuracy: 0.926 - ETA: 17:23 - loss: 0.2338 - accuracy: 0.925 - ETA: 17:11 - loss: 0.2358 - accuracy: 0.923 - ETA: 16:58 - loss: 0.2337 - accuracy: 0.924 - ETA: 16:47 - loss: 0.2327 - accuracy: 0.924 - ETA: 16:34 - loss: 0.2352 - accuracy: 0.921 - ETA: 16:21 - loss: 0.2406 - accuracy: 0.918 - ETA: 16:09 - loss: 0.2358 - accuracy: 0.919 - ETA: 15:56 - loss: 0.2412 - accuracy: 0.917 - ETA: 15:43 - loss: 0.2397 - accuracy: 0.916 - ETA: 15:30 - loss: 0.2456 - accuracy: 0.915 - ETA: 15:17 - loss: 0.2493 - accuracy: 0.914 - ETA: 15:04 - loss: 0.2521 - accuracy: 0.913 - ETA: 14:51 - loss: 0.2530 - accuracy: 0.912 - ETA: 14:38 - loss: 0.2512 - accuracy: 0.912 - ETA: 14:25 - loss: 0.2487 - accuracy: 0.913 - ETA: 14:12 - loss: 0.2462 - accuracy: 0.913 - ETA: 13:58 - loss: 0.2437 - accuracy: 0.915 - ETA: 13:45 - loss: 0.2537 - accuracy: 0.911 - ETA: 13:32 - loss: 0.2518 - accuracy: 0.911 - ETA: 13:18 - loss: 0.2508 - accuracy: 0.911 - ETA: 13:05 - loss: 0.2509 - accuracy: 0.911 - ETA: 12:52 - loss: 0.2521 - accuracy: 0.909 - ETA: 12:38 - loss: 0.2502 - accuracy: 0.910 - ETA: 12:25 - loss: 0.2518 - accuracy: 0.910 - ETA: 12:11 - loss: 0.2529 - accuracy: 0.908 - ETA: 11:57 - loss: 0.2503 - accuracy: 0.909 - ETA: 11:44 - loss: 0.2483 - accuracy: 0.911 - ETA: 11:30 - loss: 0.2499 - accuracy: 0.910 - ETA: 11:17 - loss: 0.2464 - accuracy: 0.912 - ETA: 11:03 - loss: 0.2490 - accuracy: 0.910 - ETA: 10:49 - loss: 0.2488 - accuracy: 0.911 - ETA: 10:36 - loss: 0.2474 - accuracy: 0.910 - ETA: 10:22 - loss: 0.2548 - accuracy: 0.909 - ETA: 10:09 - loss: 0.2549 - accuracy: 0.907 - ETA: 9:55 - loss: 0.2549 - accuracy: 0.908 - ETA: 9:41 - loss: 0.2542 - accuracy: 0.90 - ETA: 9:28 - loss: 0.2511 - accuracy: 0.91 - ETA: 9:14 - loss: 0.2524 - accuracy: 0.91 - ETA: 9:00 - loss: 0.2552 - accuracy: 0.90 - ETA: 8:47 - loss: 0.2567 - accuracy: 0.90 - ETA: 8:32 - loss: 0.2550 - accuracy: 0.90 - ETA: 8:19 - loss: 0.2553 - accuracy: 0.90 - ETA: 8:05 - loss: 0.2570 - accuracy: 0.90 - ETA: 7:51 - loss: 0.2580 - accuracy: 0.90 - ETA: 7:37 - loss: 0.2627 - accuracy: 0.90 - ETA: 7:24 - loss: 0.2613 - accuracy: 0.90 - ETA: 7:10 - loss: 0.2618 - accuracy: 0.90 - ETA: 6:56 - loss: 0.2620 - accuracy: 0.90 - ETA: 6:42 - loss: 0.2637 - accuracy: 0.90 - ETA: 6:28 - loss: 0.2644 - accuracy: 0.90 - ETA: 6:15 - loss: 0.2639 - accuracy: 0.90 - ETA: 6:01 - loss: 0.2624 - accuracy: 0.90 - ETA: 5:47 - loss: 0.2655 - accuracy: 0.90 - ETA: 5:33 - loss: 0.2671 - accuracy: 0.90 - ETA: 5:19 - loss: 0.2684 - accuracy: 0.90 - ETA: 5:05 - loss: 0.2677 - accuracy: 0.90 - ETA: 4:51 - loss: 0.2677 - accuracy: 0.90 - ETA: 4:38 - loss: 0.2686 - accuracy: 0.90 - ETA: 4:24 - loss: 0.2722 - accuracy: 0.89 - ETA: 4:10 - loss: 0.2754 - accuracy: 0.89 - ETA: 3:56 - loss: 0.2744 - accuracy: 0.89 - ETA: 3:42 - loss: 0.2789 - accuracy: 0.89 - ETA: 3:28 - loss: 0.2787 - accuracy: 0.89 - ETA: 3:14 - loss: 0.2793 - accuracy: 0.89 - ETA: 3:00 - loss: 0.2799 - accuracy: 0.89 - ETA: 2:47 - loss: 0.2800 - accuracy: 0.89 - ETA: 2:33 - loss: 0.2807 - accuracy: 0.89 - ETA: 2:19 - loss: 0.2811 - accuracy: 0.89 - ETA: 2:05 - loss: 0.2822 - accuracy: 0.89 - ETA: 1:51 - loss: 0.2828 - accuracy: 0.89 - ETA: 1:37 - loss: 0.2831 - accuracy: 0.89 - ETA: 1:23 - loss: 0.2876 - accuracy: 0.89 - ETA: 1:09 - loss: 0.2886 - accuracy: 0.89 - ETA: 55s - loss: 0.2883 - accuracy: 0.8936 - ETA: 41s - loss: 0.2882 - accuracy: 0.893 - ETA: 27s - loss: 0.2899 - accuracy: 0.892 - ETA: 13s - loss: 0.2905 - accuracy: 0.893 - ETA: 0s - loss: 0.2899 - accuracy: 0.893 - 1460s 14s/step - loss: 0.2899 - accuracy: 0.8931 - val_loss: 0.6282 - val_accuracy: 0.7935\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.87 - ETA: 11:44 - loss: 0.2675 - accuracy: 0.859 - ETA: 15:32 - loss: 0.3300 - accuracy: 0.833 - ETA: 17:19 - loss: 0.2909 - accuracy: 0.859 - ETA: 18:19 - loss: 0.3350 - accuracy: 0.843 - ETA: 18:54 - loss: 0.3157 - accuracy: 0.854 - ETA: 19:14 - loss: 0.3165 - accuracy: 0.866 - ETA: 19:26 - loss: 0.3109 - accuracy: 0.867 - ETA: 19:34 - loss: 0.3045 - accuracy: 0.875 - ETA: 19:37 - loss: 0.2983 - accuracy: 0.881 - ETA: 19:36 - loss: 0.3086 - accuracy: 0.880 - ETA: 19:33 - loss: 0.3102 - accuracy: 0.880 - ETA: 19:28 - loss: 0.3001 - accuracy: 0.887 - ETA: 19:22 - loss: 0.3106 - accuracy: 0.881 - ETA: 19:15 - loss: 0.3030 - accuracy: 0.885 - ETA: 19:08 - loss: 0.2952 - accuracy: 0.888 - ETA: 18:59 - loss: 0.2917 - accuracy: 0.891 - ETA: 18:50 - loss: 0.3005 - accuracy: 0.888 - ETA: 18:40 - loss: 0.2958 - accuracy: 0.888 - ETA: 18:29 - loss: 0.2885 - accuracy: 0.890 - ETA: 18:19 - loss: 0.2785 - accuracy: 0.894 - ETA: 18:08 - loss: 0.2741 - accuracy: 0.896 - ETA: 17:56 - loss: 0.2667 - accuracy: 0.899 - ETA: 17:45 - loss: 0.2700 - accuracy: 0.899 - ETA: 17:34 - loss: 0.2672 - accuracy: 0.900 - ETA: 17:23 - loss: 0.3482 - accuracy: 0.899 - ETA: 17:10 - loss: 0.3406 - accuracy: 0.902 - ETA: 16:59 - loss: 0.3372 - accuracy: 0.905 - ETA: 16:46 - loss: 0.3288 - accuracy: 0.907 - ETA: 16:34 - loss: 0.3306 - accuracy: 0.905 - ETA: 16:21 - loss: 0.3299 - accuracy: 0.906 - ETA: 16:08 - loss: 0.3239 - accuracy: 0.907 - ETA: 15:55 - loss: 0.3227 - accuracy: 0.907 - ETA: 15:42 - loss: 0.3399 - accuracy: 0.904 - ETA: 15:30 - loss: 0.3505 - accuracy: 0.898 - ETA: 15:17 - loss: 0.3522 - accuracy: 0.896 - ETA: 15:04 - loss: 0.3642 - accuracy: 0.891 - ETA: 14:51 - loss: 0.3701 - accuracy: 0.890 - ETA: 14:37 - loss: 0.3726 - accuracy: 0.888 - ETA: 14:24 - loss: 0.3768 - accuracy: 0.885 - ETA: 14:11 - loss: 0.3796 - accuracy: 0.884 - ETA: 13:58 - loss: 0.3790 - accuracy: 0.883 - ETA: 13:45 - loss: 0.3776 - accuracy: 0.882 - ETA: 13:31 - loss: 0.3860 - accuracy: 0.879 - ETA: 13:18 - loss: 0.3894 - accuracy: 0.878 - ETA: 13:05 - loss: 0.4039 - accuracy: 0.873 - ETA: 12:51 - loss: 0.4094 - accuracy: 0.869 - ETA: 12:38 - loss: 0.4163 - accuracy: 0.867 - ETA: 12:24 - loss: 0.4223 - accuracy: 0.866 - ETA: 12:11 - loss: 0.4239 - accuracy: 0.863 - ETA: 11:57 - loss: 0.4307 - accuracy: 0.860 - ETA: 11:44 - loss: 0.4459 - accuracy: 0.859 - ETA: 11:30 - loss: 0.4458 - accuracy: 0.859 - ETA: 11:17 - loss: 0.4450 - accuracy: 0.858 - ETA: 11:03 - loss: 0.4481 - accuracy: 0.857 - ETA: 10:50 - loss: 0.4458 - accuracy: 0.858 - ETA: 10:36 - loss: 0.4478 - accuracy: 0.856 - ETA: 10:22 - loss: 0.4457 - accuracy: 0.857 - ETA: 10:09 - loss: 0.4451 - accuracy: 0.857 - ETA: 9:55 - loss: 0.4425 - accuracy: 0.857 - ETA: 9:41 - loss: 0.4463 - accuracy: 0.85 - ETA: 9:28 - loss: 0.4446 - accuracy: 0.85 - ETA: 9:14 - loss: 0.4440 - accuracy: 0.85 - ETA: 9:00 - loss: 0.4414 - accuracy: 0.85 - ETA: 8:46 - loss: 0.4436 - accuracy: 0.85 - ETA: 8:33 - loss: 0.4442 - accuracy: 0.85 - ETA: 8:19 - loss: 0.4446 - accuracy: 0.85 - ETA: 8:05 - loss: 0.4421 - accuracy: 0.85 - ETA: 7:51 - loss: 0.4463 - accuracy: 0.85 - ETA: 7:38 - loss: 0.4515 - accuracy: 0.84 - ETA: 7:24 - loss: 0.4504 - accuracy: 0.84 - ETA: 7:10 - loss: 0.4504 - accuracy: 0.84 - ETA: 6:56 - loss: 0.4495 - accuracy: 0.84 - ETA: 6:42 - loss: 0.4528 - accuracy: 0.84 - ETA: 6:28 - loss: 0.4510 - accuracy: 0.84 - ETA: 6:15 - loss: 0.4495 - accuracy: 0.84 - ETA: 6:01 - loss: 0.4497 - accuracy: 0.84 - ETA: 5:47 - loss: 0.4515 - accuracy: 0.84 - ETA: 5:33 - loss: 0.4506 - accuracy: 0.84 - ETA: 5:19 - loss: 0.4502 - accuracy: 0.84 - ETA: 5:05 - loss: 0.4482 - accuracy: 0.84 - ETA: 4:52 - loss: 0.4475 - accuracy: 0.84 - ETA: 4:38 - loss: 0.4464 - accuracy: 0.84 - ETA: 4:24 - loss: 0.4471 - accuracy: 0.84 - ETA: 4:10 - loss: 0.4460 - accuracy: 0.84 - ETA: 3:56 - loss: 0.4454 - accuracy: 0.84 - ETA: 3:42 - loss: 0.4437 - accuracy: 0.84 - ETA: 3:28 - loss: 0.4460 - accuracy: 0.84 - ETA: 3:14 - loss: 0.4461 - accuracy: 0.84 - ETA: 3:00 - loss: 0.4453 - accuracy: 0.84 - ETA: 2:46 - loss: 0.4446 - accuracy: 0.84 - ETA: 2:33 - loss: 0.4420 - accuracy: 0.84 - ETA: 2:19 - loss: 0.4454 - accuracy: 0.84 - ETA: 2:05 - loss: 0.4438 - accuracy: 0.84 - ETA: 1:51 - loss: 0.4409 - accuracy: 0.84 - ETA: 1:37 - loss: 0.4414 - accuracy: 0.84 - ETA: 1:23 - loss: 0.4399 - accuracy: 0.84 - ETA: 1:09 - loss: 0.4382 - accuracy: 0.85 - ETA: 55s - loss: 0.4381 - accuracy: 0.8497 - ETA: 41s - loss: 0.4356 - accuracy: 0.850 - ETA: 27s - loss: 0.4393 - accuracy: 0.849 - ETA: 13s - loss: 0.4408 - accuracy: 0.848 - ETA: 0s - loss: 0.4410 - accuracy: 0.847 - 1460s 14s/step - loss: 0.4410 - accuracy: 0.8479 - val_loss: 0.6153 - val_accuracy: 0.8098\n",
      "Epoch 16/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.75 - ETA: 11:50 - loss: 0.4635 - accuracy: 0.750 - ETA: 15:37 - loss: 0.7031 - accuracy: 0.781 - ETA: 17:22 - loss: 0.6220 - accuracy: 0.812 - ETA: 18:20 - loss: 1.2661 - accuracy: 0.818 - ETA: 18:54 - loss: 1.0930 - accuracy: 0.838 - ETA: 19:15 - loss: 0.9867 - accuracy: 0.848 - ETA: 19:27 - loss: 0.8984 - accuracy: 0.851 - ETA: 19:33 - loss: 0.8250 - accuracy: 0.857 - ETA: 19:34 - loss: 0.7812 - accuracy: 0.859 - ETA: 19:33 - loss: 0.7220 - accuracy: 0.869 - ETA: 19:30 - loss: 0.7341 - accuracy: 0.859 - ETA: 19:26 - loss: 0.7111 - accuracy: 0.860 - ETA: 19:20 - loss: 0.7385 - accuracy: 0.859 - ETA: 19:13 - loss: 0.7067 - accuracy: 0.862 - ETA: 19:05 - loss: 0.6995 - accuracy: 0.859 - ETA: 18:56 - loss: 0.6715 - accuracy: 0.864 - ETA: 18:47 - loss: 0.6496 - accuracy: 0.864 - ETA: 18:38 - loss: 0.6708 - accuracy: 0.858 - ETA: 18:27 - loss: 0.6825 - accuracy: 0.851 - ETA: 18:17 - loss: 0.6641 - accuracy: 0.854 - ETA: 18:06 - loss: 0.6782 - accuracy: 0.850 - ETA: 17:55 - loss: 0.7075 - accuracy: 0.847 - ETA: 17:44 - loss: 0.6958 - accuracy: 0.850 - ETA: 17:32 - loss: 0.7164 - accuracy: 0.846 - ETA: 17:20 - loss: 0.9652 - accuracy: 0.843 - ETA: 17:08 - loss: 1.1054 - accuracy: 0.842 - ETA: 16:56 - loss: 1.0845 - accuracy: 0.842 - ETA: 16:44 - loss: 1.1197 - accuracy: 0.835 - ETA: 16:31 - loss: 1.0996 - accuracy: 0.834 - ETA: 16:17 - loss: 1.0832 - accuracy: 0.834 - ETA: 16:05 - loss: 1.0721 - accuracy: 0.829 - ETA: 15:52 - loss: 1.0757 - accuracy: 0.829 - ETA: 15:39 - loss: 1.0629 - accuracy: 0.825 - ETA: 15:26 - loss: 1.0482 - accuracy: 0.826 - ETA: 15:13 - loss: 1.0462 - accuracy: 0.820 - ETA: 15:01 - loss: 1.0342 - accuracy: 0.820 - ETA: 14:48 - loss: 1.0226 - accuracy: 0.818 - ETA: 14:35 - loss: 1.0160 - accuracy: 0.814 - ETA: 14:22 - loss: 1.0095 - accuracy: 0.810 - ETA: 14:09 - loss: 0.9974 - accuracy: 0.811 - ETA: 13:55 - loss: 0.9866 - accuracy: 0.809 - ETA: 13:42 - loss: 0.9768 - accuracy: 0.810 - ETA: 13:29 - loss: 0.9736 - accuracy: 0.808 - ETA: 13:16 - loss: 0.9712 - accuracy: 0.804 - ETA: 13:03 - loss: 0.9616 - accuracy: 0.804 - ETA: 12:49 - loss: 0.9579 - accuracy: 0.802 - ETA: 12:36 - loss: 0.9541 - accuracy: 0.801 - ETA: 12:23 - loss: 0.9491 - accuracy: 0.798 - ETA: 12:10 - loss: 0.9429 - accuracy: 0.798 - ETA: 11:56 - loss: 0.9352 - accuracy: 0.798 - ETA: 11:43 - loss: 0.9280 - accuracy: 0.797 - ETA: 11:29 - loss: 0.9227 - accuracy: 0.796 - ETA: 11:15 - loss: 0.9165 - accuracy: 0.796 - ETA: 11:02 - loss: 0.9121 - accuracy: 0.795 - ETA: 10:48 - loss: 0.9075 - accuracy: 0.795 - ETA: 10:35 - loss: 0.9009 - accuracy: 0.794 - ETA: 10:21 - loss: 0.8939 - accuracy: 0.795 - ETA: 10:08 - loss: 0.8878 - accuracy: 0.795 - ETA: 9:54 - loss: 0.8825 - accuracy: 0.796 - ETA: 9:40 - loss: 0.8775 - accuracy: 0.79 - ETA: 9:27 - loss: 0.8747 - accuracy: 0.79 - ETA: 9:13 - loss: 0.8683 - accuracy: 0.79 - ETA: 8:59 - loss: 0.8648 - accuracy: 0.79 - ETA: 8:46 - loss: 0.8626 - accuracy: 0.79 - ETA: 8:32 - loss: 0.8581 - accuracy: 0.79 - ETA: 8:18 - loss: 0.8553 - accuracy: 0.79 - ETA: 8:04 - loss: 0.8544 - accuracy: 0.78 - ETA: 7:51 - loss: 0.8508 - accuracy: 0.78 - ETA: 7:37 - loss: 0.8471 - accuracy: 0.78 - ETA: 7:23 - loss: 0.8412 - accuracy: 0.79 - ETA: 7:09 - loss: 0.9182 - accuracy: 0.78 - ETA: 6:56 - loss: 0.9155 - accuracy: 0.78 - ETA: 6:42 - loss: 0.9148 - accuracy: 0.78 - ETA: 6:28 - loss: 0.9217 - accuracy: 0.78 - ETA: 6:14 - loss: 0.9153 - accuracy: 0.78 - ETA: 6:00 - loss: 0.9119 - accuracy: 0.78 - ETA: 5:47 - loss: 0.9084 - accuracy: 0.78 - ETA: 5:33 - loss: 0.9034 - accuracy: 0.78 - ETA: 5:19 - loss: 0.9004 - accuracy: 0.78 - ETA: 5:05 - loss: 0.9164 - accuracy: 0.78 - ETA: 4:51 - loss: 0.9126 - accuracy: 0.78 - ETA: 4:37 - loss: 0.9052 - accuracy: 0.78 - ETA: 4:24 - loss: 0.9013 - accuracy: 0.78 - ETA: 4:10 - loss: 0.8942 - accuracy: 0.78 - ETA: 3:56 - loss: 0.8895 - accuracy: 0.78 - ETA: 3:42 - loss: 0.8839 - accuracy: 0.78 - ETA: 3:28 - loss: 0.8954 - accuracy: 0.78 - ETA: 3:14 - loss: 0.8900 - accuracy: 0.78 - ETA: 3:00 - loss: 0.8968 - accuracy: 0.78 - ETA: 2:46 - loss: 0.8904 - accuracy: 0.79 - ETA: 2:33 - loss: 0.9229 - accuracy: 0.79 - ETA: 2:19 - loss: 0.9180 - accuracy: 0.79 - ETA: 2:05 - loss: 0.9172 - accuracy: 0.78 - ETA: 1:51 - loss: 0.9182 - accuracy: 0.78 - ETA: 1:37 - loss: 0.9161 - accuracy: 0.78 - ETA: 1:23 - loss: 0.9199 - accuracy: 0.78 - ETA: 1:09 - loss: 0.9154 - accuracy: 0.78 - ETA: 55s - loss: 0.9128 - accuracy: 0.7871 - ETA: 41s - loss: 0.9842 - accuracy: 0.785 - ETA: 27s - loss: 0.9788 - accuracy: 0.785 - ETA: 13s - loss: 0.9799 - accuracy: 0.786 - ETA: 0s - loss: 0.9743 - accuracy: 0.786 - 1459s 14s/step - loss: 0.9743 - accuracy: 0.7866 - val_loss: 2676.6052 - val_accuracy: 0.6141\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.5140 - accuracy: 0.78 - ETA: 11:48 - loss: 0.5474 - accuracy: 0.781 - ETA: 15:33 - loss: 0.5515 - accuracy: 0.802 - ETA: 17:23 - loss: 0.5365 - accuracy: 0.804 - ETA: 18:22 - loss: 0.5142 - accuracy: 0.818 - ETA: 18:56 - loss: 0.5050 - accuracy: 0.822 - ETA: 19:16 - loss: 0.5210 - accuracy: 0.821 - ETA: 19:29 - loss: 0.5120 - accuracy: 0.808 - ETA: 19:38 - loss: 0.8231 - accuracy: 0.809 - ETA: 19:39 - loss: 0.8045 - accuracy: 0.800 - ETA: 19:39 - loss: 0.7873 - accuracy: 0.795 - ETA: 19:35 - loss: 0.7694 - accuracy: 0.791 - ETA: 19:31 - loss: 0.7510 - accuracy: 0.790 - ETA: 19:24 - loss: 0.7874 - accuracy: 0.787 - ETA: 19:16 - loss: 0.7558 - accuracy: 0.795 - ETA: 19:08 - loss: 0.7466 - accuracy: 0.793 - ETA: 18:59 - loss: 0.8286 - accuracy: 0.784 - ETA: 18:50 - loss: 0.8046 - accuracy: 0.788 - ETA: 18:40 - loss: 0.7802 - accuracy: 0.792 - ETA: 18:30 - loss: 0.8575 - accuracy: 0.789 - ETA: 18:20 - loss: 0.8417 - accuracy: 0.787 - ETA: 18:09 - loss: 0.8377 - accuracy: 0.784 - ETA: 17:57 - loss: 0.8165 - accuracy: 0.788 - ETA: 17:46 - loss: 0.8134 - accuracy: 0.783 - ETA: 17:34 - loss: 0.8011 - accuracy: 0.782 - ETA: 17:22 - loss: 0.7844 - accuracy: 0.786 - ETA: 17:10 - loss: 0.7708 - accuracy: 0.788 - ETA: 16:56 - loss: 0.7618 - accuracy: 0.788 - ETA: 16:43 - loss: 0.7527 - accuracy: 0.789 - ETA: 16:31 - loss: 0.7437 - accuracy: 0.791 - ETA: 16:19 - loss: 0.7320 - accuracy: 0.792 - ETA: 16:06 - loss: 0.7241 - accuracy: 0.794 - ETA: 15:53 - loss: 0.7188 - accuracy: 0.794 - ETA: 15:41 - loss: 0.7101 - accuracy: 0.795 - ETA: 15:28 - loss: 0.7009 - accuracy: 0.797 - ETA: 15:15 - loss: 0.7092 - accuracy: 0.794 - ETA: 15:02 - loss: 0.7042 - accuracy: 0.796 - ETA: 14:49 - loss: 0.6961 - accuracy: 0.797 - ETA: 14:36 - loss: 0.6956 - accuracy: 0.795 - ETA: 14:23 - loss: 0.6963 - accuracy: 0.794 - ETA: 14:10 - loss: 0.6930 - accuracy: 0.794 - ETA: 13:57 - loss: 0.6921 - accuracy: 0.793 - ETA: 13:43 - loss: 0.6891 - accuracy: 0.794 - ETA: 13:30 - loss: 0.6835 - accuracy: 0.795 - ETA: 13:17 - loss: 0.6754 - accuracy: 0.796 - ETA: 13:03 - loss: 0.6723 - accuracy: 0.795 - ETA: 12:50 - loss: 0.6672 - accuracy: 0.796 - ETA: 12:36 - loss: 0.6601 - accuracy: 0.799 - ETA: 12:23 - loss: 0.6590 - accuracy: 0.798 - ETA: 12:10 - loss: 0.6557 - accuracy: 0.797 - ETA: 11:56 - loss: 0.6504 - accuracy: 0.798 - ETA: 11:43 - loss: 0.6446 - accuracy: 0.799 - ETA: 11:29 - loss: 0.6412 - accuracy: 0.799 - ETA: 11:16 - loss: 0.6416 - accuracy: 0.799 - ETA: 11:02 - loss: 0.6443 - accuracy: 0.798 - ETA: 10:48 - loss: 0.6504 - accuracy: 0.799 - ETA: 10:35 - loss: 0.6487 - accuracy: 0.800 - ETA: 10:21 - loss: 0.6440 - accuracy: 0.801 - ETA: 10:07 - loss: 0.6401 - accuracy: 0.801 - ETA: 9:54 - loss: 0.6350 - accuracy: 0.803 - ETA: 9:40 - loss: 0.6324 - accuracy: 0.80 - ETA: 9:26 - loss: 0.6336 - accuracy: 0.80 - ETA: 9:13 - loss: 0.6342 - accuracy: 0.80 - ETA: 8:59 - loss: 0.6325 - accuracy: 0.80 - ETA: 8:45 - loss: 0.6280 - accuracy: 0.80 - ETA: 8:32 - loss: 0.6253 - accuracy: 0.80 - ETA: 8:18 - loss: 0.6236 - accuracy: 0.80 - ETA: 8:04 - loss: 0.6206 - accuracy: 0.80 - ETA: 7:51 - loss: 0.6164 - accuracy: 0.80 - ETA: 7:37 - loss: 0.6148 - accuracy: 0.80 - ETA: 7:23 - loss: 0.6130 - accuracy: 0.80 - ETA: 7:09 - loss: 0.6133 - accuracy: 0.80 - ETA: 6:56 - loss: 0.6110 - accuracy: 0.80 - ETA: 6:42 - loss: 0.6082 - accuracy: 0.80 - ETA: 6:28 - loss: 0.6066 - accuracy: 0.80 - ETA: 6:14 - loss: 0.6075 - accuracy: 0.80 - ETA: 6:01 - loss: 0.6055 - accuracy: 0.80 - ETA: 5:47 - loss: 0.6063 - accuracy: 0.79 - ETA: 5:33 - loss: 0.6060 - accuracy: 0.79 - ETA: 5:19 - loss: 0.6025 - accuracy: 0.79 - ETA: 5:05 - loss: 0.6015 - accuracy: 0.79 - ETA: 4:51 - loss: 0.6258 - accuracy: 0.79 - ETA: 4:37 - loss: 0.6233 - accuracy: 0.79 - ETA: 4:24 - loss: 0.6224 - accuracy: 0.79 - ETA: 4:10 - loss: 0.6195 - accuracy: 0.79 - ETA: 3:56 - loss: 0.6187 - accuracy: 0.79 - ETA: 3:42 - loss: 0.6162 - accuracy: 0.80 - ETA: 3:28 - loss: 0.6143 - accuracy: 0.80 - ETA: 3:14 - loss: 0.6102 - accuracy: 0.80 - ETA: 3:00 - loss: 0.6106 - accuracy: 0.80 - ETA: 2:46 - loss: 0.6113 - accuracy: 0.80 - ETA: 2:33 - loss: 0.6080 - accuracy: 0.80 - ETA: 2:19 - loss: 0.6072 - accuracy: 0.80 - ETA: 2:05 - loss: 0.6056 - accuracy: 0.80 - ETA: 1:51 - loss: 0.6023 - accuracy: 0.80 - ETA: 1:37 - loss: 0.5992 - accuracy: 0.80 - ETA: 1:23 - loss: 0.5992 - accuracy: 0.80 - ETA: 1:09 - loss: 0.5986 - accuracy: 0.80 - ETA: 55s - loss: 0.5964 - accuracy: 0.8032 - ETA: 41s - loss: 0.5955 - accuracy: 0.803 - ETA: 27s - loss: 0.5933 - accuracy: 0.804 - ETA: 13s - loss: 0.5905 - accuracy: 0.805 - ETA: 0s - loss: 0.5892 - accuracy: 0.804 - 1459s 14s/step - loss: 0.5892 - accuracy: 0.8048 - val_loss: 0.7341 - val_accuracy: 0.7283\n",
      "Epoch 18/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.87 - ETA: 11:55 - loss: 0.4530 - accuracy: 0.859 - ETA: 15:41 - loss: 0.4029 - accuracy: 0.875 - ETA: 17:25 - loss: 0.3858 - accuracy: 0.867 - ETA: 18:23 - loss: 0.3573 - accuracy: 0.875 - ETA: 18:56 - loss: 0.3343 - accuracy: 0.875 - ETA: 19:15 - loss: 0.3322 - accuracy: 0.879 - ETA: 19:18 - loss: 0.3869 - accuracy: 0.870 - ETA: 19:25 - loss: 0.4068 - accuracy: 0.856 - ETA: 19:28 - loss: 0.4049 - accuracy: 0.849 - ETA: 19:28 - loss: 0.3933 - accuracy: 0.848 - ETA: 19:25 - loss: 0.4019 - accuracy: 0.845 - ETA: 19:22 - loss: 0.3989 - accuracy: 0.845 - ETA: 19:17 - loss: 0.3957 - accuracy: 0.845 - ETA: 19:09 - loss: 0.4028 - accuracy: 0.841 - ETA: 19:02 - loss: 0.4155 - accuracy: 0.833 - ETA: 18:54 - loss: 0.4111 - accuracy: 0.833 - ETA: 18:45 - loss: 0.4000 - accuracy: 0.841 - ETA: 18:35 - loss: 0.3982 - accuracy: 0.844 - ETA: 18:25 - loss: 0.3908 - accuracy: 0.848 - ETA: 18:15 - loss: 0.4186 - accuracy: 0.844 - ETA: 18:04 - loss: 0.4291 - accuracy: 0.840 - ETA: 17:53 - loss: 0.4259 - accuracy: 0.840 - ETA: 17:42 - loss: 0.4254 - accuracy: 0.836 - ETA: 17:31 - loss: 0.4268 - accuracy: 0.837 - ETA: 17:19 - loss: 0.4238 - accuracy: 0.836 - ETA: 17:07 - loss: 0.4271 - accuracy: 0.835 - ETA: 16:55 - loss: 0.4241 - accuracy: 0.836 - ETA: 16:43 - loss: 0.4223 - accuracy: 0.835 - ETA: 16:30 - loss: 0.4190 - accuracy: 0.839 - ETA: 16:18 - loss: 0.4201 - accuracy: 0.839 - ETA: 16:05 - loss: 0.4242 - accuracy: 0.836 - ETA: 15:53 - loss: 0.4256 - accuracy: 0.836 - ETA: 15:41 - loss: 0.4260 - accuracy: 0.837 - ETA: 15:28 - loss: 0.4206 - accuracy: 0.839 - ETA: 15:15 - loss: 0.4196 - accuracy: 0.838 - ETA: 15:02 - loss: 0.4213 - accuracy: 0.836 - ETA: 14:49 - loss: 0.4214 - accuracy: 0.836 - ETA: 14:36 - loss: 0.4233 - accuracy: 0.834 - ETA: 14:23 - loss: 0.4301 - accuracy: 0.832 - ETA: 14:10 - loss: 0.4283 - accuracy: 0.832 - ETA: 13:57 - loss: 0.4276 - accuracy: 0.831 - ETA: 13:44 - loss: 0.4246 - accuracy: 0.833 - ETA: 13:30 - loss: 0.4224 - accuracy: 0.835 - ETA: 13:17 - loss: 0.4209 - accuracy: 0.835 - ETA: 13:04 - loss: 0.4167 - accuracy: 0.837 - ETA: 12:50 - loss: 0.4196 - accuracy: 0.836 - ETA: 12:37 - loss: 0.4403 - accuracy: 0.837 - ETA: 12:23 - loss: 0.4394 - accuracy: 0.837 - ETA: 12:10 - loss: 0.4370 - accuracy: 0.838 - ETA: 11:56 - loss: 0.4446 - accuracy: 0.838 - ETA: 11:43 - loss: 0.4522 - accuracy: 0.835 - ETA: 11:29 - loss: 0.4560 - accuracy: 0.836 - ETA: 11:16 - loss: 0.4558 - accuracy: 0.836 - ETA: 11:02 - loss: 0.4574 - accuracy: 0.836 - ETA: 10:48 - loss: 0.4569 - accuracy: 0.836 - ETA: 10:35 - loss: 0.4572 - accuracy: 0.835 - ETA: 10:21 - loss: 0.4522 - accuracy: 0.837 - ETA: 10:08 - loss: 0.4530 - accuracy: 0.836 - ETA: 9:54 - loss: 0.4487 - accuracy: 0.838 - ETA: 9:40 - loss: 0.4463 - accuracy: 0.83 - ETA: 9:27 - loss: 0.4447 - accuracy: 0.83 - ETA: 9:13 - loss: 0.4408 - accuracy: 0.84 - ETA: 8:59 - loss: 0.4393 - accuracy: 0.84 - ETA: 8:46 - loss: 0.4411 - accuracy: 0.83 - ETA: 8:32 - loss: 0.4393 - accuracy: 0.84 - ETA: 8:18 - loss: 0.4372 - accuracy: 0.84 - ETA: 8:04 - loss: 0.4342 - accuracy: 0.84 - ETA: 7:51 - loss: 0.4333 - accuracy: 0.84 - ETA: 7:37 - loss: 0.4296 - accuracy: 0.84 - ETA: 7:23 - loss: 0.4269 - accuracy: 0.84 - ETA: 7:09 - loss: 0.4245 - accuracy: 0.84 - ETA: 6:56 - loss: 0.4226 - accuracy: 0.84 - ETA: 6:42 - loss: 0.4221 - accuracy: 0.84 - ETA: 6:28 - loss: 0.4270 - accuracy: 0.84 - ETA: 6:14 - loss: 0.4260 - accuracy: 0.84 - ETA: 6:00 - loss: 0.4285 - accuracy: 0.84 - ETA: 5:47 - loss: 0.4275 - accuracy: 0.84 - ETA: 5:33 - loss: 0.4293 - accuracy: 0.84 - ETA: 5:19 - loss: 0.4303 - accuracy: 0.84 - ETA: 5:05 - loss: 0.4338 - accuracy: 0.84 - ETA: 4:51 - loss: 0.4306 - accuracy: 0.84 - ETA: 4:37 - loss: 0.4280 - accuracy: 0.84 - ETA: 4:24 - loss: 0.4301 - accuracy: 0.84 - ETA: 4:10 - loss: 0.4300 - accuracy: 0.84 - ETA: 3:56 - loss: 0.4302 - accuracy: 0.84 - ETA: 3:42 - loss: 0.4286 - accuracy: 0.84 - ETA: 3:28 - loss: 0.4270 - accuracy: 0.84 - ETA: 3:14 - loss: 0.4295 - accuracy: 0.84 - ETA: 3:00 - loss: 0.4292 - accuracy: 0.84 - ETA: 2:46 - loss: 0.4262 - accuracy: 0.84 - ETA: 2:33 - loss: 0.4239 - accuracy: 0.84 - ETA: 2:19 - loss: 0.4216 - accuracy: 0.85 - ETA: 2:05 - loss: 0.4222 - accuracy: 0.85 - ETA: 1:51 - loss: 0.4210 - accuracy: 0.85 - ETA: 1:37 - loss: 0.4212 - accuracy: 0.85 - ETA: 1:23 - loss: 0.4189 - accuracy: 0.85 - ETA: 1:09 - loss: 0.4204 - accuracy: 0.85 - ETA: 55s - loss: 0.4203 - accuracy: 0.8512 - ETA: 41s - loss: 0.4189 - accuracy: 0.851 - ETA: 27s - loss: 0.4188 - accuracy: 0.851 - ETA: 13s - loss: 0.4189 - accuracy: 0.851 - ETA: 0s - loss: 0.4181 - accuracy: 0.851 - 1460s 14s/step - loss: 0.4181 - accuracy: 0.8519 - val_loss: 0.5837 - val_accuracy: 0.7853\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.1153 - accuracy: 1.00 - ETA: 11:51 - loss: 0.1265 - accuracy: 0.984 - ETA: 15:40 - loss: 0.2031 - accuracy: 0.947 - ETA: 17:24 - loss: 0.3001 - accuracy: 0.921 - ETA: 18:25 - loss: 0.2993 - accuracy: 0.912 - ETA: 19:00 - loss: 0.2887 - accuracy: 0.906 - ETA: 19:19 - loss: 0.2778 - accuracy: 0.910 - ETA: 19:32 - loss: 0.2800 - accuracy: 0.902 - ETA: 19:38 - loss: 0.2913 - accuracy: 0.892 - ETA: 19:40 - loss: 0.3006 - accuracy: 0.890 - ETA: 19:38 - loss: 0.2836 - accuracy: 0.897 - ETA: 19:35 - loss: 0.2717 - accuracy: 0.901 - ETA: 19:29 - loss: 0.2586 - accuracy: 0.906 - ETA: 19:23 - loss: 0.2647 - accuracy: 0.897 - ETA: 19:16 - loss: 0.2632 - accuracy: 0.897 - ETA: 19:08 - loss: 0.2714 - accuracy: 0.894 - ETA: 18:59 - loss: 0.2634 - accuracy: 0.897 - ETA: 18:50 - loss: 0.2749 - accuracy: 0.888 - ETA: 18:40 - loss: 0.2977 - accuracy: 0.879 - ETA: 18:29 - loss: 0.2977 - accuracy: 0.882 - ETA: 18:18 - loss: 0.3037 - accuracy: 0.882 - ETA: 18:08 - loss: 0.3086 - accuracy: 0.882 - ETA: 17:57 - loss: 0.3068 - accuracy: 0.883 - ETA: 17:46 - loss: 0.3217 - accuracy: 0.881 - ETA: 17:34 - loss: 0.3280 - accuracy: 0.877 - ETA: 17:22 - loss: 0.3362 - accuracy: 0.872 - ETA: 17:10 - loss: 0.3327 - accuracy: 0.873 - ETA: 16:58 - loss: 0.3367 - accuracy: 0.871 - ETA: 16:46 - loss: 0.3386 - accuracy: 0.869 - ETA: 16:33 - loss: 0.3373 - accuracy: 0.869 - ETA: 16:21 - loss: 0.3412 - accuracy: 0.869 - ETA: 16:08 - loss: 0.3483 - accuracy: 0.868 - ETA: 15:55 - loss: 0.3511 - accuracy: 0.865 - ETA: 15:42 - loss: 0.3496 - accuracy: 0.864 - ETA: 15:29 - loss: 0.3505 - accuracy: 0.866 - ETA: 15:16 - loss: 0.3446 - accuracy: 0.869 - ETA: 15:03 - loss: 0.3422 - accuracy: 0.871 - ETA: 14:51 - loss: 0.3515 - accuracy: 0.869 - ETA: 14:36 - loss: 0.3533 - accuracy: 0.867 - ETA: 14:23 - loss: 0.3502 - accuracy: 0.868 - ETA: 14:10 - loss: 0.3494 - accuracy: 0.867 - ETA: 13:57 - loss: 0.3498 - accuracy: 0.867 - ETA: 13:44 - loss: 0.3462 - accuracy: 0.869 - ETA: 13:30 - loss: 0.3478 - accuracy: 0.868 - ETA: 13:17 - loss: 0.3492 - accuracy: 0.867 - ETA: 13:04 - loss: 0.3553 - accuracy: 0.866 - ETA: 12:51 - loss: 0.3518 - accuracy: 0.867 - ETA: 12:38 - loss: 0.3509 - accuracy: 0.867 - ETA: 12:24 - loss: 0.3504 - accuracy: 0.867 - ETA: 12:11 - loss: 0.3499 - accuracy: 0.866 - ETA: 11:57 - loss: 0.3461 - accuracy: 0.868 - ETA: 11:44 - loss: 0.3473 - accuracy: 0.869 - ETA: 11:30 - loss: 0.3458 - accuracy: 0.870 - ETA: 11:17 - loss: 0.3420 - accuracy: 0.872 - ETA: 11:03 - loss: 0.3461 - accuracy: 0.870 - ETA: 10:49 - loss: 0.3504 - accuracy: 0.869 - ETA: 10:36 - loss: 0.3481 - accuracy: 0.870 - ETA: 10:22 - loss: 0.3486 - accuracy: 0.869 - ETA: 10:09 - loss: 0.3513 - accuracy: 0.869 - ETA: 9:55 - loss: 0.3485 - accuracy: 0.870 - ETA: 9:41 - loss: 0.3478 - accuracy: 0.87 - ETA: 9:28 - loss: 0.3459 - accuracy: 0.87 - ETA: 9:14 - loss: 0.3471 - accuracy: 0.87 - ETA: 9:00 - loss: 0.3459 - accuracy: 0.87 - ETA: 8:46 - loss: 0.3456 - accuracy: 0.87 - ETA: 8:33 - loss: 0.3452 - accuracy: 0.87 - ETA: 8:19 - loss: 0.3447 - accuracy: 0.87 - ETA: 8:05 - loss: 0.3433 - accuracy: 0.87 - ETA: 7:51 - loss: 0.3405 - accuracy: 0.87 - ETA: 7:38 - loss: 0.3439 - accuracy: 0.87 - ETA: 7:24 - loss: 0.3470 - accuracy: 0.86 - ETA: 7:10 - loss: 0.3470 - accuracy: 0.86 - ETA: 6:56 - loss: 0.3491 - accuracy: 0.86 - ETA: 6:42 - loss: 0.3478 - accuracy: 0.86 - ETA: 6:29 - loss: 0.3467 - accuracy: 0.86 - ETA: 6:15 - loss: 0.3459 - accuracy: 0.87 - ETA: 6:01 - loss: 0.3459 - accuracy: 0.87 - ETA: 5:47 - loss: 0.3457 - accuracy: 0.87 - ETA: 5:33 - loss: 0.3459 - accuracy: 0.87 - ETA: 5:19 - loss: 0.3448 - accuracy: 0.87 - ETA: 5:05 - loss: 0.3468 - accuracy: 0.86 - ETA: 4:52 - loss: 0.3489 - accuracy: 0.86 - ETA: 4:38 - loss: 0.3512 - accuracy: 0.86 - ETA: 4:24 - loss: 0.3517 - accuracy: 0.86 - ETA: 4:10 - loss: 0.3526 - accuracy: 0.86 - ETA: 3:56 - loss: 0.3514 - accuracy: 0.86 - ETA: 3:42 - loss: 0.3513 - accuracy: 0.86 - ETA: 3:28 - loss: 0.3523 - accuracy: 0.86 - ETA: 3:14 - loss: 0.3514 - accuracy: 0.86 - ETA: 3:01 - loss: 0.3532 - accuracy: 0.86 - ETA: 2:47 - loss: 0.3513 - accuracy: 0.86 - ETA: 2:33 - loss: 0.3507 - accuracy: 0.86 - ETA: 2:19 - loss: 0.3497 - accuracy: 0.86 - ETA: 2:05 - loss: 0.3488 - accuracy: 0.86 - ETA: 1:51 - loss: 0.3494 - accuracy: 0.86 - ETA: 1:37 - loss: 0.3498 - accuracy: 0.86 - ETA: 1:23 - loss: 0.3489 - accuracy: 0.86 - ETA: 1:09 - loss: 0.3480 - accuracy: 0.86 - ETA: 55s - loss: 0.3504 - accuracy: 0.8692 - ETA: 41s - loss: 0.3515 - accuracy: 0.868 - ETA: 27s - loss: 0.3505 - accuracy: 0.869 - ETA: 13s - loss: 0.3500 - accuracy: 0.869 - ETA: 0s - loss: 0.3511 - accuracy: 0.867 - 1461s 14s/step - loss: 0.3511 - accuracy: 0.8679 - val_loss: 0.5950 - val_accuracy: 0.7962\n",
      "Epoch 20/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.87 - ETA: 11:55 - loss: 0.4679 - accuracy: 0.828 - ETA: 15:43 - loss: 0.4129 - accuracy: 0.864 - ETA: 17:28 - loss: 0.3906 - accuracy: 0.867 - ETA: 18:27 - loss: 0.3725 - accuracy: 0.868 - ETA: 19:00 - loss: 0.3503 - accuracy: 0.875 - ETA: 19:18 - loss: 0.3664 - accuracy: 0.857 - ETA: 19:30 - loss: 0.3494 - accuracy: 0.867 - ETA: 19:35 - loss: 0.3318 - accuracy: 0.871 - ETA: 19:37 - loss: 0.3370 - accuracy: 0.868 - ETA: 19:37 - loss: 0.3341 - accuracy: 0.872 - ETA: 19:34 - loss: 0.3239 - accuracy: 0.877 - ETA: 19:29 - loss: 0.3416 - accuracy: 0.872 - ETA: 19:23 - loss: 0.3392 - accuracy: 0.877 - ETA: 19:15 - loss: 0.3319 - accuracy: 0.879 - ETA: 19:07 - loss: 0.3336 - accuracy: 0.873 - ETA: 19:00 - loss: 0.3274 - accuracy: 0.876 - ETA: 18:50 - loss: 0.3179 - accuracy: 0.881 - ETA: 18:39 - loss: 0.3169 - accuracy: 0.883 - ETA: 18:29 - loss: 0.3125 - accuracy: 0.884 - ETA: 18:18 - loss: 0.3044 - accuracy: 0.888 - ETA: 18:07 - loss: 0.2975 - accuracy: 0.892 - ETA: 17:56 - loss: 0.3011 - accuracy: 0.892 - ETA: 17:45 - loss: 0.3148 - accuracy: 0.889 - ETA: 17:33 - loss: 0.3147 - accuracy: 0.890 - ETA: 17:21 - loss: 0.3115 - accuracy: 0.891 - ETA: 17:09 - loss: 0.3181 - accuracy: 0.886 - ETA: 16:57 - loss: 0.3261 - accuracy: 0.883 - ETA: 16:45 - loss: 0.3323 - accuracy: 0.882 - ETA: 16:32 - loss: 0.3362 - accuracy: 0.883 - ETA: 16:20 - loss: 0.3374 - accuracy: 0.884 - ETA: 16:07 - loss: 0.3376 - accuracy: 0.883 - ETA: 15:55 - loss: 0.3372 - accuracy: 0.883 - ETA: 15:42 - loss: 0.3416 - accuracy: 0.881 - ETA: 15:29 - loss: 0.3408 - accuracy: 0.883 - ETA: 15:16 - loss: 0.3353 - accuracy: 0.884 - ETA: 15:03 - loss: 0.3388 - accuracy: 0.882 - ETA: 14:50 - loss: 0.3360 - accuracy: 0.882 - ETA: 14:37 - loss: 0.3370 - accuracy: 0.882 - ETA: 14:24 - loss: 0.3367 - accuracy: 0.882 - ETA: 14:11 - loss: 0.3354 - accuracy: 0.882 - ETA: 13:56 - loss: 0.3323 - accuracy: 0.883 - ETA: 13:43 - loss: 0.3312 - accuracy: 0.882 - ETA: 13:30 - loss: 0.3295 - accuracy: 0.884 - ETA: 13:17 - loss: 0.3272 - accuracy: 0.884 - ETA: 13:03 - loss: 0.3275 - accuracy: 0.884 - ETA: 12:50 - loss: 0.3309 - accuracy: 0.883 - ETA: 12:37 - loss: 0.3389 - accuracy: 0.878 - ETA: 12:23 - loss: 0.3757 - accuracy: 0.878 - ETA: 12:10 - loss: 0.3809 - accuracy: 0.874 - ETA: 11:56 - loss: 0.3826 - accuracy: 0.872 - ETA: 11:43 - loss: 0.4026 - accuracy: 0.870 - ETA: 11:29 - loss: 0.4016 - accuracy: 0.869 - ETA: 11:16 - loss: 0.4000 - accuracy: 0.869 - ETA: 11:02 - loss: 0.3982 - accuracy: 0.869 - ETA: 10:49 - loss: 0.3987 - accuracy: 0.868 - ETA: 10:35 - loss: 0.4011 - accuracy: 0.866 - ETA: 10:22 - loss: 0.3997 - accuracy: 0.866 - ETA: 10:08 - loss: 0.3958 - accuracy: 0.868 - ETA: 9:54 - loss: 0.3976 - accuracy: 0.867 - ETA: 9:41 - loss: 0.4012 - accuracy: 0.86 - ETA: 9:27 - loss: 0.4001 - accuracy: 0.86 - ETA: 9:13 - loss: 0.4015 - accuracy: 0.86 - ETA: 9:00 - loss: 0.3994 - accuracy: 0.86 - ETA: 8:46 - loss: 0.4002 - accuracy: 0.86 - ETA: 8:32 - loss: 0.3995 - accuracy: 0.86 - ETA: 8:18 - loss: 0.3989 - accuracy: 0.86 - ETA: 8:05 - loss: 0.3980 - accuracy: 0.86 - ETA: 7:51 - loss: 0.3945 - accuracy: 0.86 - ETA: 7:37 - loss: 0.3942 - accuracy: 0.86 - ETA: 7:23 - loss: 0.3926 - accuracy: 0.86 - ETA: 7:10 - loss: 0.3937 - accuracy: 0.86 - ETA: 6:56 - loss: 0.3978 - accuracy: 0.86 - ETA: 6:42 - loss: 0.3962 - accuracy: 0.86 - ETA: 6:28 - loss: 0.3962 - accuracy: 0.86 - ETA: 6:14 - loss: 0.3948 - accuracy: 0.86 - ETA: 6:01 - loss: 0.3961 - accuracy: 0.86 - ETA: 5:47 - loss: 0.3954 - accuracy: 0.86 - ETA: 5:33 - loss: 0.3948 - accuracy: 0.86 - ETA: 5:19 - loss: 0.3924 - accuracy: 0.86 - ETA: 5:05 - loss: 0.3932 - accuracy: 0.86 - ETA: 4:51 - loss: 0.3909 - accuracy: 0.86 - ETA: 4:38 - loss: 0.3931 - accuracy: 0.86 - ETA: 4:24 - loss: 0.3926 - accuracy: 0.86 - ETA: 4:10 - loss: 0.3940 - accuracy: 0.86 - ETA: 3:56 - loss: 0.3909 - accuracy: 0.86 - ETA: 3:42 - loss: 0.3959 - accuracy: 0.86 - ETA: 3:28 - loss: 0.3950 - accuracy: 0.86 - ETA: 3:14 - loss: 0.3941 - accuracy: 0.86 - ETA: 3:00 - loss: 0.3956 - accuracy: 0.86 - ETA: 2:47 - loss: 0.3939 - accuracy: 0.86 - ETA: 2:33 - loss: 0.3969 - accuracy: 0.86 - ETA: 2:19 - loss: 0.3950 - accuracy: 0.86 - ETA: 2:05 - loss: 0.3963 - accuracy: 0.86 - ETA: 1:51 - loss: 0.3952 - accuracy: 0.86 - ETA: 1:37 - loss: 0.3934 - accuracy: 0.86 - ETA: 1:23 - loss: 0.3918 - accuracy: 0.86 - ETA: 1:09 - loss: 0.3954 - accuracy: 0.86 - ETA: 55s - loss: 0.3967 - accuracy: 0.8648 - ETA: 41s - loss: 0.3965 - accuracy: 0.864 - ETA: 27s - loss: 0.3964 - accuracy: 0.864 - ETA: 13s - loss: 0.4364 - accuracy: 0.863 - ETA: 0s - loss: 0.4355 - accuracy: 0.863 - 1460s 14s/step - loss: 0.4355 - accuracy: 0.8631 - val_loss: 0.6972 - val_accuracy: 0.7582\n"
     ]
    }
   ],
   "source": [
    "modelss.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "r2 = modelss.fit_generator(train_set, validation_data=test_set, epochs=20, steps_per_epoch=len(train_set), validation_steps=len(test_set))\n",
    "x=r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelss.save('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=r2\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "mob1 = DenseNet121(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            250885      flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,288,389\n",
      "Trainable params: 7,204,741\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x1= Flatten()(mob1.output)\n",
    "prediction1 = Dense(5, activation='softmax')(x1)\n",
    "model121 = Model(inputs = mob1.inputs, outputs = prediction1)\n",
    "model121.summary()\n",
    "model121.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.9085 - accuracy: 0.37 - ETA: 14:46 - loss: 6.9774 - accuracy: 0.453 - ETA: 19:31 - loss: 11.1174 - accuracy: 0.47 - ETA: 21:46 - loss: 10.0570 - accuracy: 0.52 - ETA: 22:59 - loss: 8.7412 - accuracy: 0.5688 - ETA: 23:42 - loss: 8.0852 - accuracy: 0.572 - ETA: 24:08 - loss: 7.5392 - accuracy: 0.558 - ETA: 24:23 - loss: 6.7127 - accuracy: 0.570 - ETA: 24:34 - loss: 6.4252 - accuracy: 0.572 - ETA: 24:38 - loss: 5.9699 - accuracy: 0.553 - ETA: 24:37 - loss: 5.8560 - accuracy: 0.548 - ETA: 24:33 - loss: 5.5208 - accuracy: 0.544 - ETA: 24:27 - loss: 5.2321 - accuracy: 0.550 - ETA: 24:19 - loss: 4.9668 - accuracy: 0.560 - ETA: 24:12 - loss: 4.8157 - accuracy: 0.556 - ETA: 24:01 - loss: 4.9431 - accuracy: 0.554 - ETA: 23:51 - loss: 4.7233 - accuracy: 0.558 - ETA: 23:39 - loss: 4.5349 - accuracy: 0.555 - ETA: 23:28 - loss: 4.3505 - accuracy: 0.562 - ETA: 23:15 - loss: 4.2230 - accuracy: 0.556 - ETA: 23:02 - loss: 4.1056 - accuracy: 0.547 - ETA: 22:48 - loss: 3.9845 - accuracy: 0.539 - ETA: 22:34 - loss: 3.8573 - accuracy: 0.542 - ETA: 22:19 - loss: 3.7358 - accuracy: 0.548 - ETA: 22:05 - loss: 3.6343 - accuracy: 0.552 - ETA: 21:50 - loss: 3.7692 - accuracy: 0.555 - ETA: 21:35 - loss: 3.7977 - accuracy: 0.554 - ETA: 21:19 - loss: 3.7372 - accuracy: 0.553 - ETA: 21:04 - loss: 3.7171 - accuracy: 0.555 - ETA: 20:48 - loss: 3.7837 - accuracy: 0.553 - ETA: 20:32 - loss: 3.8740 - accuracy: 0.551 - ETA: 20:18 - loss: 3.9540 - accuracy: 0.549 - ETA: 20:02 - loss: 3.9643 - accuracy: 0.549 - ETA: 19:45 - loss: 3.9200 - accuracy: 0.550 - ETA: 19:29 - loss: 4.0850 - accuracy: 0.550 - ETA: 19:13 - loss: 4.0444 - accuracy: 0.547 - ETA: 18:57 - loss: 3.9674 - accuracy: 0.548 - ETA: 18:41 - loss: 3.9204 - accuracy: 0.548 - ETA: 18:24 - loss: 3.8565 - accuracy: 0.553 - ETA: 18:08 - loss: 3.7902 - accuracy: 0.557 - ETA: 17:51 - loss: 3.7552 - accuracy: 0.562 - ETA: 17:35 - loss: 3.6951 - accuracy: 0.564 - ETA: 17:18 - loss: 3.6319 - accuracy: 0.565 - ETA: 17:01 - loss: 3.8028 - accuracy: 0.565 - ETA: 16:44 - loss: 3.7461 - accuracy: 0.562 - ETA: 16:28 - loss: 3.7708 - accuracy: 0.561 - ETA: 16:11 - loss: 3.7952 - accuracy: 0.559 - ETA: 15:54 - loss: 3.7414 - accuracy: 0.556 - ETA: 15:37 - loss: 3.6910 - accuracy: 0.558 - ETA: 15:20 - loss: 3.6637 - accuracy: 0.556 - ETA: 15:03 - loss: 3.6237 - accuracy: 0.554 - ETA: 14:46 - loss: 3.5757 - accuracy: 0.557 - ETA: 14:29 - loss: 3.5437 - accuracy: 0.557 - ETA: 14:12 - loss: 3.4972 - accuracy: 0.560 - ETA: 13:55 - loss: 3.4646 - accuracy: 0.561 - ETA: 13:38 - loss: 3.4255 - accuracy: 0.560 - ETA: 13:21 - loss: 3.3921 - accuracy: 0.557 - ETA: 13:04 - loss: 3.3567 - accuracy: 0.559 - ETA: 12:48 - loss: 3.3423 - accuracy: 0.559 - ETA: 12:32 - loss: 3.3143 - accuracy: 0.559 - ETA: 12:15 - loss: 3.2885 - accuracy: 0.559 - ETA: 11:57 - loss: 3.2502 - accuracy: 0.561 - ETA: 11:40 - loss: 3.2289 - accuracy: 0.559 - ETA: 11:23 - loss: 3.1975 - accuracy: 0.559 - ETA: 11:06 - loss: 3.1709 - accuracy: 0.559 - ETA: 10:49 - loss: 3.1501 - accuracy: 0.562 - ETA: 10:32 - loss: 3.1370 - accuracy: 0.560 - ETA: 10:15 - loss: 3.1060 - accuracy: 0.562 - ETA: 9:58 - loss: 3.0743 - accuracy: 0.563 - ETA: 9:41 - loss: 3.0424 - accuracy: 0.56 - ETA: 9:23 - loss: 3.0297 - accuracy: 0.56 - ETA: 9:05 - loss: 3.0044 - accuracy: 0.56 - ETA: 8:48 - loss: 2.9740 - accuracy: 0.56 - ETA: 8:31 - loss: 2.9514 - accuracy: 0.56 - ETA: 8:13 - loss: 2.9305 - accuracy: 0.56 - ETA: 7:55 - loss: 2.9114 - accuracy: 0.56 - ETA: 7:38 - loss: 2.8919 - accuracy: 0.56 - ETA: 7:20 - loss: 2.8653 - accuracy: 0.56 - ETA: 7:03 - loss: 2.8550 - accuracy: 0.56 - ETA: 6:45 - loss: 2.8303 - accuracy: 0.56 - ETA: 6:27 - loss: 2.8067 - accuracy: 0.56 - ETA: 6:10 - loss: 2.7809 - accuracy: 0.57 - ETA: 5:52 - loss: 2.7610 - accuracy: 0.57 - ETA: 5:35 - loss: 2.7375 - accuracy: 0.57 - ETA: 5:17 - loss: 2.7210 - accuracy: 0.57 - ETA: 4:59 - loss: 2.7057 - accuracy: 0.57 - ETA: 4:42 - loss: 2.6889 - accuracy: 0.57 - ETA: 4:24 - loss: 2.6741 - accuracy: 0.57 - ETA: 4:07 - loss: 2.6625 - accuracy: 0.57 - ETA: 3:49 - loss: 2.6453 - accuracy: 0.57 - ETA: 3:31 - loss: 2.6267 - accuracy: 0.57 - ETA: 3:14 - loss: 2.6104 - accuracy: 0.57 - ETA: 2:56 - loss: 2.5919 - accuracy: 0.57 - ETA: 2:38 - loss: 2.5767 - accuracy: 0.57 - ETA: 2:21 - loss: 2.5622 - accuracy: 0.58 - ETA: 2:03 - loss: 2.5431 - accuracy: 0.58 - ETA: 1:45 - loss: 2.5243 - accuracy: 0.58 - ETA: 1:28 - loss: 2.5069 - accuracy: 0.58 - ETA: 1:10 - loss: 2.4905 - accuracy: 0.58 - ETA: 52s - loss: 2.4734 - accuracy: 0.5866 - ETA: 35s - loss: 2.4568 - accuracy: 0.587 - ETA: 17s - loss: 2.4417 - accuracy: 0.588 - ETA: 0s - loss: 2.4251 - accuracy: 0.589 - 1841s 18s/step - loss: 2.4251 - accuracy: 0.5899 - val_loss: 129.1593 - val_accuracy: 0.6848\n",
      "Epoch 2/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.4744 - accuracy: 0.81 - ETA: 14:47 - loss: 0.7190 - accuracy: 0.734 - ETA: 19:28 - loss: 0.6880 - accuracy: 0.739 - ETA: 21:42 - loss: 0.7885 - accuracy: 0.726 - ETA: 22:59 - loss: 0.7305 - accuracy: 0.737 - ETA: 23:44 - loss: 0.7387 - accuracy: 0.744 - ETA: 23:54 - loss: 0.7239 - accuracy: 0.752 - ETA: 24:11 - loss: 0.7665 - accuracy: 0.724 - ETA: 24:22 - loss: 0.7569 - accuracy: 0.734 - ETA: 24:25 - loss: 0.7779 - accuracy: 0.713 - ETA: 24:27 - loss: 0.7484 - accuracy: 0.725 - ETA: 24:26 - loss: 0.7354 - accuracy: 0.730 - ETA: 24:23 - loss: 0.7257 - accuracy: 0.731 - ETA: 24:16 - loss: 0.7537 - accuracy: 0.724 - ETA: 24:07 - loss: 0.7511 - accuracy: 0.732 - ETA: 23:58 - loss: 0.7639 - accuracy: 0.731 - ETA: 23:47 - loss: 0.8331 - accuracy: 0.719 - ETA: 23:36 - loss: 0.8431 - accuracy: 0.714 - ETA: 23:25 - loss: 0.8455 - accuracy: 0.709 - ETA: 23:12 - loss: 0.8453 - accuracy: 0.705 - ETA: 22:58 - loss: 0.8528 - accuracy: 0.706 - ETA: 22:44 - loss: 0.8478 - accuracy: 0.706 - ETA: 22:31 - loss: 0.8539 - accuracy: 0.701 - ETA: 22:17 - loss: 0.8567 - accuracy: 0.698 - ETA: 22:03 - loss: 0.8340 - accuracy: 0.708 - ETA: 21:48 - loss: 0.8269 - accuracy: 0.710 - ETA: 21:33 - loss: 0.8160 - accuracy: 0.711 - ETA: 21:18 - loss: 0.8142 - accuracy: 0.713 - ETA: 21:04 - loss: 0.8223 - accuracy: 0.711 - ETA: 20:48 - loss: 0.8290 - accuracy: 0.710 - ETA: 20:33 - loss: 0.8259 - accuracy: 0.712 - ETA: 20:17 - loss: 0.8196 - accuracy: 0.713 - ETA: 20:01 - loss: 0.8192 - accuracy: 0.713 - ETA: 19:45 - loss: 0.8205 - accuracy: 0.711 - ETA: 19:29 - loss: 0.8204 - accuracy: 0.710 - ETA: 19:12 - loss: 0.8206 - accuracy: 0.709 - ETA: 18:56 - loss: 0.8207 - accuracy: 0.706 - ETA: 18:40 - loss: 0.8352 - accuracy: 0.703 - ETA: 18:24 - loss: 0.8438 - accuracy: 0.700 - ETA: 18:07 - loss: 0.8432 - accuracy: 0.701 - ETA: 17:50 - loss: 0.8460 - accuracy: 0.700 - ETA: 17:33 - loss: 0.8431 - accuracy: 0.701 - ETA: 17:17 - loss: 0.8541 - accuracy: 0.700 - ETA: 17:00 - loss: 0.8557 - accuracy: 0.700 - ETA: 16:44 - loss: 0.8571 - accuracy: 0.698 - ETA: 16:27 - loss: 0.8552 - accuracy: 0.700 - ETA: 16:10 - loss: 0.8541 - accuracy: 0.698 - ETA: 15:53 - loss: 0.8517 - accuracy: 0.696 - ETA: 15:36 - loss: 0.8529 - accuracy: 0.697 - ETA: 15:19 - loss: 0.8579 - accuracy: 0.696 - ETA: 15:02 - loss: 0.8543 - accuracy: 0.696 - ETA: 14:45 - loss: 0.8622 - accuracy: 0.696 - ETA: 14:28 - loss: 0.8573 - accuracy: 0.697 - ETA: 14:11 - loss: 0.8605 - accuracy: 0.695 - ETA: 13:54 - loss: 0.8627 - accuracy: 0.694 - ETA: 13:37 - loss: 0.9634 - accuracy: 0.693 - ETA: 13:20 - loss: 0.9620 - accuracy: 0.694 - ETA: 13:03 - loss: 0.9742 - accuracy: 0.693 - ETA: 12:46 - loss: 0.9729 - accuracy: 0.692 - ETA: 12:29 - loss: 0.9724 - accuracy: 0.693 - ETA: 12:11 - loss: 1.0023 - accuracy: 0.693 - ETA: 11:54 - loss: 0.9993 - accuracy: 0.693 - ETA: 11:37 - loss: 1.0126 - accuracy: 0.693 - ETA: 11:19 - loss: 1.0179 - accuracy: 0.691 - ETA: 11:02 - loss: 1.0183 - accuracy: 0.690 - ETA: 10:45 - loss: 1.0306 - accuracy: 0.688 - ETA: 10:28 - loss: 1.0351 - accuracy: 0.685 - ETA: 10:10 - loss: 1.0351 - accuracy: 0.683 - ETA: 9:53 - loss: 1.1865 - accuracy: 0.681 - ETA: 9:36 - loss: 1.1831 - accuracy: 0.68 - ETA: 9:18 - loss: 1.1840 - accuracy: 0.67 - ETA: 9:01 - loss: 1.1854 - accuracy: 0.67 - ETA: 8:44 - loss: 1.1778 - accuracy: 0.68 - ETA: 8:26 - loss: 1.1825 - accuracy: 0.67 - ETA: 8:09 - loss: 1.1855 - accuracy: 0.67 - ETA: 7:52 - loss: 1.1889 - accuracy: 0.67 - ETA: 7:34 - loss: 1.1835 - accuracy: 0.67 - ETA: 7:17 - loss: 1.1847 - accuracy: 0.67 - ETA: 6:59 - loss: 1.1933 - accuracy: 0.67 - ETA: 6:42 - loss: 1.1887 - accuracy: 0.67 - ETA: 6:25 - loss: 1.1884 - accuracy: 0.67 - ETA: 6:07 - loss: 1.1864 - accuracy: 0.67 - ETA: 5:50 - loss: 1.1789 - accuracy: 0.67 - ETA: 5:32 - loss: 1.1819 - accuracy: 0.67 - ETA: 5:15 - loss: 1.1866 - accuracy: 0.67 - ETA: 4:57 - loss: 1.3242 - accuracy: 0.66 - ETA: 4:40 - loss: 1.6233 - accuracy: 0.66 - ETA: 4:22 - loss: 1.8116 - accuracy: 0.66 - ETA: 4:05 - loss: 1.8708 - accuracy: 0.66 - ETA: 3:47 - loss: 1.9024 - accuracy: 0.65 - ETA: 3:30 - loss: 1.9141 - accuracy: 0.65 - ETA: 3:12 - loss: 1.9212 - accuracy: 0.65 - ETA: 2:55 - loss: 1.9526 - accuracy: 0.65 - ETA: 2:37 - loss: 2.0268 - accuracy: 0.65 - ETA: 2:20 - loss: 2.0904 - accuracy: 0.65 - ETA: 2:02 - loss: 2.1058 - accuracy: 0.65 - ETA: 1:45 - loss: 2.1006 - accuracy: 0.65 - ETA: 1:27 - loss: 2.1561 - accuracy: 0.65 - ETA: 1:10 - loss: 2.2192 - accuracy: 0.64 - ETA: 52s - loss: 2.3240 - accuracy: 0.6454 - ETA: 35s - loss: 2.3387 - accuracy: 0.644 - ETA: 17s - loss: 2.4042 - accuracy: 0.642 - ETA: 0s - loss: 2.4296 - accuracy: 0.641 - 1828s 18s/step - loss: 2.4296 - accuracy: 0.6412 - val_loss: 23573.5000 - val_accuracy: 0.2772\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 7.0873 - accuracy: 0.34 - ETA: 14:50 - loss: 5.6461 - accuracy: 0.484 - ETA: 19:39 - loss: 7.1582 - accuracy: 0.468 - ETA: 21:52 - loss: 6.2199 - accuracy: 0.515 - ETA: 23:04 - loss: 5.5089 - accuracy: 0.512 - ETA: 23:47 - loss: 5.4095 - accuracy: 0.494 - ETA: 24:14 - loss: 7.4636 - accuracy: 0.486 - ETA: 24:27 - loss: 6.9300 - accuracy: 0.496 - ETA: 24:37 - loss: 6.8344 - accuracy: 0.510 - ETA: 24:40 - loss: 6.4724 - accuracy: 0.509 - ETA: 24:39 - loss: 6.6463 - accuracy: 0.488 - ETA: 24:34 - loss: 6.2576 - accuracy: 0.487 - ETA: 24:29 - loss: 5.9479 - accuracy: 0.490 - ETA: 24:22 - loss: 5.7279 - accuracy: 0.497 - ETA: 24:13 - loss: 5.5354 - accuracy: 0.510 - ETA: 24:03 - loss: 5.3381 - accuracy: 0.509 - ETA: 23:53 - loss: 5.3812 - accuracy: 0.505 - ETA: 23:41 - loss: 5.4082 - accuracy: 0.496 - ETA: 23:28 - loss: 5.2525 - accuracy: 0.496 - ETA: 23:16 - loss: 5.1031 - accuracy: 0.493 - ETA: 23:03 - loss: 5.0790 - accuracy: 0.495 - ETA: 22:48 - loss: 4.9849 - accuracy: 0.494 - ETA: 22:35 - loss: 4.9768 - accuracy: 0.482 - ETA: 22:21 - loss: 4.9093 - accuracy: 0.467 - ETA: 22:06 - loss: 4.8097 - accuracy: 0.458 - ETA: 21:51 - loss: 4.7520 - accuracy: 0.462 - ETA: 21:36 - loss: 4.6498 - accuracy: 0.467 - ETA: 21:21 - loss: 4.9038 - accuracy: 0.465 - ETA: 21:05 - loss: 4.8205 - accuracy: 0.469 - ETA: 20:50 - loss: 4.9158 - accuracy: 0.470 - ETA: 20:34 - loss: 4.8245 - accuracy: 0.472 - ETA: 20:18 - loss: 4.8131 - accuracy: 0.470 - ETA: 20:02 - loss: 4.8656 - accuracy: 0.466 - ETA: 19:46 - loss: 4.7722 - accuracy: 0.467 - ETA: 19:30 - loss: 4.6922 - accuracy: 0.470 - ETA: 19:14 - loss: 4.8450 - accuracy: 0.472 - ETA: 18:58 - loss: 4.7985 - accuracy: 0.475 - ETA: 18:42 - loss: 4.7601 - accuracy: 0.478 - ETA: 18:25 - loss: 4.7242 - accuracy: 0.480 - ETA: 18:09 - loss: 4.6861 - accuracy: 0.484 - ETA: 17:52 - loss: 4.7751 - accuracy: 0.484 - ETA: 17:35 - loss: 4.6879 - accuracy: 0.488 - ETA: 17:19 - loss: 4.6903 - accuracy: 0.486 - ETA: 17:02 - loss: 4.7518 - accuracy: 0.483 - ETA: 16:45 - loss: 4.8233 - accuracy: 0.484 - ETA: 16:28 - loss: 4.7369 - accuracy: 0.488 - ETA: 16:12 - loss: 4.7034 - accuracy: 0.486 - ETA: 15:55 - loss: 4.6566 - accuracy: 0.489 - ETA: 15:38 - loss: 4.6814 - accuracy: 0.489 - ETA: 15:20 - loss: 4.7146 - accuracy: 0.492 - ETA: 15:02 - loss: 4.6617 - accuracy: 0.496 - ETA: 14:45 - loss: 4.6562 - accuracy: 0.497 - ETA: 14:28 - loss: 4.6899 - accuracy: 0.498 - ETA: 14:11 - loss: 4.6479 - accuracy: 0.498 - ETA: 13:54 - loss: 4.6078 - accuracy: 0.496 - ETA: 13:37 - loss: 4.5503 - accuracy: 0.496 - ETA: 13:20 - loss: 4.5151 - accuracy: 0.492 - ETA: 13:03 - loss: 4.4705 - accuracy: 0.488 - ETA: 12:46 - loss: 4.4122 - accuracy: 0.492 - ETA: 12:29 - loss: 4.5266 - accuracy: 0.494 - ETA: 12:12 - loss: 4.5053 - accuracy: 0.495 - ETA: 11:54 - loss: 4.4726 - accuracy: 0.497 - ETA: 11:37 - loss: 4.4348 - accuracy: 0.497 - ETA: 11:20 - loss: 4.4145 - accuracy: 0.496 - ETA: 11:03 - loss: 4.3925 - accuracy: 0.495 - ETA: 10:45 - loss: 4.3612 - accuracy: 0.494 - ETA: 10:28 - loss: 4.3282 - accuracy: 0.496 - ETA: 10:11 - loss: 4.3126 - accuracy: 0.496 - ETA: 9:54 - loss: 4.2903 - accuracy: 0.495 - ETA: 9:36 - loss: 4.2761 - accuracy: 0.49 - ETA: 9:19 - loss: 4.2434 - accuracy: 0.49 - ETA: 9:02 - loss: 4.2257 - accuracy: 0.49 - ETA: 8:44 - loss: 4.2866 - accuracy: 0.49 - ETA: 8:27 - loss: 4.2493 - accuracy: 0.49 - ETA: 8:09 - loss: 4.2042 - accuracy: 0.49 - ETA: 7:52 - loss: 4.1654 - accuracy: 0.50 - ETA: 7:35 - loss: 4.1518 - accuracy: 0.50 - ETA: 7:17 - loss: 4.1323 - accuracy: 0.50 - ETA: 7:00 - loss: 4.1138 - accuracy: 0.50 - ETA: 6:43 - loss: 4.1158 - accuracy: 0.50 - ETA: 6:25 - loss: 4.0967 - accuracy: 0.50 - ETA: 6:08 - loss: 4.0798 - accuracy: 0.51 - ETA: 5:50 - loss: 4.0510 - accuracy: 0.51 - ETA: 5:33 - loss: 4.0372 - accuracy: 0.51 - ETA: 5:15 - loss: 4.0176 - accuracy: 0.51 - ETA: 4:58 - loss: 3.9899 - accuracy: 0.51 - ETA: 4:40 - loss: 3.9750 - accuracy: 0.51 - ETA: 4:23 - loss: 3.9683 - accuracy: 0.51 - ETA: 4:05 - loss: 3.9398 - accuracy: 0.51 - ETA: 3:48 - loss: 3.9345 - accuracy: 0.51 - ETA: 3:30 - loss: 3.9114 - accuracy: 0.51 - ETA: 3:13 - loss: 3.8960 - accuracy: 0.51 - ETA: 2:55 - loss: 3.8754 - accuracy: 0.51 - ETA: 2:37 - loss: 3.8505 - accuracy: 0.51 - ETA: 2:20 - loss: 3.8217 - accuracy: 0.51 - ETA: 2:02 - loss: 3.7937 - accuracy: 0.51 - ETA: 1:45 - loss: 3.7623 - accuracy: 0.52 - ETA: 1:27 - loss: 3.7347 - accuracy: 0.52 - ETA: 1:10 - loss: 3.7121 - accuracy: 0.52 - ETA: 52s - loss: 3.6960 - accuracy: 0.5210 - ETA: 35s - loss: 3.7604 - accuracy: 0.521 - ETA: 17s - loss: 3.7392 - accuracy: 0.522 - ETA: 0s - loss: 3.7304 - accuracy: 0.522 - 1830s 18s/step - loss: 3.7304 - accuracy: 0.5225 - val_loss: 7553145.5000 - val_accuracy: 0.4918\n",
      "Epoch 4/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.6668 - accuracy: 0.62 - ETA: 14:52 - loss: 1.6062 - accuracy: 0.593 - ETA: 19:40 - loss: 1.4555 - accuracy: 0.614 - ETA: 21:51 - loss: 1.4921 - accuracy: 0.632 - ETA: 23:05 - loss: 1.4775 - accuracy: 0.612 - ETA: 23:50 - loss: 1.4523 - accuracy: 0.614 - ETA: 24:20 - loss: 1.5402 - accuracy: 0.558 - ETA: 24:35 - loss: 1.4920 - accuracy: 0.554 - ETA: 24:43 - loss: 1.4662 - accuracy: 0.548 - ETA: 24:44 - loss: 1.4060 - accuracy: 0.571 - ETA: 24:44 - loss: 1.4415 - accuracy: 0.571 - ETA: 24:39 - loss: 1.3982 - accuracy: 0.583 - ETA: 24:34 - loss: 1.3423 - accuracy: 0.598 - ETA: 24:26 - loss: 1.3704 - accuracy: 0.593 - ETA: 24:17 - loss: 1.3262 - accuracy: 0.604 - ETA: 24:07 - loss: 1.3346 - accuracy: 0.605 - ETA: 23:55 - loss: 1.3365 - accuracy: 0.604 - ETA: 23:43 - loss: 1.3316 - accuracy: 0.611 - ETA: 23:31 - loss: 1.9555 - accuracy: 0.615 - ETA: 23:18 - loss: 1.9722 - accuracy: 0.612 - ETA: 23:04 - loss: 1.9461 - accuracy: 0.613 - ETA: 22:51 - loss: 1.9071 - accuracy: 0.615 - ETA: 22:37 - loss: 1.9103 - accuracy: 0.604 - ETA: 22:23 - loss: 3.0999 - accuracy: 0.593 - ETA: 22:08 - loss: 3.0326 - accuracy: 0.591 - ETA: 21:54 - loss: 2.9621 - accuracy: 0.588 - ETA: 21:39 - loss: 2.9135 - accuracy: 0.586 - ETA: 21:23 - loss: 2.9253 - accuracy: 0.585 - ETA: 21:08 - loss: 2.8908 - accuracy: 0.587 - ETA: 20:52 - loss: 2.8639 - accuracy: 0.584 - ETA: 20:36 - loss: 2.8175 - accuracy: 0.582 - ETA: 20:20 - loss: 2.7933 - accuracy: 0.582 - ETA: 20:04 - loss: 2.7577 - accuracy: 0.576 - ETA: 19:48 - loss: 2.7455 - accuracy: 0.569 - ETA: 19:32 - loss: 2.7222 - accuracy: 0.566 - ETA: 19:15 - loss: 2.7043 - accuracy: 0.563 - ETA: 18:59 - loss: 2.6664 - accuracy: 0.564 - ETA: 18:42 - loss: 2.6347 - accuracy: 0.566 - ETA: 18:26 - loss: 2.6187 - accuracy: 0.569 - ETA: 18:09 - loss: 2.5971 - accuracy: 0.569 - ETA: 17:53 - loss: 2.5621 - accuracy: 0.571 - ETA: 17:36 - loss: 2.5416 - accuracy: 0.572 - ETA: 17:19 - loss: 2.5232 - accuracy: 0.568 - ETA: 17:03 - loss: 2.5049 - accuracy: 0.567 - ETA: 16:46 - loss: 2.4907 - accuracy: 0.563 - ETA: 16:29 - loss: 2.4716 - accuracy: 0.562 - ETA: 16:12 - loss: 2.4480 - accuracy: 0.563 - ETA: 15:55 - loss: 2.4181 - accuracy: 0.563 - ETA: 15:38 - loss: 2.3946 - accuracy: 0.562 - ETA: 15:21 - loss: 2.3751 - accuracy: 0.566 - ETA: 15:04 - loss: 2.3516 - accuracy: 0.567 - ETA: 14:47 - loss: 2.3297 - accuracy: 0.569 - ETA: 14:30 - loss: 2.3168 - accuracy: 0.569 - ETA: 14:13 - loss: 2.2904 - accuracy: 0.570 - ETA: 13:56 - loss: 2.2787 - accuracy: 0.571 - ETA: 13:38 - loss: 2.2659 - accuracy: 0.569 - ETA: 13:21 - loss: 2.2509 - accuracy: 0.568 - ETA: 13:04 - loss: 2.2369 - accuracy: 0.565 - ETA: 12:47 - loss: 2.2210 - accuracy: 0.564 - ETA: 12:29 - loss: 2.2100 - accuracy: 0.563 - ETA: 12:12 - loss: 2.1847 - accuracy: 0.566 - ETA: 11:55 - loss: 2.1766 - accuracy: 0.566 - ETA: 11:38 - loss: 2.1632 - accuracy: 0.567 - ETA: 11:20 - loss: 2.1483 - accuracy: 0.568 - ETA: 11:03 - loss: 2.1325 - accuracy: 0.568 - ETA: 10:46 - loss: 2.1162 - accuracy: 0.569 - ETA: 10:29 - loss: 2.0966 - accuracy: 0.570 - ETA: 10:11 - loss: 2.0767 - accuracy: 0.573 - ETA: 9:54 - loss: 2.0641 - accuracy: 0.574 - ETA: 9:37 - loss: 2.0448 - accuracy: 0.57 - ETA: 9:19 - loss: 2.0416 - accuracy: 0.57 - ETA: 9:02 - loss: 2.0378 - accuracy: 0.57 - ETA: 8:44 - loss: 2.0396 - accuracy: 0.57 - ETA: 8:27 - loss: 2.0381 - accuracy: 0.57 - ETA: 8:10 - loss: 2.0334 - accuracy: 0.57 - ETA: 7:52 - loss: 2.0193 - accuracy: 0.57 - ETA: 7:35 - loss: 2.0103 - accuracy: 0.57 - ETA: 7:17 - loss: 2.0032 - accuracy: 0.57 - ETA: 7:00 - loss: 1.9906 - accuracy: 0.57 - ETA: 6:43 - loss: 1.9745 - accuracy: 0.57 - ETA: 6:25 - loss: 1.9606 - accuracy: 0.57 - ETA: 6:08 - loss: 1.9537 - accuracy: 0.58 - ETA: 5:50 - loss: 1.9419 - accuracy: 0.58 - ETA: 5:33 - loss: 1.9324 - accuracy: 0.58 - ETA: 5:15 - loss: 1.9231 - accuracy: 0.58 - ETA: 4:58 - loss: 1.9108 - accuracy: 0.58 - ETA: 4:40 - loss: 1.9047 - accuracy: 0.58 - ETA: 4:23 - loss: 1.8979 - accuracy: 0.58 - ETA: 4:05 - loss: 1.8864 - accuracy: 0.58 - ETA: 3:48 - loss: 1.8830 - accuracy: 0.58 - ETA: 3:30 - loss: 1.8722 - accuracy: 0.58 - ETA: 3:13 - loss: 1.8612 - accuracy: 0.58 - ETA: 2:55 - loss: 1.8557 - accuracy: 0.58 - ETA: 2:38 - loss: 1.8432 - accuracy: 0.58 - ETA: 2:20 - loss: 1.8332 - accuracy: 0.58 - ETA: 2:02 - loss: 1.8209 - accuracy: 0.58 - ETA: 1:45 - loss: 1.8090 - accuracy: 0.59 - ETA: 1:27 - loss: 1.8029 - accuracy: 0.59 - ETA: 1:10 - loss: 1.7957 - accuracy: 0.59 - ETA: 52s - loss: 1.7883 - accuracy: 0.5910 - ETA: 35s - loss: 1.7819 - accuracy: 0.589 - ETA: 17s - loss: 1.7729 - accuracy: 0.590 - ETA: 0s - loss: 1.7675 - accuracy: 0.591 - 1830s 18s/step - loss: 1.7675 - accuracy: 0.5911 - val_loss: 3.7071 - val_accuracy: 0.6467\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.7738 - accuracy: 0.71 - ETA: 14:50 - loss: 0.9854 - accuracy: 0.640 - ETA: 19:41 - loss: 1.0028 - accuracy: 0.635 - ETA: 21:59 - loss: 1.0802 - accuracy: 0.601 - ETA: 23:11 - loss: 1.0539 - accuracy: 0.606 - ETA: 23:54 - loss: 1.0839 - accuracy: 0.588 - ETA: 24:20 - loss: 1.0970 - accuracy: 0.593 - ETA: 24:35 - loss: 1.0830 - accuracy: 0.585 - ETA: 24:43 - loss: 1.0600 - accuracy: 0.604 - ETA: 24:44 - loss: 1.0770 - accuracy: 0.612 - ETA: 24:44 - loss: 1.0665 - accuracy: 0.616 - ETA: 24:39 - loss: 1.0671 - accuracy: 0.622 - ETA: 24:33 - loss: 1.0382 - accuracy: 0.632 - ETA: 24:24 - loss: 1.0239 - accuracy: 0.636 - ETA: 24:15 - loss: 1.0299 - accuracy: 0.637 - ETA: 24:04 - loss: 1.0341 - accuracy: 0.634 - ETA: 23:53 - loss: 1.0369 - accuracy: 0.630 - ETA: 23:42 - loss: 1.0372 - accuracy: 0.628 - ETA: 23:29 - loss: 1.0543 - accuracy: 0.623 - ETA: 23:16 - loss: 1.0372 - accuracy: 0.626 - ETA: 23:03 - loss: 1.0692 - accuracy: 0.625 - ETA: 22:49 - loss: 1.0705 - accuracy: 0.627 - ETA: 22:35 - loss: 1.0856 - accuracy: 0.629 - ETA: 22:22 - loss: 1.0713 - accuracy: 0.635 - ETA: 22:08 - loss: 1.0550 - accuracy: 0.641 - ETA: 21:53 - loss: 1.0548 - accuracy: 0.639 - ETA: 21:38 - loss: 1.0557 - accuracy: 0.635 - ETA: 21:22 - loss: 1.0478 - accuracy: 0.640 - ETA: 21:07 - loss: 1.0511 - accuracy: 0.641 - ETA: 20:51 - loss: 1.0657 - accuracy: 0.640 - ETA: 20:35 - loss: 1.0654 - accuracy: 0.638 - ETA: 20:20 - loss: 1.0599 - accuracy: 0.640 - ETA: 20:04 - loss: 1.0700 - accuracy: 0.639 - ETA: 19:48 - loss: 1.0616 - accuracy: 0.642 - ETA: 19:32 - loss: 1.0753 - accuracy: 0.639 - ETA: 19:14 - loss: 1.0679 - accuracy: 0.640 - ETA: 18:57 - loss: 1.0726 - accuracy: 0.636 - ETA: 18:41 - loss: 1.0883 - accuracy: 0.633 - ETA: 18:25 - loss: 1.1667 - accuracy: 0.630 - ETA: 18:08 - loss: 1.1646 - accuracy: 0.629 - ETA: 17:52 - loss: 1.2828 - accuracy: 0.623 - ETA: 17:35 - loss: 1.2878 - accuracy: 0.620 - ETA: 17:18 - loss: 1.2952 - accuracy: 0.619 - ETA: 17:02 - loss: 1.3043 - accuracy: 0.619 - ETA: 16:45 - loss: 1.3152 - accuracy: 0.619 - ETA: 16:28 - loss: 1.3367 - accuracy: 0.621 - ETA: 16:11 - loss: 1.3553 - accuracy: 0.621 - ETA: 15:54 - loss: 1.3499 - accuracy: 0.623 - ETA: 15:37 - loss: 1.3483 - accuracy: 0.624 - ETA: 15:20 - loss: 1.3638 - accuracy: 0.625 - ETA: 15:03 - loss: 1.3565 - accuracy: 0.628 - ETA: 14:46 - loss: 1.3587 - accuracy: 0.628 - ETA: 14:29 - loss: 1.3537 - accuracy: 0.630 - ETA: 14:12 - loss: 1.3593 - accuracy: 0.629 - ETA: 13:55 - loss: 1.3620 - accuracy: 0.629 - ETA: 13:38 - loss: 1.6529 - accuracy: 0.622 - ETA: 13:21 - loss: 1.6530 - accuracy: 0.620 - ETA: 13:03 - loss: 1.6480 - accuracy: 0.618 - ETA: 12:46 - loss: 1.6385 - accuracy: 0.619 - ETA: 12:29 - loss: 1.6362 - accuracy: 0.617 - ETA: 12:12 - loss: 1.6267 - accuracy: 0.616 - ETA: 11:55 - loss: 1.6466 - accuracy: 0.614 - ETA: 11:38 - loss: 1.6506 - accuracy: 0.614 - ETA: 11:21 - loss: 1.6516 - accuracy: 0.616 - ETA: 11:03 - loss: 1.6512 - accuracy: 0.614 - ETA: 10:46 - loss: 1.6468 - accuracy: 0.616 - ETA: 10:29 - loss: 1.6515 - accuracy: 0.615 - ETA: 10:11 - loss: 1.6505 - accuracy: 0.615 - ETA: 9:54 - loss: 1.6642 - accuracy: 0.611 - ETA: 9:37 - loss: 1.6570 - accuracy: 0.61 - ETA: 9:19 - loss: 1.6419 - accuracy: 0.61 - ETA: 9:02 - loss: 1.6463 - accuracy: 0.61 - ETA: 8:44 - loss: 1.6392 - accuracy: 0.61 - ETA: 8:27 - loss: 1.6341 - accuracy: 0.61 - ETA: 8:10 - loss: 1.6385 - accuracy: 0.61 - ETA: 7:52 - loss: 1.6391 - accuracy: 0.61 - ETA: 7:35 - loss: 1.6426 - accuracy: 0.61 - ETA: 7:17 - loss: 1.6589 - accuracy: 0.61 - ETA: 7:00 - loss: 1.6503 - accuracy: 0.61 - ETA: 6:43 - loss: 1.6550 - accuracy: 0.61 - ETA: 6:25 - loss: 1.6511 - accuracy: 0.61 - ETA: 6:08 - loss: 1.6464 - accuracy: 0.61 - ETA: 5:50 - loss: 1.6414 - accuracy: 0.61 - ETA: 5:33 - loss: 1.6351 - accuracy: 0.61 - ETA: 5:15 - loss: 1.6308 - accuracy: 0.61 - ETA: 4:58 - loss: 1.6339 - accuracy: 0.60 - ETA: 4:40 - loss: 1.9506 - accuracy: 0.61 - ETA: 4:23 - loss: 1.9484 - accuracy: 0.61 - ETA: 4:05 - loss: 1.9671 - accuracy: 0.60 - ETA: 3:48 - loss: 1.9662 - accuracy: 0.60 - ETA: 3:30 - loss: 1.9476 - accuracy: 0.61 - ETA: 3:13 - loss: 1.9410 - accuracy: 0.61 - ETA: 2:55 - loss: 1.9346 - accuracy: 0.61 - ETA: 2:37 - loss: 2.0298 - accuracy: 0.61 - ETA: 2:20 - loss: 2.0233 - accuracy: 0.61 - ETA: 2:02 - loss: 2.0188 - accuracy: 0.61 - ETA: 1:45 - loss: 2.0113 - accuracy: 0.61 - ETA: 1:27 - loss: 2.0310 - accuracy: 0.61 - ETA: 1:10 - loss: 2.0517 - accuracy: 0.61 - ETA: 52s - loss: 2.0457 - accuracy: 0.6110 - ETA: 35s - loss: 2.0397 - accuracy: 0.610 - ETA: 17s - loss: 2.0345 - accuracy: 0.611 - ETA: 0s - loss: 2.0284 - accuracy: 0.611 - 1830s 18s/step - loss: 2.0284 - accuracy: 0.6117 - val_loss: 169378.7344 - val_accuracy: 0.4076\n",
      "Epoch 6/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.2726 - accuracy: 0.65 - ETA: 14:51 - loss: 1.8564 - accuracy: 0.656 - ETA: 19:39 - loss: 5.1224 - accuracy: 0.593 - ETA: 21:56 - loss: 11.6399 - accuracy: 0.59 - ETA: 23:07 - loss: 9.4736 - accuracy: 0.6062 - ETA: 23:51 - loss: 8.0789 - accuracy: 0.625 - ETA: 24:16 - loss: 7.1709 - accuracy: 0.616 - ETA: 24:31 - loss: 6.4228 - accuracy: 0.609 - ETA: 24:39 - loss: 5.7995 - accuracy: 0.618 - ETA: 24:43 - loss: 5.3024 - accuracy: 0.625 - ETA: 24:42 - loss: 4.9577 - accuracy: 0.610 - ETA: 24:38 - loss: 4.6159 - accuracy: 0.619 - ETA: 24:32 - loss: 4.3552 - accuracy: 0.613 - ETA: 24:24 - loss: 4.1237 - accuracy: 0.602 - ETA: 24:15 - loss: 3.9079 - accuracy: 0.602 - ETA: 24:05 - loss: 4.6972 - accuracy: 0.603 - ETA: 23:54 - loss: 4.5374 - accuracy: 0.593 - ETA: 23:44 - loss: 4.8027 - accuracy: 0.590 - ETA: 23:32 - loss: 4.7621 - accuracy: 0.574 - ETA: 23:19 - loss: 4.6386 - accuracy: 0.554 - ETA: 23:01 - loss: 4.5456 - accuracy: 0.546 - ETA: 22:49 - loss: 4.5460 - accuracy: 0.545 - ETA: 22:36 - loss: 4.5449 - accuracy: 0.542 - ETA: 22:21 - loss: 4.9309 - accuracy: 0.543 - ETA: 22:06 - loss: 4.8327 - accuracy: 0.541 - ETA: 21:51 - loss: 4.7215 - accuracy: 0.536 - ETA: 21:36 - loss: 4.9321 - accuracy: 0.532 - ETA: 21:21 - loss: 5.0490 - accuracy: 0.532 - ETA: 21:06 - loss: 4.9264 - accuracy: 0.533 - ETA: 20:50 - loss: 5.0768 - accuracy: 0.530 - ETA: 20:34 - loss: 4.9572 - accuracy: 0.528 - ETA: 20:19 - loss: 5.0706 - accuracy: 0.525 - ETA: 20:03 - loss: 5.0442 - accuracy: 0.521 - ETA: 19:47 - loss: 4.9606 - accuracy: 0.523 - ETA: 19:31 - loss: 5.1502 - accuracy: 0.522 - ETA: 19:14 - loss: 5.1433 - accuracy: 0.518 - ETA: 18:58 - loss: 5.0994 - accuracy: 0.513 - ETA: 18:42 - loss: 5.0242 - accuracy: 0.514 - ETA: 18:25 - loss: 4.9528 - accuracy: 0.513 - ETA: 18:09 - loss: 5.3310 - accuracy: 0.511 - ETA: 17:52 - loss: 5.3057 - accuracy: 0.508 - ETA: 17:35 - loss: 5.3112 - accuracy: 0.506 - ETA: 17:19 - loss: 5.2245 - accuracy: 0.507 - ETA: 17:02 - loss: 5.1755 - accuracy: 0.504 - ETA: 16:45 - loss: 5.1920 - accuracy: 0.503 - ETA: 16:28 - loss: 5.1731 - accuracy: 0.500 - ETA: 16:11 - loss: 5.1886 - accuracy: 0.493 - ETA: 15:54 - loss: 5.1411 - accuracy: 0.488 - ETA: 15:37 - loss: 5.1682 - accuracy: 0.492 - ETA: 15:20 - loss: 5.1288 - accuracy: 0.493 - ETA: 15:03 - loss: 5.0967 - accuracy: 0.495 - ETA: 14:46 - loss: 5.0454 - accuracy: 0.495 - ETA: 14:29 - loss: 4.9914 - accuracy: 0.499 - ETA: 14:12 - loss: 4.9701 - accuracy: 0.501 - ETA: 13:55 - loss: 5.0808 - accuracy: 0.500 - ETA: 13:38 - loss: 5.1188 - accuracy: 0.499 - ETA: 13:21 - loss: 5.1802 - accuracy: 0.498 - ETA: 13:04 - loss: 5.1363 - accuracy: 0.497 - ETA: 12:46 - loss: 5.1168 - accuracy: 0.496 - ETA: 12:29 - loss: 5.1261 - accuracy: 0.495 - ETA: 12:12 - loss: 5.0726 - accuracy: 0.498 - ETA: 11:55 - loss: 5.0753 - accuracy: 0.496 - ETA: 11:38 - loss: 5.0133 - accuracy: 0.498 - ETA: 11:20 - loss: 4.9656 - accuracy: 0.498 - ETA: 11:03 - loss: 4.9207 - accuracy: 0.498 - ETA: 10:46 - loss: 4.8822 - accuracy: 0.498 - ETA: 10:28 - loss: 4.8438 - accuracy: 0.498 - ETA: 10:11 - loss: 4.8017 - accuracy: 0.494 - ETA: 9:54 - loss: 4.7568 - accuracy: 0.493 - ETA: 9:36 - loss: 4.7206 - accuracy: 0.49 - ETA: 9:19 - loss: 4.6890 - accuracy: 0.49 - ETA: 9:02 - loss: 4.6483 - accuracy: 0.49 - ETA: 8:44 - loss: 4.6013 - accuracy: 0.49 - ETA: 8:27 - loss: 4.7142 - accuracy: 0.49 - ETA: 8:10 - loss: 4.6677 - accuracy: 0.49 - ETA: 7:52 - loss: 4.6297 - accuracy: 0.49 - ETA: 7:35 - loss: 4.5888 - accuracy: 0.49 - ETA: 7:17 - loss: 4.5430 - accuracy: 0.49 - ETA: 7:00 - loss: 4.5007 - accuracy: 0.50 - ETA: 6:42 - loss: 4.4733 - accuracy: 0.50 - ETA: 6:25 - loss: 4.4447 - accuracy: 0.50 - ETA: 6:08 - loss: 4.4107 - accuracy: 0.50 - ETA: 5:50 - loss: 4.3758 - accuracy: 0.50 - ETA: 5:33 - loss: 4.3464 - accuracy: 0.50 - ETA: 5:15 - loss: 4.3151 - accuracy: 0.50 - ETA: 4:58 - loss: 4.3137 - accuracy: 0.50 - ETA: 4:40 - loss: 4.2844 - accuracy: 0.50 - ETA: 4:23 - loss: 4.2457 - accuracy: 0.50 - ETA: 4:05 - loss: 4.2101 - accuracy: 0.50 - ETA: 3:48 - loss: 4.2302 - accuracy: 0.50 - ETA: 3:30 - loss: 4.1924 - accuracy: 0.51 - ETA: 3:13 - loss: 4.1590 - accuracy: 0.51 - ETA: 2:55 - loss: 4.1265 - accuracy: 0.51 - ETA: 2:37 - loss: 4.1034 - accuracy: 0.51 - ETA: 2:20 - loss: 4.0812 - accuracy: 0.52 - ETA: 2:02 - loss: 4.0613 - accuracy: 0.51 - ETA: 1:45 - loss: 4.0390 - accuracy: 0.52 - ETA: 1:27 - loss: 4.0089 - accuracy: 0.52 - ETA: 1:10 - loss: 3.9795 - accuracy: 0.52 - ETA: 52s - loss: 3.9566 - accuracy: 0.5206 - ETA: 35s - loss: 3.9304 - accuracy: 0.519 - ETA: 17s - loss: 3.9004 - accuracy: 0.520 - ETA: 0s - loss: 3.8725 - accuracy: 0.521 - 1830s 18s/step - loss: 3.8725 - accuracy: 0.5216 - val_loss: 389409.0938 - val_accuracy: 0.4973\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 1.3841 - accuracy: 0.68 - ETA: 14:51 - loss: 1.3435 - accuracy: 0.578 - ETA: 19:40 - loss: 1.5274 - accuracy: 0.583 - ETA: 21:54 - loss: 1.5757 - accuracy: 0.601 - ETA: 23:06 - loss: 1.5565 - accuracy: 0.600 - ETA: 23:52 - loss: 1.5037 - accuracy: 0.609 - ETA: 24:17 - loss: 1.4515 - accuracy: 0.625 - ETA: 24:32 - loss: 1.3860 - accuracy: 0.628 - ETA: 24:39 - loss: 1.4132 - accuracy: 0.611 - ETA: 24:40 - loss: 1.4282 - accuracy: 0.590 - ETA: 24:39 - loss: 1.4247 - accuracy: 0.585 - ETA: 24:36 - loss: 2.0102 - accuracy: 0.575 - ETA: 24:31 - loss: 1.9470 - accuracy: 0.581 - ETA: 24:23 - loss: 1.8598 - accuracy: 0.598 - ETA: 24:14 - loss: 1.8638 - accuracy: 0.597 - ETA: 24:05 - loss: 1.8160 - accuracy: 0.601 - ETA: 23:54 - loss: 1.8373 - accuracy: 0.597 - ETA: 23:42 - loss: 1.8489 - accuracy: 0.590 - ETA: 23:31 - loss: 1.8102 - accuracy: 0.592 - ETA: 23:19 - loss: 1.8082 - accuracy: 0.582 - ETA: 23:05 - loss: 1.7856 - accuracy: 0.584 - ETA: 22:51 - loss: 1.7789 - accuracy: 0.590 - ETA: 22:36 - loss: 1.7790 - accuracy: 0.589 - ETA: 22:22 - loss: 1.7600 - accuracy: 0.587 - ETA: 22:07 - loss: 1.7334 - accuracy: 0.590 - ETA: 21:53 - loss: 1.7112 - accuracy: 0.596 - ETA: 21:38 - loss: 1.7132 - accuracy: 0.594 - ETA: 21:23 - loss: 1.6913 - accuracy: 0.598 - ETA: 21:07 - loss: 1.6679 - accuracy: 0.599 - ETA: 20:51 - loss: 1.6690 - accuracy: 0.597 - ETA: 20:35 - loss: 1.6430 - accuracy: 0.601 - ETA: 20:19 - loss: 1.6170 - accuracy: 0.605 - ETA: 20:03 - loss: 1.6120 - accuracy: 0.599 - ETA: 19:47 - loss: 1.5901 - accuracy: 0.601 - ETA: 19:31 - loss: 1.5867 - accuracy: 0.599 - ETA: 19:14 - loss: 1.5625 - accuracy: 0.604 - ETA: 18:58 - loss: 1.5722 - accuracy: 0.603 - ETA: 18:42 - loss: 1.6113 - accuracy: 0.598 - ETA: 18:25 - loss: 1.6292 - accuracy: 0.597 - ETA: 18:09 - loss: 1.6070 - accuracy: 0.602 - ETA: 17:50 - loss: 1.5949 - accuracy: 0.603 - ETA: 17:34 - loss: 1.5884 - accuracy: 0.602 - ETA: 17:17 - loss: 1.5791 - accuracy: 0.601 - ETA: 17:01 - loss: 1.5717 - accuracy: 0.601 - ETA: 16:44 - loss: 1.5607 - accuracy: 0.601 - ETA: 16:27 - loss: 1.5623 - accuracy: 0.598 - ETA: 16:10 - loss: 1.5544 - accuracy: 0.595 - ETA: 15:53 - loss: 1.5472 - accuracy: 0.595 - ETA: 15:36 - loss: 1.5378 - accuracy: 0.596 - ETA: 15:20 - loss: 1.5369 - accuracy: 0.596 - ETA: 15:03 - loss: 1.5277 - accuracy: 0.596 - ETA: 14:46 - loss: 1.5152 - accuracy: 0.599 - ETA: 14:29 - loss: 1.5090 - accuracy: 0.601 - ETA: 14:13 - loss: 1.4938 - accuracy: 0.603 - ETA: 13:56 - loss: 1.4802 - accuracy: 0.605 - ETA: 13:39 - loss: 1.4667 - accuracy: 0.608 - ETA: 13:21 - loss: 1.4573 - accuracy: 0.609 - ETA: 13:04 - loss: 1.7097 - accuracy: 0.611 - ETA: 12:47 - loss: 1.7001 - accuracy: 0.607 - ETA: 12:30 - loss: 1.6969 - accuracy: 0.605 - ETA: 12:13 - loss: 1.6852 - accuracy: 0.605 - ETA: 11:55 - loss: 1.6763 - accuracy: 0.604 - ETA: 11:38 - loss: 1.6694 - accuracy: 0.604 - ETA: 11:21 - loss: 1.6574 - accuracy: 0.605 - ETA: 11:03 - loss: 1.6520 - accuracy: 0.605 - ETA: 10:46 - loss: 1.6448 - accuracy: 0.606 - ETA: 10:29 - loss: 1.6358 - accuracy: 0.607 - ETA: 10:11 - loss: 1.6302 - accuracy: 0.608 - ETA: 9:54 - loss: 1.6168 - accuracy: 0.609 - ETA: 9:37 - loss: 1.6064 - accuracy: 0.61 - ETA: 9:20 - loss: 1.5983 - accuracy: 0.61 - ETA: 9:02 - loss: 1.5893 - accuracy: 0.61 - ETA: 8:45 - loss: 1.5796 - accuracy: 0.61 - ETA: 8:27 - loss: 1.5765 - accuracy: 0.61 - ETA: 8:10 - loss: 1.5649 - accuracy: 0.61 - ETA: 7:52 - loss: 1.5552 - accuracy: 0.61 - ETA: 7:35 - loss: 1.5468 - accuracy: 0.61 - ETA: 7:17 - loss: 1.5347 - accuracy: 0.61 - ETA: 7:00 - loss: 1.5258 - accuracy: 0.61 - ETA: 6:43 - loss: 1.5167 - accuracy: 0.61 - ETA: 6:25 - loss: 1.5096 - accuracy: 0.61 - ETA: 6:08 - loss: 1.5003 - accuracy: 0.61 - ETA: 5:50 - loss: 1.4872 - accuracy: 0.62 - ETA: 5:33 - loss: 1.4792 - accuracy: 0.62 - ETA: 5:15 - loss: 1.4749 - accuracy: 0.62 - ETA: 4:58 - loss: 1.4668 - accuracy: 0.62 - ETA: 4:40 - loss: 1.4615 - accuracy: 0.62 - ETA: 4:23 - loss: 1.4590 - accuracy: 0.62 - ETA: 4:05 - loss: 1.4498 - accuracy: 0.62 - ETA: 3:48 - loss: 1.4485 - accuracy: 0.62 - ETA: 3:30 - loss: 1.4455 - accuracy: 0.62 - ETA: 3:13 - loss: 1.4388 - accuracy: 0.62 - ETA: 2:55 - loss: 1.4395 - accuracy: 0.62 - ETA: 2:37 - loss: 1.4380 - accuracy: 0.61 - ETA: 2:20 - loss: 1.4288 - accuracy: 0.62 - ETA: 2:02 - loss: 1.4237 - accuracy: 0.62 - ETA: 1:45 - loss: 1.4198 - accuracy: 0.62 - ETA: 1:27 - loss: 1.4186 - accuracy: 0.62 - ETA: 1:10 - loss: 1.4140 - accuracy: 0.62 - ETA: 52s - loss: 1.4154 - accuracy: 0.6245 - ETA: 35s - loss: 1.4137 - accuracy: 0.625 - ETA: 17s - loss: 1.4205 - accuracy: 0.623 - ETA: 0s - loss: 1.4276 - accuracy: 0.622 - 1830s 18s/step - loss: 1.4276 - accuracy: 0.6223 - val_loss: 1802.1610 - val_accuracy: 0.3750\n",
      "Epoch 8/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.8907 - accuracy: 0.68 - ETA: 14:51 - loss: 1.0109 - accuracy: 0.687 - ETA: 19:49 - loss: 0.9570 - accuracy: 0.687 - ETA: 22:00 - loss: 1.1011 - accuracy: 0.648 - ETA: 23:17 - loss: 1.1405 - accuracy: 0.668 - ETA: 23:59 - loss: 1.1154 - accuracy: 0.645 - ETA: 24:26 - loss: 2.3950 - accuracy: 0.656 - ETA: 24:39 - loss: 2.3434 - accuracy: 0.644 - ETA: 24:44 - loss: 2.2883 - accuracy: 0.618 - ETA: 24:46 - loss: 2.1885 - accuracy: 0.628 - ETA: 24:45 - loss: 2.1185 - accuracy: 0.625 - ETA: 24:41 - loss: 2.0681 - accuracy: 0.627 - ETA: 24:34 - loss: 2.7759 - accuracy: 0.608 - ETA: 24:26 - loss: 2.6673 - accuracy: 0.600 - ETA: 24:16 - loss: 2.6208 - accuracy: 0.585 - ETA: 24:06 - loss: 2.5298 - accuracy: 0.587 - ETA: 23:57 - loss: 3.3472 - accuracy: 0.573 - ETA: 23:46 - loss: 3.2043 - accuracy: 0.581 - ETA: 23:33 - loss: 3.0714 - accuracy: 0.592 - ETA: 23:20 - loss: 3.0270 - accuracy: 0.581 - ETA: 23:06 - loss: 2.9664 - accuracy: 0.577 - ETA: 22:53 - loss: 2.8680 - accuracy: 0.578 - ETA: 22:39 - loss: 2.7933 - accuracy: 0.578 - ETA: 22:24 - loss: 2.6974 - accuracy: 0.591 - ETA: 22:09 - loss: 2.6311 - accuracy: 0.595 - ETA: 21:54 - loss: 2.5796 - accuracy: 0.598 - ETA: 21:39 - loss: 2.5598 - accuracy: 0.591 - ETA: 21:23 - loss: 2.5081 - accuracy: 0.590 - ETA: 21:07 - loss: 2.4692 - accuracy: 0.590 - ETA: 20:52 - loss: 2.4248 - accuracy: 0.588 - ETA: 20:36 - loss: 2.3778 - accuracy: 0.589 - ETA: 20:22 - loss: 2.3315 - accuracy: 0.593 - ETA: 20:08 - loss: 2.3000 - accuracy: 0.597 - ETA: 19:53 - loss: 2.2928 - accuracy: 0.598 - ETA: 19:38 - loss: 2.2706 - accuracy: 0.600 - ETA: 19:24 - loss: 2.2191 - accuracy: 0.608 - ETA: 19:07 - loss: 2.2157 - accuracy: 0.604 - ETA: 18:50 - loss: 2.1865 - accuracy: 0.604 - ETA: 18:33 - loss: 2.1612 - accuracy: 0.599 - ETA: 18:16 - loss: 2.1311 - accuracy: 0.600 - ETA: 18:00 - loss: 2.1037 - accuracy: 0.597 - ETA: 17:43 - loss: 2.0765 - accuracy: 0.599 - ETA: 17:26 - loss: 2.0584 - accuracy: 0.598 - ETA: 17:08 - loss: 2.0352 - accuracy: 0.601 - ETA: 16:51 - loss: 2.0063 - accuracy: 0.604 - ETA: 16:34 - loss: 1.9799 - accuracy: 0.608 - ETA: 16:17 - loss: 1.9789 - accuracy: 0.605 - ETA: 16:00 - loss: 1.9538 - accuracy: 0.609 - ETA: 15:43 - loss: 1.9261 - accuracy: 0.611 - ETA: 15:25 - loss: 1.9103 - accuracy: 0.612 - ETA: 15:08 - loss: 1.8884 - accuracy: 0.614 - ETA: 14:51 - loss: 1.8727 - accuracy: 0.615 - ETA: 14:34 - loss: 1.8496 - accuracy: 0.619 - ETA: 14:16 - loss: 1.8393 - accuracy: 0.618 - ETA: 13:59 - loss: 1.8247 - accuracy: 0.617 - ETA: 13:42 - loss: 1.8132 - accuracy: 0.615 - ETA: 13:25 - loss: 1.8000 - accuracy: 0.613 - ETA: 13:07 - loss: 1.7823 - accuracy: 0.615 - ETA: 12:50 - loss: 1.7672 - accuracy: 0.614 - ETA: 12:32 - loss: 1.7578 - accuracy: 0.614 - ETA: 12:15 - loss: 1.7440 - accuracy: 0.614 - ETA: 11:58 - loss: 1.7354 - accuracy: 0.616 - ETA: 11:40 - loss: 1.7163 - accuracy: 0.620 - ETA: 11:23 - loss: 1.7026 - accuracy: 0.622 - ETA: 11:06 - loss: 1.6869 - accuracy: 0.624 - ETA: 10:48 - loss: 1.6766 - accuracy: 0.625 - ETA: 10:31 - loss: 1.6601 - accuracy: 0.627 - ETA: 10:14 - loss: 1.6527 - accuracy: 0.627 - ETA: 9:56 - loss: 1.6477 - accuracy: 0.625 - ETA: 9:39 - loss: 1.6360 - accuracy: 0.62 - ETA: 9:21 - loss: 1.6273 - accuracy: 0.62 - ETA: 9:04 - loss: 1.6175 - accuracy: 0.62 - ETA: 8:46 - loss: 1.6074 - accuracy: 0.62 - ETA: 8:29 - loss: 1.5970 - accuracy: 0.62 - ETA: 8:11 - loss: 1.5939 - accuracy: 0.62 - ETA: 7:54 - loss: 1.5867 - accuracy: 0.62 - ETA: 7:36 - loss: 1.5735 - accuracy: 0.62 - ETA: 7:19 - loss: 1.5709 - accuracy: 0.62 - ETA: 7:01 - loss: 1.5616 - accuracy: 0.62 - ETA: 6:44 - loss: 1.5606 - accuracy: 0.62 - ETA: 6:26 - loss: 1.5518 - accuracy: 0.62 - ETA: 6:09 - loss: 1.5478 - accuracy: 0.62 - ETA: 5:51 - loss: 1.5437 - accuracy: 0.62 - ETA: 5:34 - loss: 1.5397 - accuracy: 0.62 - ETA: 5:16 - loss: 1.5318 - accuracy: 0.62 - ETA: 4:59 - loss: 1.5291 - accuracy: 0.62 - ETA: 4:41 - loss: 1.5240 - accuracy: 0.62 - ETA: 4:23 - loss: 1.5160 - accuracy: 0.62 - ETA: 4:06 - loss: 1.5124 - accuracy: 0.62 - ETA: 3:48 - loss: 1.5062 - accuracy: 0.62 - ETA: 3:31 - loss: 1.7139 - accuracy: 0.62 - ETA: 3:13 - loss: 1.7087 - accuracy: 0.62 - ETA: 2:55 - loss: 1.7086 - accuracy: 0.62 - ETA: 2:38 - loss: 1.7011 - accuracy: 0.62 - ETA: 2:20 - loss: 1.6930 - accuracy: 0.62 - ETA: 2:03 - loss: 1.6867 - accuracy: 0.62 - ETA: 1:45 - loss: 1.6830 - accuracy: 0.62 - ETA: 1:27 - loss: 1.6779 - accuracy: 0.62 - ETA: 1:10 - loss: 1.6722 - accuracy: 0.62 - ETA: 52s - loss: 1.6683 - accuracy: 0.6251 - ETA: 35s - loss: 1.6601 - accuracy: 0.626 - ETA: 17s - loss: 1.6600 - accuracy: 0.626 - ETA: 0s - loss: 1.6504 - accuracy: 0.628 - 1834s 18s/step - loss: 1.6504 - accuracy: 0.6281 - val_loss: 1.3942 - val_accuracy: 0.5571\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.7110 - accuracy: 0.81 - ETA: 14:51 - loss: 1.0139 - accuracy: 0.734 - ETA: 19:33 - loss: 0.9887 - accuracy: 0.718 - ETA: 21:50 - loss: 0.9802 - accuracy: 0.695 - ETA: 23:05 - loss: 0.9554 - accuracy: 0.718 - ETA: 23:49 - loss: 1.0129 - accuracy: 0.677 - ETA: 24:15 - loss: 1.0571 - accuracy: 0.647 - ETA: 24:31 - loss: 1.0651 - accuracy: 0.640 - ETA: 24:38 - loss: 1.0308 - accuracy: 0.642 - ETA: 24:41 - loss: 1.0099 - accuracy: 0.650 - ETA: 24:41 - loss: 0.9902 - accuracy: 0.661 - ETA: 24:36 - loss: 1.0295 - accuracy: 0.651 - ETA: 24:31 - loss: 1.0339 - accuracy: 0.649 - ETA: 24:23 - loss: 1.0227 - accuracy: 0.651 - ETA: 24:15 - loss: 1.0397 - accuracy: 0.652 - ETA: 24:06 - loss: 1.0487 - accuracy: 0.652 - ETA: 23:54 - loss: 1.0870 - accuracy: 0.634 - ETA: 23:37 - loss: 1.0863 - accuracy: 0.632 - ETA: 23:25 - loss: 1.0799 - accuracy: 0.637 - ETA: 23:13 - loss: 1.0795 - accuracy: 0.642 - ETA: 23:00 - loss: 1.0856 - accuracy: 0.646 - ETA: 22:46 - loss: 1.1049 - accuracy: 0.639 - ETA: 22:32 - loss: 1.1156 - accuracy: 0.637 - ETA: 22:19 - loss: 1.1047 - accuracy: 0.641 - ETA: 22:04 - loss: 1.1194 - accuracy: 0.637 - ETA: 21:50 - loss: 1.1093 - accuracy: 0.639 - ETA: 21:35 - loss: 1.1061 - accuracy: 0.643 - ETA: 21:20 - loss: 1.0961 - accuracy: 0.648 - ETA: 21:05 - loss: 1.1002 - accuracy: 0.651 - ETA: 20:49 - loss: 1.1100 - accuracy: 0.653 - ETA: 20:33 - loss: 1.1121 - accuracy: 0.652 - ETA: 20:18 - loss: 1.1102 - accuracy: 0.650 - ETA: 20:01 - loss: 1.1169 - accuracy: 0.648 - ETA: 19:46 - loss: 1.1162 - accuracy: 0.649 - ETA: 19:30 - loss: 1.1370 - accuracy: 0.643 - ETA: 19:13 - loss: 1.1511 - accuracy: 0.642 - ETA: 18:57 - loss: 1.1336 - accuracy: 0.648 - ETA: 18:40 - loss: 1.1464 - accuracy: 0.647 - ETA: 18:24 - loss: 1.1395 - accuracy: 0.650 - ETA: 18:07 - loss: 1.1307 - accuracy: 0.653 - ETA: 17:51 - loss: 1.1430 - accuracy: 0.651 - ETA: 17:34 - loss: 1.1572 - accuracy: 0.646 - ETA: 17:17 - loss: 1.1523 - accuracy: 0.647 - ETA: 17:00 - loss: 1.1584 - accuracy: 0.645 - ETA: 16:44 - loss: 1.1564 - accuracy: 0.642 - ETA: 16:27 - loss: 1.1563 - accuracy: 0.641 - ETA: 16:10 - loss: 1.1535 - accuracy: 0.640 - ETA: 15:53 - loss: 1.1506 - accuracy: 0.641 - ETA: 15:36 - loss: 1.1380 - accuracy: 0.645 - ETA: 15:19 - loss: 1.1329 - accuracy: 0.646 - ETA: 15:03 - loss: 1.1324 - accuracy: 0.647 - ETA: 14:46 - loss: 1.1278 - accuracy: 0.649 - ETA: 14:29 - loss: 1.1343 - accuracy: 0.648 - ETA: 14:12 - loss: 1.2964 - accuracy: 0.644 - ETA: 13:55 - loss: 1.2865 - accuracy: 0.647 - ETA: 13:37 - loss: 1.2940 - accuracy: 0.648 - ETA: 13:20 - loss: 1.2852 - accuracy: 0.649 - ETA: 13:03 - loss: 1.2749 - accuracy: 0.652 - ETA: 12:46 - loss: 1.2719 - accuracy: 0.652 - ETA: 12:29 - loss: 1.2639 - accuracy: 0.653 - ETA: 12:12 - loss: 1.2617 - accuracy: 0.654 - ETA: 11:54 - loss: 1.2545 - accuracy: 0.656 - ETA: 11:37 - loss: 1.2561 - accuracy: 0.655 - ETA: 11:20 - loss: 1.2496 - accuracy: 0.656 - ETA: 11:02 - loss: 1.2497 - accuracy: 0.654 - ETA: 10:45 - loss: 1.2428 - accuracy: 0.654 - ETA: 10:28 - loss: 1.2373 - accuracy: 0.655 - ETA: 10:11 - loss: 1.2314 - accuracy: 0.656 - ETA: 9:53 - loss: 1.2238 - accuracy: 0.657 - ETA: 9:36 - loss: 1.2152 - accuracy: 0.66 - ETA: 9:19 - loss: 1.2094 - accuracy: 0.66 - ETA: 9:01 - loss: 1.2126 - accuracy: 0.66 - ETA: 8:44 - loss: 1.2094 - accuracy: 0.66 - ETA: 8:27 - loss: 1.2011 - accuracy: 0.66 - ETA: 8:09 - loss: 1.1966 - accuracy: 0.66 - ETA: 7:52 - loss: 1.1964 - accuracy: 0.65 - ETA: 7:34 - loss: 1.1932 - accuracy: 0.65 - ETA: 7:17 - loss: 1.1902 - accuracy: 0.65 - ETA: 6:59 - loss: 1.1880 - accuracy: 0.65 - ETA: 6:42 - loss: 1.1838 - accuracy: 0.66 - ETA: 6:25 - loss: 1.1811 - accuracy: 0.66 - ETA: 6:07 - loss: 1.1784 - accuracy: 0.65 - ETA: 5:50 - loss: 1.1840 - accuracy: 0.65 - ETA: 5:32 - loss: 1.1805 - accuracy: 0.65 - ETA: 5:15 - loss: 1.1816 - accuracy: 0.65 - ETA: 4:57 - loss: 1.1771 - accuracy: 0.65 - ETA: 4:40 - loss: 1.1758 - accuracy: 0.65 - ETA: 4:22 - loss: 1.1728 - accuracy: 0.65 - ETA: 4:05 - loss: 1.1681 - accuracy: 0.65 - ETA: 3:47 - loss: 1.1644 - accuracy: 0.65 - ETA: 3:30 - loss: 1.1623 - accuracy: 0.65 - ETA: 3:12 - loss: 1.1585 - accuracy: 0.66 - ETA: 2:55 - loss: 1.1559 - accuracy: 0.66 - ETA: 2:37 - loss: 1.1509 - accuracy: 0.66 - ETA: 2:20 - loss: 1.1474 - accuracy: 0.66 - ETA: 2:02 - loss: 1.1465 - accuracy: 0.66 - ETA: 1:45 - loss: 1.1416 - accuracy: 0.66 - ETA: 1:27 - loss: 1.1391 - accuracy: 0.66 - ETA: 1:10 - loss: 1.1338 - accuracy: 0.66 - ETA: 52s - loss: 1.1280 - accuracy: 0.6667 - ETA: 35s - loss: 1.1276 - accuracy: 0.665 - ETA: 17s - loss: 1.1279 - accuracy: 0.664 - ETA: 0s - loss: 1.1256 - accuracy: 0.663 - 1828s 18s/step - loss: 1.1256 - accuracy: 0.6633 - val_loss: 0.8294 - val_accuracy: 0.7174\n",
      "Epoch 10/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7157 - accuracy: 0.71 - ETA: 14:50 - loss: 0.7647 - accuracy: 0.687 - ETA: 19:34 - loss: 0.8537 - accuracy: 0.677 - ETA: 21:55 - loss: 0.7855 - accuracy: 0.718 - ETA: 23:06 - loss: 0.8694 - accuracy: 0.693 - ETA: 23:50 - loss: 0.8904 - accuracy: 0.692 - ETA: 24:17 - loss: 0.8692 - accuracy: 0.705 - ETA: 24:33 - loss: 0.8630 - accuracy: 0.710 - ETA: 24:40 - loss: 0.8630 - accuracy: 0.715 - ETA: 24:44 - loss: 0.8588 - accuracy: 0.718 - ETA: 24:44 - loss: 0.8606 - accuracy: 0.710 - ETA: 24:40 - loss: 0.8574 - accuracy: 0.703 - ETA: 24:33 - loss: 0.8470 - accuracy: 0.704 - ETA: 24:27 - loss: 0.8600 - accuracy: 0.692 - ETA: 24:17 - loss: 0.8826 - accuracy: 0.685 - ETA: 24:07 - loss: 0.8690 - accuracy: 0.689 - ETA: 23:55 - loss: 0.8638 - accuracy: 0.691 - ETA: 23:44 - loss: 0.8619 - accuracy: 0.691 - ETA: 23:31 - loss: 0.8482 - accuracy: 0.695 - ETA: 23:19 - loss: 0.8476 - accuracy: 0.693 - ETA: 23:07 - loss: 0.8648 - accuracy: 0.687 - ETA: 22:53 - loss: 0.8879 - accuracy: 0.680 - ETA: 22:39 - loss: 0.8883 - accuracy: 0.679 - ETA: 22:24 - loss: 0.8900 - accuracy: 0.681 - ETA: 22:09 - loss: 0.8951 - accuracy: 0.676 - ETA: 21:53 - loss: 0.9092 - accuracy: 0.667 - ETA: 21:38 - loss: 0.9074 - accuracy: 0.665 - ETA: 21:22 - loss: 0.8964 - accuracy: 0.668 - ETA: 21:07 - loss: 0.8924 - accuracy: 0.669 - ETA: 20:51 - loss: 1.0163 - accuracy: 0.669 - ETA: 20:35 - loss: 1.0082 - accuracy: 0.668 - ETA: 20:19 - loss: 1.0017 - accuracy: 0.668 - ETA: 20:03 - loss: 0.9962 - accuracy: 0.674 - ETA: 19:47 - loss: 0.9865 - accuracy: 0.678 - ETA: 19:31 - loss: 0.9731 - accuracy: 0.681 - ETA: 19:14 - loss: 0.9769 - accuracy: 0.680 - ETA: 18:58 - loss: 0.9761 - accuracy: 0.680 - ETA: 18:42 - loss: 0.9777 - accuracy: 0.682 - ETA: 18:25 - loss: 0.9776 - accuracy: 0.685 - ETA: 18:09 - loss: 0.9751 - accuracy: 0.685 - ETA: 17:52 - loss: 0.9939 - accuracy: 0.685 - ETA: 17:36 - loss: 0.9891 - accuracy: 0.685 - ETA: 17:19 - loss: 0.9876 - accuracy: 0.684 - ETA: 17:02 - loss: 0.9845 - accuracy: 0.685 - ETA: 16:45 - loss: 0.9785 - accuracy: 0.687 - ETA: 16:28 - loss: 0.9730 - accuracy: 0.688 - ETA: 16:10 - loss: 0.9718 - accuracy: 0.688 - ETA: 15:53 - loss: 0.9700 - accuracy: 0.687 - ETA: 15:36 - loss: 0.9674 - accuracy: 0.689 - ETA: 15:19 - loss: 0.9605 - accuracy: 0.689 - ETA: 15:02 - loss: 0.9649 - accuracy: 0.689 - ETA: 14:45 - loss: 0.9587 - accuracy: 0.689 - ETA: 14:28 - loss: 0.9570 - accuracy: 0.690 - ETA: 14:11 - loss: 0.9508 - accuracy: 0.692 - ETA: 13:54 - loss: 0.9476 - accuracy: 0.694 - ETA: 13:37 - loss: 0.9453 - accuracy: 0.694 - ETA: 13:20 - loss: 0.9368 - accuracy: 0.697 - ETA: 13:03 - loss: 0.9339 - accuracy: 0.699 - ETA: 12:46 - loss: 0.9281 - accuracy: 0.701 - ETA: 12:28 - loss: 0.9336 - accuracy: 0.699 - ETA: 12:11 - loss: 0.9324 - accuracy: 0.699 - ETA: 11:54 - loss: 0.9374 - accuracy: 0.697 - ETA: 11:37 - loss: 0.9355 - accuracy: 0.696 - ETA: 11:20 - loss: 0.9343 - accuracy: 0.696 - ETA: 11:03 - loss: 0.9343 - accuracy: 0.694 - ETA: 10:45 - loss: 0.9416 - accuracy: 0.693 - ETA: 10:28 - loss: 0.9446 - accuracy: 0.692 - ETA: 10:11 - loss: 0.9496 - accuracy: 0.689 - ETA: 9:53 - loss: 0.9439 - accuracy: 0.691 - ETA: 9:36 - loss: 0.9441 - accuracy: 0.69 - ETA: 9:19 - loss: 0.9411 - accuracy: 0.69 - ETA: 9:01 - loss: 0.9405 - accuracy: 0.69 - ETA: 8:44 - loss: 0.9386 - accuracy: 0.69 - ETA: 8:27 - loss: 0.9397 - accuracy: 0.69 - ETA: 8:09 - loss: 0.9377 - accuracy: 0.69 - ETA: 7:52 - loss: 0.9376 - accuracy: 0.69 - ETA: 7:34 - loss: 0.9356 - accuracy: 0.69 - ETA: 7:17 - loss: 0.9374 - accuracy: 0.69 - ETA: 6:59 - loss: 0.9365 - accuracy: 0.69 - ETA: 6:42 - loss: 0.9329 - accuracy: 0.69 - ETA: 6:25 - loss: 0.9293 - accuracy: 0.69 - ETA: 6:07 - loss: 0.9272 - accuracy: 0.69 - ETA: 5:50 - loss: 0.9221 - accuracy: 0.69 - ETA: 5:32 - loss: 0.9191 - accuracy: 0.69 - ETA: 5:15 - loss: 0.9191 - accuracy: 0.69 - ETA: 4:57 - loss: 0.9229 - accuracy: 0.69 - ETA: 4:40 - loss: 0.9209 - accuracy: 0.69 - ETA: 4:22 - loss: 0.9208 - accuracy: 0.69 - ETA: 4:05 - loss: 0.9193 - accuracy: 0.69 - ETA: 3:47 - loss: 0.9146 - accuracy: 0.69 - ETA: 3:30 - loss: 0.9125 - accuracy: 0.69 - ETA: 3:12 - loss: 0.9114 - accuracy: 0.69 - ETA: 2:55 - loss: 0.9090 - accuracy: 0.69 - ETA: 2:37 - loss: 0.9071 - accuracy: 0.69 - ETA: 2:20 - loss: 0.9067 - accuracy: 0.69 - ETA: 2:02 - loss: 0.9079 - accuracy: 0.69 - ETA: 1:45 - loss: 0.9047 - accuracy: 0.69 - ETA: 1:27 - loss: 0.9052 - accuracy: 0.69 - ETA: 1:10 - loss: 0.9050 - accuracy: 0.69 - ETA: 52s - loss: 0.9052 - accuracy: 0.6951 - ETA: 35s - loss: 0.9041 - accuracy: 0.694 - ETA: 17s - loss: 0.9029 - accuracy: 0.694 - ETA: 0s - loss: 0.9024 - accuracy: 0.693 - 1829s 18s/step - loss: 0.9024 - accuracy: 0.6937 - val_loss: 1.1640 - val_accuracy: 0.5516\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.7495 - accuracy: 0.71 - ETA: 15:00 - loss: 0.6835 - accuracy: 0.718 - ETA: 19:45 - loss: 0.7067 - accuracy: 0.708 - ETA: 21:59 - loss: 0.7094 - accuracy: 0.710 - ETA: 23:14 - loss: 0.6836 - accuracy: 0.737 - ETA: 23:56 - loss: 0.7020 - accuracy: 0.739 - ETA: 24:20 - loss: 0.6745 - accuracy: 0.754 - ETA: 24:35 - loss: 0.6565 - accuracy: 0.769 - ETA: 24:44 - loss: 0.7033 - accuracy: 0.756 - ETA: 24:46 - loss: 0.7439 - accuracy: 0.740 - ETA: 24:45 - loss: 0.7266 - accuracy: 0.741 - ETA: 24:45 - loss: 0.7244 - accuracy: 0.744 - ETA: 24:38 - loss: 0.7471 - accuracy: 0.740 - ETA: 24:30 - loss: 0.7487 - accuracy: 0.738 - ETA: 24:21 - loss: 0.7636 - accuracy: 0.739 - ETA: 24:11 - loss: 0.7664 - accuracy: 0.736 - ETA: 24:00 - loss: 0.7714 - accuracy: 0.735 - ETA: 23:48 - loss: 0.7758 - accuracy: 0.734 - ETA: 23:34 - loss: 0.7788 - accuracy: 0.731 - ETA: 23:21 - loss: 0.7841 - accuracy: 0.728 - ETA: 23:08 - loss: 0.7763 - accuracy: 0.729 - ETA: 22:54 - loss: 0.7805 - accuracy: 0.725 - ETA: 22:40 - loss: 0.7836 - accuracy: 0.721 - ETA: 22:21 - loss: 0.7805 - accuracy: 0.719 - ETA: 22:07 - loss: 0.7745 - accuracy: 0.724 - ETA: 21:52 - loss: 0.7774 - accuracy: 0.725 - ETA: 21:37 - loss: 0.7853 - accuracy: 0.721 - ETA: 21:22 - loss: 0.7812 - accuracy: 0.722 - ETA: 21:06 - loss: 0.7892 - accuracy: 0.721 - ETA: 20:50 - loss: 0.7919 - accuracy: 0.722 - ETA: 20:35 - loss: 0.7898 - accuracy: 0.722 - ETA: 20:19 - loss: 0.7941 - accuracy: 0.719 - ETA: 20:03 - loss: 0.7959 - accuracy: 0.719 - ETA: 19:47 - loss: 0.8015 - accuracy: 0.717 - ETA: 19:30 - loss: 0.8001 - accuracy: 0.716 - ETA: 19:14 - loss: 0.7989 - accuracy: 0.714 - ETA: 18:57 - loss: 0.8035 - accuracy: 0.712 - ETA: 18:41 - loss: 0.8106 - accuracy: 0.706 - ETA: 18:25 - loss: 0.8069 - accuracy: 0.709 - ETA: 18:08 - loss: 0.8093 - accuracy: 0.709 - ETA: 17:51 - loss: 0.8028 - accuracy: 0.713 - ETA: 17:35 - loss: 0.8070 - accuracy: 0.713 - ETA: 17:18 - loss: 0.8044 - accuracy: 0.716 - ETA: 17:01 - loss: 0.8016 - accuracy: 0.716 - ETA: 16:45 - loss: 0.8055 - accuracy: 0.713 - ETA: 16:28 - loss: 0.8020 - accuracy: 0.715 - ETA: 16:11 - loss: 0.8044 - accuracy: 0.714 - ETA: 15:54 - loss: 0.8040 - accuracy: 0.713 - ETA: 15:38 - loss: 0.8021 - accuracy: 0.713 - ETA: 15:21 - loss: 0.8040 - accuracy: 0.711 - ETA: 15:04 - loss: 0.8042 - accuracy: 0.709 - ETA: 14:47 - loss: 0.7967 - accuracy: 0.713 - ETA: 14:30 - loss: 0.7969 - accuracy: 0.713 - ETA: 14:12 - loss: 0.7948 - accuracy: 0.714 - ETA: 13:55 - loss: 0.8010 - accuracy: 0.712 - ETA: 13:38 - loss: 0.8046 - accuracy: 0.710 - ETA: 13:21 - loss: 0.8123 - accuracy: 0.708 - ETA: 13:04 - loss: 0.8138 - accuracy: 0.707 - ETA: 12:47 - loss: 0.8157 - accuracy: 0.707 - ETA: 12:29 - loss: 0.8135 - accuracy: 0.707 - ETA: 12:12 - loss: 0.8156 - accuracy: 0.707 - ETA: 11:55 - loss: 0.8117 - accuracy: 0.710 - ETA: 11:38 - loss: 0.8167 - accuracy: 0.707 - ETA: 11:21 - loss: 0.8144 - accuracy: 0.708 - ETA: 11:03 - loss: 0.8123 - accuracy: 0.709 - ETA: 10:46 - loss: 0.8133 - accuracy: 0.706 - ETA: 10:28 - loss: 0.8110 - accuracy: 0.706 - ETA: 10:11 - loss: 0.8036 - accuracy: 0.710 - ETA: 9:54 - loss: 0.8060 - accuracy: 0.709 - ETA: 9:36 - loss: 0.8055 - accuracy: 0.70 - ETA: 9:19 - loss: 0.8080 - accuracy: 0.70 - ETA: 9:02 - loss: 0.8085 - accuracy: 0.70 - ETA: 8:44 - loss: 0.8087 - accuracy: 0.70 - ETA: 8:27 - loss: 0.8075 - accuracy: 0.70 - ETA: 8:09 - loss: 0.8083 - accuracy: 0.70 - ETA: 7:52 - loss: 0.8150 - accuracy: 0.70 - ETA: 7:35 - loss: 0.8161 - accuracy: 0.70 - ETA: 7:17 - loss: 0.8170 - accuracy: 0.70 - ETA: 7:00 - loss: 0.8213 - accuracy: 0.70 - ETA: 6:42 - loss: 0.8235 - accuracy: 0.70 - ETA: 6:25 - loss: 0.8243 - accuracy: 0.70 - ETA: 6:07 - loss: 0.8263 - accuracy: 0.70 - ETA: 5:50 - loss: 0.8272 - accuracy: 0.70 - ETA: 5:32 - loss: 0.8281 - accuracy: 0.70 - ETA: 5:15 - loss: 0.8254 - accuracy: 0.70 - ETA: 4:57 - loss: 0.8240 - accuracy: 0.70 - ETA: 4:40 - loss: 0.8268 - accuracy: 0.70 - ETA: 4:22 - loss: 0.8245 - accuracy: 0.70 - ETA: 4:05 - loss: 0.8240 - accuracy: 0.70 - ETA: 3:47 - loss: 0.8244 - accuracy: 0.70 - ETA: 3:30 - loss: 0.8284 - accuracy: 0.70 - ETA: 3:12 - loss: 0.8308 - accuracy: 0.69 - ETA: 2:55 - loss: 0.8280 - accuracy: 0.70 - ETA: 2:37 - loss: 0.8276 - accuracy: 0.70 - ETA: 2:20 - loss: 0.8314 - accuracy: 0.69 - ETA: 2:02 - loss: 0.8313 - accuracy: 0.69 - ETA: 1:45 - loss: 0.8299 - accuracy: 0.70 - ETA: 1:27 - loss: 0.8297 - accuracy: 0.70 - ETA: 1:10 - loss: 0.8283 - accuracy: 0.70 - ETA: 52s - loss: 0.8292 - accuracy: 0.7004 - ETA: 35s - loss: 0.8287 - accuracy: 0.700 - ETA: 17s - loss: 0.8275 - accuracy: 0.701 - ETA: 0s - loss: 0.8268 - accuracy: 0.701 - 1829s 18s/step - loss: 0.8268 - accuracy: 0.7010 - val_loss: 1.4184 - val_accuracy: 0.5462\n",
      "Epoch 12/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.6829 - accuracy: 0.81 - ETA: 14:51 - loss: 0.7859 - accuracy: 0.765 - ETA: 19:38 - loss: 0.7952 - accuracy: 0.750 - ETA: 21:49 - loss: 0.8026 - accuracy: 0.718 - ETA: 23:04 - loss: 0.8497 - accuracy: 0.725 - ETA: 23:48 - loss: 0.8356 - accuracy: 0.739 - ETA: 24:15 - loss: 0.8217 - accuracy: 0.745 - ETA: 24:30 - loss: 0.8201 - accuracy: 0.730 - ETA: 24:39 - loss: 0.7948 - accuracy: 0.739 - ETA: 24:45 - loss: 0.7897 - accuracy: 0.728 - ETA: 24:43 - loss: 0.7682 - accuracy: 0.735 - ETA: 24:40 - loss: 0.7837 - accuracy: 0.737 - ETA: 24:33 - loss: 0.7947 - accuracy: 0.728 - ETA: 24:25 - loss: 0.7857 - accuracy: 0.732 - ETA: 24:16 - loss: 0.7956 - accuracy: 0.729 - ETA: 24:05 - loss: 0.7818 - accuracy: 0.732 - ETA: 23:55 - loss: 0.7646 - accuracy: 0.739 - ETA: 23:43 - loss: 0.7657 - accuracy: 0.739 - ETA: 23:31 - loss: 0.7610 - accuracy: 0.741 - ETA: 23:17 - loss: 0.7598 - accuracy: 0.742 - ETA: 23:03 - loss: 0.7514 - accuracy: 0.747 - ETA: 22:50 - loss: 0.7445 - accuracy: 0.748 - ETA: 22:36 - loss: 0.7473 - accuracy: 0.748 - ETA: 22:22 - loss: 0.7372 - accuracy: 0.755 - ETA: 22:07 - loss: 0.7556 - accuracy: 0.745 - ETA: 21:53 - loss: 0.7701 - accuracy: 0.740 - ETA: 21:38 - loss: 0.7849 - accuracy: 0.735 - ETA: 21:22 - loss: 0.7878 - accuracy: 0.732 - ETA: 21:07 - loss: 0.7917 - accuracy: 0.730 - ETA: 20:52 - loss: 0.7907 - accuracy: 0.729 - ETA: 20:36 - loss: 0.7923 - accuracy: 0.726 - ETA: 20:20 - loss: 0.7941 - accuracy: 0.724 - ETA: 20:04 - loss: 0.8001 - accuracy: 0.720 - ETA: 19:48 - loss: 0.8042 - accuracy: 0.720 - ETA: 19:32 - loss: 0.8057 - accuracy: 0.720 - ETA: 19:16 - loss: 0.7994 - accuracy: 0.723 - ETA: 18:59 - loss: 0.7975 - accuracy: 0.721 - ETA: 18:43 - loss: 0.7934 - accuracy: 0.723 - ETA: 18:26 - loss: 0.7966 - accuracy: 0.721 - ETA: 18:10 - loss: 0.7931 - accuracy: 0.723 - ETA: 17:54 - loss: 0.7940 - accuracy: 0.725 - ETA: 17:37 - loss: 0.7960 - accuracy: 0.724 - ETA: 17:20 - loss: 0.7959 - accuracy: 0.723 - ETA: 17:04 - loss: 0.7925 - accuracy: 0.724 - ETA: 16:47 - loss: 0.7993 - accuracy: 0.722 - ETA: 16:30 - loss: 0.7958 - accuracy: 0.724 - ETA: 16:13 - loss: 0.7962 - accuracy: 0.723 - ETA: 15:56 - loss: 0.7939 - accuracy: 0.723 - ETA: 15:39 - loss: 0.7947 - accuracy: 0.722 - ETA: 15:22 - loss: 0.7953 - accuracy: 0.721 - ETA: 15:05 - loss: 0.7929 - accuracy: 0.721 - ETA: 14:48 - loss: 0.7962 - accuracy: 0.721 - ETA: 14:31 - loss: 0.7908 - accuracy: 0.723 - ETA: 14:13 - loss: 0.7972 - accuracy: 0.722 - ETA: 13:56 - loss: 0.7939 - accuracy: 0.723 - ETA: 13:39 - loss: 0.7933 - accuracy: 0.722 - ETA: 13:22 - loss: 0.7949 - accuracy: 0.722 - ETA: 13:05 - loss: 0.7917 - accuracy: 0.723 - ETA: 12:47 - loss: 0.7938 - accuracy: 0.722 - ETA: 12:30 - loss: 0.7991 - accuracy: 0.720 - ETA: 12:13 - loss: 0.7980 - accuracy: 0.719 - ETA: 11:56 - loss: 0.8006 - accuracy: 0.718 - ETA: 11:38 - loss: 0.7993 - accuracy: 0.718 - ETA: 11:21 - loss: 0.8028 - accuracy: 0.716 - ETA: 11:04 - loss: 0.8024 - accuracy: 0.716 - ETA: 10:47 - loss: 0.8022 - accuracy: 0.716 - ETA: 10:29 - loss: 0.8047 - accuracy: 0.716 - ETA: 10:12 - loss: 0.8035 - accuracy: 0.715 - ETA: 9:54 - loss: 0.8051 - accuracy: 0.713 - ETA: 9:37 - loss: 0.8033 - accuracy: 0.71 - ETA: 9:20 - loss: 0.8012 - accuracy: 0.71 - ETA: 9:02 - loss: 0.8008 - accuracy: 0.71 - ETA: 8:45 - loss: 0.8013 - accuracy: 0.71 - ETA: 8:27 - loss: 0.8035 - accuracy: 0.71 - ETA: 8:10 - loss: 0.8000 - accuracy: 0.71 - ETA: 7:52 - loss: 0.8015 - accuracy: 0.71 - ETA: 7:35 - loss: 0.8049 - accuracy: 0.71 - ETA: 7:17 - loss: 0.7999 - accuracy: 0.71 - ETA: 7:00 - loss: 0.8001 - accuracy: 0.71 - ETA: 6:42 - loss: 0.7970 - accuracy: 0.71 - ETA: 6:25 - loss: 0.7971 - accuracy: 0.71 - ETA: 6:07 - loss: 0.7964 - accuracy: 0.71 - ETA: 5:50 - loss: 0.7949 - accuracy: 0.71 - ETA: 5:32 - loss: 0.7981 - accuracy: 0.71 - ETA: 5:15 - loss: 0.7988 - accuracy: 0.71 - ETA: 4:57 - loss: 0.7985 - accuracy: 0.71 - ETA: 4:40 - loss: 0.7995 - accuracy: 0.71 - ETA: 4:23 - loss: 0.8009 - accuracy: 0.71 - ETA: 4:05 - loss: 0.7988 - accuracy: 0.71 - ETA: 3:48 - loss: 0.7975 - accuracy: 0.71 - ETA: 3:30 - loss: 0.7976 - accuracy: 0.71 - ETA: 3:12 - loss: 0.7957 - accuracy: 0.71 - ETA: 2:55 - loss: 0.7950 - accuracy: 0.71 - ETA: 2:37 - loss: 0.7978 - accuracy: 0.71 - ETA: 2:20 - loss: 0.7966 - accuracy: 0.71 - ETA: 2:02 - loss: 0.7965 - accuracy: 0.71 - ETA: 1:45 - loss: 0.7934 - accuracy: 0.71 - ETA: 1:27 - loss: 0.7928 - accuracy: 0.71 - ETA: 1:10 - loss: 0.7918 - accuracy: 0.71 - ETA: 52s - loss: 0.7901 - accuracy: 0.7170 - ETA: 35s - loss: 0.7908 - accuracy: 0.718 - ETA: 17s - loss: 0.7923 - accuracy: 0.717 - ETA: 0s - loss: 0.7928 - accuracy: 0.717 - 1829s 18s/step - loss: 0.7928 - accuracy: 0.7171 - val_loss: 1.3280 - val_accuracy: 0.5598\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.8357 - accuracy: 0.65 - ETA: 14:51 - loss: 0.8010 - accuracy: 0.703 - ETA: 19:39 - loss: 0.7878 - accuracy: 0.687 - ETA: 21:52 - loss: 0.7535 - accuracy: 0.695 - ETA: 23:05 - loss: 0.7155 - accuracy: 0.700 - ETA: 23:49 - loss: 0.7390 - accuracy: 0.697 - ETA: 24:18 - loss: 0.8055 - accuracy: 0.683 - ETA: 24:37 - loss: 0.7619 - accuracy: 0.699 - ETA: 24:44 - loss: 0.7391 - accuracy: 0.715 - ETA: 24:49 - loss: 0.7323 - accuracy: 0.715 - ETA: 24:48 - loss: 0.7514 - accuracy: 0.704 - ETA: 24:43 - loss: 0.7513 - accuracy: 0.705 - ETA: 24:37 - loss: 0.7768 - accuracy: 0.697 - ETA: 24:28 - loss: 0.7938 - accuracy: 0.689 - ETA: 24:19 - loss: 0.7793 - accuracy: 0.695 - ETA: 24:10 - loss: 0.7815 - accuracy: 0.693 - ETA: 23:58 - loss: 0.7897 - accuracy: 0.698 - ETA: 23:46 - loss: 0.7847 - accuracy: 0.701 - ETA: 23:33 - loss: 0.7790 - accuracy: 0.707 - ETA: 23:20 - loss: 0.7862 - accuracy: 0.701 - ETA: 23:07 - loss: 0.7802 - accuracy: 0.702 - ETA: 22:53 - loss: 0.7792 - accuracy: 0.703 - ETA: 22:38 - loss: 0.7766 - accuracy: 0.709 - ETA: 22:24 - loss: 0.7764 - accuracy: 0.707 - ETA: 22:09 - loss: 0.7824 - accuracy: 0.706 - ETA: 21:53 - loss: 0.7805 - accuracy: 0.709 - ETA: 21:39 - loss: 0.7732 - accuracy: 0.713 - ETA: 21:23 - loss: 0.7738 - accuracy: 0.712 - ETA: 21:08 - loss: 0.7651 - accuracy: 0.715 - ETA: 20:52 - loss: 0.7631 - accuracy: 0.713 - ETA: 20:37 - loss: 0.7550 - accuracy: 0.715 - ETA: 20:21 - loss: 0.7506 - accuracy: 0.716 - ETA: 20:05 - loss: 0.7529 - accuracy: 0.715 - ETA: 19:49 - loss: 0.7551 - accuracy: 0.715 - ETA: 19:32 - loss: 0.7536 - accuracy: 0.717 - ETA: 19:16 - loss: 0.7497 - accuracy: 0.719 - ETA: 19:00 - loss: 0.7483 - accuracy: 0.721 - ETA: 18:43 - loss: 0.7463 - accuracy: 0.720 - ETA: 18:27 - loss: 0.7479 - accuracy: 0.719 - ETA: 18:11 - loss: 0.7514 - accuracy: 0.719 - ETA: 17:54 - loss: 0.7548 - accuracy: 0.719 - ETA: 17:37 - loss: 0.7510 - accuracy: 0.721 - ETA: 17:21 - loss: 0.7534 - accuracy: 0.722 - ETA: 17:04 - loss: 0.7527 - accuracy: 0.723 - ETA: 16:47 - loss: 0.7485 - accuracy: 0.725 - ETA: 16:30 - loss: 0.7405 - accuracy: 0.729 - ETA: 16:14 - loss: 0.7481 - accuracy: 0.726 - ETA: 15:56 - loss: 0.7576 - accuracy: 0.724 - ETA: 15:39 - loss: 0.7623 - accuracy: 0.721 - ETA: 15:22 - loss: 0.7666 - accuracy: 0.720 - ETA: 15:05 - loss: 0.7602 - accuracy: 0.722 - ETA: 14:48 - loss: 0.7578 - accuracy: 0.724 - ETA: 14:31 - loss: 0.7604 - accuracy: 0.723 - ETA: 14:14 - loss: 0.7634 - accuracy: 0.722 - ETA: 13:57 - loss: 0.7680 - accuracy: 0.720 - ETA: 13:40 - loss: 0.7727 - accuracy: 0.718 - ETA: 13:23 - loss: 0.7697 - accuracy: 0.719 - ETA: 13:06 - loss: 0.7693 - accuracy: 0.719 - ETA: 12:48 - loss: 0.7701 - accuracy: 0.717 - ETA: 12:31 - loss: 0.7706 - accuracy: 0.716 - ETA: 12:14 - loss: 0.7684 - accuracy: 0.716 - ETA: 11:56 - loss: 0.7670 - accuracy: 0.716 - ETA: 11:39 - loss: 0.7690 - accuracy: 0.716 - ETA: 11:22 - loss: 0.7660 - accuracy: 0.717 - ETA: 11:04 - loss: 0.7673 - accuracy: 0.717 - ETA: 10:47 - loss: 0.7656 - accuracy: 0.717 - ETA: 10:30 - loss: 0.7689 - accuracy: 0.718 - ETA: 10:12 - loss: 0.7691 - accuracy: 0.718 - ETA: 9:55 - loss: 0.7696 - accuracy: 0.718 - ETA: 9:38 - loss: 0.7710 - accuracy: 0.71 - ETA: 9:20 - loss: 0.7744 - accuracy: 0.71 - ETA: 9:03 - loss: 0.7749 - accuracy: 0.71 - ETA: 8:45 - loss: 0.7745 - accuracy: 0.71 - ETA: 8:28 - loss: 0.7765 - accuracy: 0.71 - ETA: 8:10 - loss: 0.7756 - accuracy: 0.71 - ETA: 7:53 - loss: 0.7751 - accuracy: 0.71 - ETA: 7:35 - loss: 0.7743 - accuracy: 0.71 - ETA: 7:18 - loss: 0.7755 - accuracy: 0.71 - ETA: 7:01 - loss: 0.7746 - accuracy: 0.71 - ETA: 6:43 - loss: 0.7710 - accuracy: 0.71 - ETA: 6:25 - loss: 0.7718 - accuracy: 0.71 - ETA: 6:08 - loss: 0.7722 - accuracy: 0.71 - ETA: 5:50 - loss: 0.7730 - accuracy: 0.71 - ETA: 5:33 - loss: 0.7724 - accuracy: 0.71 - ETA: 5:15 - loss: 0.7726 - accuracy: 0.71 - ETA: 4:58 - loss: 0.7708 - accuracy: 0.71 - ETA: 4:40 - loss: 0.7696 - accuracy: 0.71 - ETA: 4:23 - loss: 0.7677 - accuracy: 0.71 - ETA: 4:05 - loss: 0.7663 - accuracy: 0.71 - ETA: 3:48 - loss: 0.7705 - accuracy: 0.71 - ETA: 3:30 - loss: 0.7685 - accuracy: 0.71 - ETA: 3:13 - loss: 0.7696 - accuracy: 0.71 - ETA: 2:55 - loss: 0.7701 - accuracy: 0.71 - ETA: 2:38 - loss: 0.7701 - accuracy: 0.71 - ETA: 2:20 - loss: 0.7709 - accuracy: 0.71 - ETA: 2:03 - loss: 0.7743 - accuracy: 0.71 - ETA: 1:45 - loss: 0.7745 - accuracy: 0.71 - ETA: 1:27 - loss: 0.7737 - accuracy: 0.71 - ETA: 1:10 - loss: 0.7735 - accuracy: 0.71 - ETA: 52s - loss: 0.7714 - accuracy: 0.7170 - ETA: 35s - loss: 0.7715 - accuracy: 0.717 - ETA: 17s - loss: 0.7717 - accuracy: 0.717 - ETA: 0s - loss: 0.7736 - accuracy: 0.717 - 1832s 18s/step - loss: 0.7736 - accuracy: 0.7171 - val_loss: 0.8327 - val_accuracy: 0.7283\n",
      "Epoch 14/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.6097 - accuracy: 0.87 - ETA: 14:52 - loss: 0.6270 - accuracy: 0.812 - ETA: 19:41 - loss: 0.6818 - accuracy: 0.802 - ETA: 21:55 - loss: 0.8024 - accuracy: 0.757 - ETA: 23:11 - loss: 0.7924 - accuracy: 0.743 - ETA: 23:59 - loss: 0.7529 - accuracy: 0.739 - ETA: 24:26 - loss: 0.7571 - accuracy: 0.727 - ETA: 24:39 - loss: 0.7292 - accuracy: 0.726 - ETA: 24:45 - loss: 0.7151 - accuracy: 0.736 - ETA: 24:48 - loss: 0.7129 - accuracy: 0.734 - ETA: 24:47 - loss: 0.7045 - accuracy: 0.738 - ETA: 24:43 - loss: 0.6948 - accuracy: 0.742 - ETA: 24:38 - loss: 0.6859 - accuracy: 0.747 - ETA: 24:32 - loss: 0.6890 - accuracy: 0.745 - ETA: 24:23 - loss: 0.7047 - accuracy: 0.739 - ETA: 24:20 - loss: 0.7251 - accuracy: 0.732 - ETA: 24:11 - loss: 0.8607 - accuracy: 0.726 - ETA: 24:01 - loss: 0.8648 - accuracy: 0.724 - ETA: 23:48 - loss: 0.8801 - accuracy: 0.717 - ETA: 23:34 - loss: 0.8818 - accuracy: 0.714 - ETA: 23:19 - loss: 0.8847 - accuracy: 0.711 - ETA: 23:04 - loss: 0.8850 - accuracy: 0.709 - ETA: 22:49 - loss: 0.8796 - accuracy: 0.707 - ETA: 22:34 - loss: 0.8728 - accuracy: 0.710 - ETA: 22:19 - loss: 0.8769 - accuracy: 0.705 - ETA: 22:04 - loss: 0.8749 - accuracy: 0.704 - ETA: 21:48 - loss: 0.8653 - accuracy: 0.705 - ETA: 21:33 - loss: 0.8615 - accuracy: 0.704 - ETA: 21:17 - loss: 0.8579 - accuracy: 0.705 - ETA: 21:01 - loss: 0.8589 - accuracy: 0.704 - ETA: 20:45 - loss: 0.8510 - accuracy: 0.707 - ETA: 20:28 - loss: 0.8567 - accuracy: 0.706 - ETA: 20:12 - loss: 0.8581 - accuracy: 0.704 - ETA: 19:56 - loss: 0.8593 - accuracy: 0.704 - ETA: 19:39 - loss: 0.8548 - accuracy: 0.707 - ETA: 19:22 - loss: 0.8523 - accuracy: 0.706 - ETA: 19:06 - loss: 0.8492 - accuracy: 0.706 - ETA: 18:49 - loss: 0.8496 - accuracy: 0.705 - ETA: 18:32 - loss: 0.8444 - accuracy: 0.707 - ETA: 18:15 - loss: 0.8434 - accuracy: 0.707 - ETA: 17:58 - loss: 0.8431 - accuracy: 0.706 - ETA: 17:41 - loss: 0.8446 - accuracy: 0.704 - ETA: 17:24 - loss: 0.8458 - accuracy: 0.702 - ETA: 17:08 - loss: 0.8493 - accuracy: 0.702 - ETA: 16:51 - loss: 0.8487 - accuracy: 0.701 - ETA: 16:33 - loss: 0.8497 - accuracy: 0.699 - ETA: 16:17 - loss: 0.8438 - accuracy: 0.702 - ETA: 15:59 - loss: 0.8451 - accuracy: 0.701 - ETA: 15:42 - loss: 0.8423 - accuracy: 0.701 - ETA: 15:25 - loss: 0.8382 - accuracy: 0.702 - ETA: 15:08 - loss: 0.8372 - accuracy: 0.701 - ETA: 14:51 - loss: 0.8344 - accuracy: 0.704 - ETA: 14:34 - loss: 0.8332 - accuracy: 0.703 - ETA: 14:17 - loss: 0.8308 - accuracy: 0.704 - ETA: 13:59 - loss: 0.8294 - accuracy: 0.704 - ETA: 13:42 - loss: 0.8319 - accuracy: 0.702 - ETA: 13:25 - loss: 0.8297 - accuracy: 0.705 - ETA: 13:08 - loss: 0.8296 - accuracy: 0.705 - ETA: 12:50 - loss: 0.8222 - accuracy: 0.708 - ETA: 12:33 - loss: 0.8196 - accuracy: 0.709 - ETA: 12:16 - loss: 0.8225 - accuracy: 0.709 - ETA: 11:58 - loss: 0.8201 - accuracy: 0.709 - ETA: 11:41 - loss: 0.8185 - accuracy: 0.710 - ETA: 11:23 - loss: 0.8304 - accuracy: 0.706 - ETA: 11:06 - loss: 0.8260 - accuracy: 0.707 - ETA: 10:48 - loss: 0.8234 - accuracy: 0.709 - ETA: 10:31 - loss: 0.8279 - accuracy: 0.709 - ETA: 10:14 - loss: 0.8275 - accuracy: 0.708 - ETA: 9:56 - loss: 0.8345 - accuracy: 0.708 - ETA: 9:39 - loss: 0.8295 - accuracy: 0.71 - ETA: 9:21 - loss: 0.8276 - accuracy: 0.71 - ETA: 9:04 - loss: 0.8280 - accuracy: 0.71 - ETA: 8:46 - loss: 0.8256 - accuracy: 0.71 - ETA: 8:29 - loss: 0.8294 - accuracy: 0.71 - ETA: 8:11 - loss: 0.8291 - accuracy: 0.71 - ETA: 7:54 - loss: 0.8279 - accuracy: 0.71 - ETA: 7:36 - loss: 0.8313 - accuracy: 0.71 - ETA: 7:19 - loss: 0.8289 - accuracy: 0.71 - ETA: 7:01 - loss: 0.8294 - accuracy: 0.71 - ETA: 6:44 - loss: 0.8272 - accuracy: 0.71 - ETA: 6:26 - loss: 0.8266 - accuracy: 0.71 - ETA: 6:09 - loss: 0.8309 - accuracy: 0.71 - ETA: 5:51 - loss: 0.8276 - accuracy: 0.71 - ETA: 5:34 - loss: 0.8267 - accuracy: 0.71 - ETA: 5:16 - loss: 0.8278 - accuracy: 0.71 - ETA: 4:58 - loss: 0.8302 - accuracy: 0.71 - ETA: 4:41 - loss: 0.8293 - accuracy: 0.71 - ETA: 4:23 - loss: 0.8273 - accuracy: 0.71 - ETA: 4:06 - loss: 0.8266 - accuracy: 0.71 - ETA: 3:48 - loss: 0.8264 - accuracy: 0.71 - ETA: 3:31 - loss: 0.8260 - accuracy: 0.71 - ETA: 3:13 - loss: 0.8264 - accuracy: 0.71 - ETA: 2:55 - loss: 0.8278 - accuracy: 0.71 - ETA: 2:38 - loss: 0.8313 - accuracy: 0.71 - ETA: 2:20 - loss: 0.8342 - accuracy: 0.70 - ETA: 2:03 - loss: 0.8334 - accuracy: 0.70 - ETA: 1:45 - loss: 0.8383 - accuracy: 0.70 - ETA: 1:28 - loss: 0.8412 - accuracy: 0.70 - ETA: 1:10 - loss: 0.8418 - accuracy: 0.70 - ETA: 52s - loss: 0.8414 - accuracy: 0.7042 - ETA: 35s - loss: 0.8459 - accuracy: 0.703 - ETA: 17s - loss: 0.8463 - accuracy: 0.704 - ETA: 0s - loss: 0.8520 - accuracy: 0.702 - 1834s 18s/step - loss: 0.8520 - accuracy: 0.7025 - val_loss: 1.2120 - val_accuracy: 0.7228\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.9746 - accuracy: 0.68 - ETA: 14:48 - loss: 0.8462 - accuracy: 0.687 - ETA: 19:46 - loss: 0.7246 - accuracy: 0.718 - ETA: 22:05 - loss: 0.7678 - accuracy: 0.718 - ETA: 23:19 - loss: 0.7128 - accuracy: 0.737 - ETA: 24:01 - loss: 0.7256 - accuracy: 0.729 - ETA: 24:26 - loss: 0.7088 - accuracy: 0.723 - ETA: 24:38 - loss: 0.7501 - accuracy: 0.707 - ETA: 24:46 - loss: 0.7556 - accuracy: 0.708 - ETA: 24:48 - loss: 0.7423 - accuracy: 0.712 - ETA: 24:48 - loss: 0.7615 - accuracy: 0.707 - ETA: 24:44 - loss: 0.7902 - accuracy: 0.700 - ETA: 24:36 - loss: 0.7786 - accuracy: 0.709 - ETA: 24:28 - loss: 0.7918 - accuracy: 0.700 - ETA: 24:20 - loss: 0.7789 - accuracy: 0.708 - ETA: 24:11 - loss: 0.7792 - accuracy: 0.710 - ETA: 23:59 - loss: 0.8042 - accuracy: 0.704 - ETA: 23:42 - loss: 0.8081 - accuracy: 0.703 - ETA: 23:30 - loss: 0.7999 - accuracy: 0.709 - ETA: 23:17 - loss: 0.7946 - accuracy: 0.713 - ETA: 23:04 - loss: 0.7827 - accuracy: 0.720 - ETA: 22:50 - loss: 0.7897 - accuracy: 0.715 - ETA: 22:36 - loss: 0.7956 - accuracy: 0.711 - ETA: 22:22 - loss: 0.7983 - accuracy: 0.710 - ETA: 22:07 - loss: 0.7894 - accuracy: 0.714 - ETA: 21:52 - loss: 0.7983 - accuracy: 0.712 - ETA: 21:37 - loss: 0.7957 - accuracy: 0.715 - ETA: 21:22 - loss: 0.7940 - accuracy: 0.713 - ETA: 21:06 - loss: 0.7978 - accuracy: 0.714 - ETA: 20:50 - loss: 0.7948 - accuracy: 0.716 - ETA: 20:35 - loss: 0.7950 - accuracy: 0.716 - ETA: 20:19 - loss: 0.7951 - accuracy: 0.716 - ETA: 20:03 - loss: 1.6045 - accuracy: 0.712 - ETA: 19:47 - loss: 1.5908 - accuracy: 0.710 - ETA: 19:32 - loss: 1.5617 - accuracy: 0.712 - ETA: 19:15 - loss: 1.7466 - accuracy: 0.705 - ETA: 18:59 - loss: 1.7242 - accuracy: 0.705 - ETA: 18:43 - loss: 1.7008 - accuracy: 0.705 - ETA: 18:26 - loss: 1.6868 - accuracy: 0.707 - ETA: 18:10 - loss: 1.6719 - accuracy: 0.705 - ETA: 17:53 - loss: 1.6522 - accuracy: 0.706 - ETA: 17:36 - loss: 1.6265 - accuracy: 0.706 - ETA: 17:19 - loss: 1.6084 - accuracy: 0.707 - ETA: 17:03 - loss: 1.5877 - accuracy: 0.707 - ETA: 16:46 - loss: 1.5715 - accuracy: 0.706 - ETA: 16:29 - loss: 1.5637 - accuracy: 0.704 - ETA: 16:13 - loss: 1.5444 - accuracy: 0.705 - ETA: 15:56 - loss: 1.5368 - accuracy: 0.703 - ETA: 15:39 - loss: 1.5198 - accuracy: 0.705 - ETA: 15:22 - loss: 1.5024 - accuracy: 0.705 - ETA: 15:05 - loss: 1.4953 - accuracy: 0.703 - ETA: 14:48 - loss: 1.4856 - accuracy: 0.702 - ETA: 14:30 - loss: 1.4695 - accuracy: 0.703 - ETA: 14:13 - loss: 1.4582 - accuracy: 0.703 - ETA: 13:57 - loss: 1.4411 - accuracy: 0.706 - ETA: 13:39 - loss: 1.4251 - accuracy: 0.708 - ETA: 13:22 - loss: 1.4052 - accuracy: 0.711 - ETA: 13:05 - loss: 1.3955 - accuracy: 0.711 - ETA: 12:48 - loss: 1.4428 - accuracy: 0.710 - ETA: 12:30 - loss: 1.4380 - accuracy: 0.708 - ETA: 12:13 - loss: 1.4358 - accuracy: 0.707 - ETA: 11:56 - loss: 1.4206 - accuracy: 0.709 - ETA: 11:39 - loss: 1.4141 - accuracy: 0.709 - ETA: 11:21 - loss: 2.0327 - accuracy: 0.708 - ETA: 11:04 - loss: 2.0131 - accuracy: 0.708 - ETA: 10:47 - loss: 2.0066 - accuracy: 0.706 - ETA: 10:29 - loss: 2.1266 - accuracy: 0.700 - ETA: 10:12 - loss: 2.1141 - accuracy: 0.697 - ETA: 9:55 - loss: 2.1082 - accuracy: 0.692 - ETA: 9:37 - loss: 2.0897 - accuracy: 0.69 - ETA: 9:20 - loss: 2.0714 - accuracy: 0.69 - ETA: 9:02 - loss: 2.0539 - accuracy: 0.69 - ETA: 8:45 - loss: 2.0520 - accuracy: 0.68 - ETA: 8:28 - loss: 2.0335 - accuracy: 0.69 - ETA: 8:10 - loss: 2.0231 - accuracy: 0.69 - ETA: 7:53 - loss: 2.0056 - accuracy: 0.69 - ETA: 7:35 - loss: 1.9878 - accuracy: 0.69 - ETA: 7:18 - loss: 1.9786 - accuracy: 0.69 - ETA: 7:00 - loss: 1.9661 - accuracy: 0.69 - ETA: 6:43 - loss: 1.9524 - accuracy: 0.69 - ETA: 6:25 - loss: 1.9373 - accuracy: 0.69 - ETA: 6:08 - loss: 1.9235 - accuracy: 0.69 - ETA: 5:50 - loss: 1.9115 - accuracy: 0.69 - ETA: 5:33 - loss: 1.9025 - accuracy: 0.68 - ETA: 5:15 - loss: 1.8943 - accuracy: 0.68 - ETA: 4:58 - loss: 1.8873 - accuracy: 0.68 - ETA: 4:40 - loss: 1.8825 - accuracy: 0.68 - ETA: 4:23 - loss: 1.8745 - accuracy: 0.68 - ETA: 4:05 - loss: 1.8656 - accuracy: 0.68 - ETA: 3:48 - loss: 1.8584 - accuracy: 0.68 - ETA: 3:30 - loss: 1.8459 - accuracy: 0.68 - ETA: 3:13 - loss: 1.8352 - accuracy: 0.68 - ETA: 2:55 - loss: 1.8262 - accuracy: 0.68 - ETA: 2:38 - loss: 1.8181 - accuracy: 0.68 - ETA: 2:20 - loss: 1.8119 - accuracy: 0.68 - ETA: 2:02 - loss: 1.8006 - accuracy: 0.68 - ETA: 1:45 - loss: 1.8071 - accuracy: 0.68 - ETA: 1:27 - loss: 1.8011 - accuracy: 0.67 - ETA: 1:10 - loss: 1.7916 - accuracy: 0.67 - ETA: 52s - loss: 1.7859 - accuracy: 0.6767 - ETA: 35s - loss: 1.7806 - accuracy: 0.676 - ETA: 17s - loss: 1.7712 - accuracy: 0.676 - ETA: 0s - loss: 1.7665 - accuracy: 0.675 - 1832s 18s/step - loss: 1.7665 - accuracy: 0.6758 - val_loss: 122802.1328 - val_accuracy: 0.4864\n",
      "Epoch 16/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0101 - accuracy: 0.65 - ETA: 15:01 - loss: 0.8879 - accuracy: 0.671 - ETA: 19:39 - loss: 0.8837 - accuracy: 0.697 - ETA: 21:52 - loss: 0.9454 - accuracy: 0.703 - ETA: 23:08 - loss: 0.9414 - accuracy: 0.706 - ETA: 23:54 - loss: 0.9177 - accuracy: 0.708 - ETA: 24:20 - loss: 0.9175 - accuracy: 0.709 - ETA: 24:37 - loss: 0.9436 - accuracy: 0.695 - ETA: 24:45 - loss: 0.9204 - accuracy: 0.697 - ETA: 24:47 - loss: 0.9527 - accuracy: 0.687 - ETA: 24:44 - loss: 0.9739 - accuracy: 0.679 - ETA: 24:40 - loss: 0.9560 - accuracy: 0.671 - ETA: 24:34 - loss: 0.9346 - accuracy: 0.675 - ETA: 24:26 - loss: 0.9403 - accuracy: 0.678 - ETA: 24:18 - loss: 0.9678 - accuracy: 0.666 - ETA: 24:08 - loss: 0.9584 - accuracy: 0.671 - ETA: 23:56 - loss: 0.9636 - accuracy: 0.669 - ETA: 23:44 - loss: 0.9579 - accuracy: 0.670 - ETA: 23:32 - loss: 0.9467 - accuracy: 0.671 - ETA: 23:18 - loss: 0.9389 - accuracy: 0.676 - ETA: 23:05 - loss: 0.9504 - accuracy: 0.675 - ETA: 22:51 - loss: 0.9433 - accuracy: 0.674 - ETA: 22:37 - loss: 0.9378 - accuracy: 0.678 - ETA: 22:22 - loss: 0.9344 - accuracy: 0.677 - ETA: 22:08 - loss: 0.9287 - accuracy: 0.678 - ETA: 21:53 - loss: 0.9148 - accuracy: 0.686 - ETA: 21:38 - loss: 0.9098 - accuracy: 0.689 - ETA: 21:23 - loss: 0.9066 - accuracy: 0.690 - ETA: 21:07 - loss: 0.9072 - accuracy: 0.691 - ETA: 20:52 - loss: 0.9063 - accuracy: 0.691 - ETA: 20:36 - loss: 0.9106 - accuracy: 0.689 - ETA: 20:20 - loss: 0.9058 - accuracy: 0.691 - ETA: 20:04 - loss: 0.9013 - accuracy: 0.693 - ETA: 19:48 - loss: 0.8933 - accuracy: 0.696 - ETA: 19:32 - loss: 0.8883 - accuracy: 0.698 - ETA: 19:16 - loss: 0.8907 - accuracy: 0.695 - ETA: 19:00 - loss: 0.8799 - accuracy: 0.697 - ETA: 18:43 - loss: 0.8831 - accuracy: 0.695 - ETA: 18:26 - loss: 0.8807 - accuracy: 0.697 - ETA: 18:10 - loss: 0.8824 - accuracy: 0.694 - ETA: 17:53 - loss: 0.8843 - accuracy: 0.693 - ETA: 17:37 - loss: 0.8796 - accuracy: 0.694 - ETA: 17:20 - loss: 0.8780 - accuracy: 0.695 - ETA: 17:03 - loss: 0.8755 - accuracy: 0.696 - ETA: 16:46 - loss: 0.8757 - accuracy: 0.695 - ETA: 16:29 - loss: 0.8772 - accuracy: 0.693 - ETA: 16:12 - loss: 0.8792 - accuracy: 0.692 - ETA: 15:56 - loss: 0.8756 - accuracy: 0.693 - ETA: 15:38 - loss: 0.8708 - accuracy: 0.695 - ETA: 15:21 - loss: 0.8636 - accuracy: 0.698 - ETA: 15:04 - loss: 0.8616 - accuracy: 0.699 - ETA: 14:47 - loss: 0.8669 - accuracy: 0.698 - ETA: 14:31 - loss: 0.8589 - accuracy: 0.702 - ETA: 14:13 - loss: 0.8523 - accuracy: 0.704 - ETA: 13:56 - loss: 0.8519 - accuracy: 0.702 - ETA: 13:39 - loss: 0.9289 - accuracy: 0.699 - ETA: 13:22 - loss: 0.9295 - accuracy: 0.698 - ETA: 13:05 - loss: 0.9270 - accuracy: 0.700 - ETA: 12:48 - loss: 0.9259 - accuracy: 0.700 - ETA: 12:30 - loss: 0.9230 - accuracy: 0.700 - ETA: 12:13 - loss: 0.9277 - accuracy: 0.701 - ETA: 11:56 - loss: 0.9438 - accuracy: 0.697 - ETA: 11:38 - loss: 0.9544 - accuracy: 0.698 - ETA: 11:21 - loss: 0.9785 - accuracy: 0.696 - ETA: 11:04 - loss: 0.9822 - accuracy: 0.696 - ETA: 10:46 - loss: 0.9790 - accuracy: 0.696 - ETA: 10:29 - loss: 0.9822 - accuracy: 0.697 - ETA: 10:12 - loss: 0.9817 - accuracy: 0.696 - ETA: 9:54 - loss: 0.9818 - accuracy: 0.696 - ETA: 9:37 - loss: 0.9869 - accuracy: 0.69 - ETA: 9:19 - loss: 0.9853 - accuracy: 0.69 - ETA: 9:02 - loss: 0.9886 - accuracy: 0.69 - ETA: 8:45 - loss: 0.9861 - accuracy: 0.69 - ETA: 8:27 - loss: 0.9856 - accuracy: 0.69 - ETA: 8:10 - loss: 0.9824 - accuracy: 0.69 - ETA: 7:52 - loss: 0.9854 - accuracy: 0.69 - ETA: 7:35 - loss: 0.9900 - accuracy: 0.69 - ETA: 7:17 - loss: 1.0035 - accuracy: 0.69 - ETA: 7:00 - loss: 0.9990 - accuracy: 0.69 - ETA: 6:43 - loss: 0.9999 - accuracy: 0.69 - ETA: 6:25 - loss: 1.0009 - accuracy: 0.69 - ETA: 6:08 - loss: 0.9980 - accuracy: 0.69 - ETA: 5:50 - loss: 0.9947 - accuracy: 0.69 - ETA: 5:33 - loss: 0.9958 - accuracy: 0.69 - ETA: 5:15 - loss: 0.9977 - accuracy: 0.69 - ETA: 4:58 - loss: 1.0031 - accuracy: 0.68 - ETA: 4:40 - loss: 1.0068 - accuracy: 0.68 - ETA: 4:23 - loss: 1.0020 - accuracy: 0.68 - ETA: 4:05 - loss: 1.0016 - accuracy: 0.68 - ETA: 3:48 - loss: 0.9990 - accuracy: 0.68 - ETA: 3:30 - loss: 0.9952 - accuracy: 0.68 - ETA: 3:13 - loss: 0.9941 - accuracy: 0.68 - ETA: 2:55 - loss: 0.9907 - accuracy: 0.69 - ETA: 2:37 - loss: 0.9883 - accuracy: 0.69 - ETA: 2:20 - loss: 0.9851 - accuracy: 0.69 - ETA: 2:02 - loss: 0.9815 - accuracy: 0.69 - ETA: 1:45 - loss: 0.9841 - accuracy: 0.69 - ETA: 1:27 - loss: 0.9918 - accuracy: 0.69 - ETA: 1:10 - loss: 1.0109 - accuracy: 0.68 - ETA: 52s - loss: 1.0250 - accuracy: 0.6889 - ETA: 35s - loss: 1.0182 - accuracy: 0.690 - ETA: 17s - loss: 1.0224 - accuracy: 0.691 - ETA: 0s - loss: 1.0184 - accuracy: 0.692 - 1829s 18s/step - loss: 1.0184 - accuracy: 0.6922 - val_loss: 21.5932 - val_accuracy: 0.6957\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.5803 - accuracy: 0.71 - ETA: 14:51 - loss: 0.6859 - accuracy: 0.671 - ETA: 19:33 - loss: 0.6840 - accuracy: 0.718 - ETA: 21:45 - loss: 0.6952 - accuracy: 0.726 - ETA: 22:59 - loss: 0.7096 - accuracy: 0.712 - ETA: 23:42 - loss: 0.6676 - accuracy: 0.739 - ETA: 24:08 - loss: 0.7589 - accuracy: 0.723 - ETA: 24:24 - loss: 0.8292 - accuracy: 0.691 - ETA: 24:33 - loss: 0.8481 - accuracy: 0.687 - ETA: 24:37 - loss: 0.8574 - accuracy: 0.684 - ETA: 24:37 - loss: 0.8610 - accuracy: 0.690 - ETA: 24:35 - loss: 0.8584 - accuracy: 0.687 - ETA: 24:29 - loss: 0.8366 - accuracy: 0.697 - ETA: 24:21 - loss: 0.8341 - accuracy: 0.694 - ETA: 24:13 - loss: 0.8298 - accuracy: 0.695 - ETA: 24:04 - loss: 0.8255 - accuracy: 0.701 - ETA: 23:53 - loss: 0.8245 - accuracy: 0.702 - ETA: 23:41 - loss: 0.8273 - accuracy: 0.706 - ETA: 23:29 - loss: 0.8452 - accuracy: 0.699 - ETA: 23:16 - loss: 0.8254 - accuracy: 0.701 - ETA: 23:03 - loss: 0.8234 - accuracy: 0.699 - ETA: 22:49 - loss: 0.8831 - accuracy: 0.693 - ETA: 22:34 - loss: 0.8906 - accuracy: 0.692 - ETA: 22:20 - loss: 0.9047 - accuracy: 0.692 - ETA: 22:06 - loss: 0.9011 - accuracy: 0.693 - ETA: 21:51 - loss: 0.8961 - accuracy: 0.697 - ETA: 21:36 - loss: 0.8953 - accuracy: 0.696 - ETA: 21:21 - loss: 0.8829 - accuracy: 0.698 - ETA: 21:06 - loss: 0.8769 - accuracy: 0.700 - ETA: 20:52 - loss: 0.8655 - accuracy: 0.704 - ETA: 20:39 - loss: 0.8603 - accuracy: 0.705 - ETA: 20:27 - loss: 0.8575 - accuracy: 0.706 - ETA: 20:11 - loss: 0.8681 - accuracy: 0.705 - ETA: 19:54 - loss: 0.8730 - accuracy: 0.705 - ETA: 19:38 - loss: 0.8752 - accuracy: 0.699 - ETA: 19:21 - loss: 0.8904 - accuracy: 0.699 - ETA: 19:02 - loss: 0.8817 - accuracy: 0.703 - ETA: 18:46 - loss: 0.8765 - accuracy: 0.704 - ETA: 18:29 - loss: 0.8960 - accuracy: 0.703 - ETA: 18:13 - loss: 0.8869 - accuracy: 0.706 - ETA: 17:56 - loss: 0.8894 - accuracy: 0.704 - ETA: 17:39 - loss: 0.8875 - accuracy: 0.704 - ETA: 17:22 - loss: 0.8797 - accuracy: 0.706 - ETA: 17:05 - loss: 0.8759 - accuracy: 0.709 - ETA: 16:48 - loss: 0.8729 - accuracy: 0.708 - ETA: 16:31 - loss: 0.8693 - accuracy: 0.709 - ETA: 16:14 - loss: 0.8721 - accuracy: 0.707 - ETA: 15:57 - loss: 0.8685 - accuracy: 0.709 - ETA: 15:40 - loss: 0.8689 - accuracy: 0.707 - ETA: 15:23 - loss: 0.8788 - accuracy: 0.704 - ETA: 15:06 - loss: 0.8790 - accuracy: 0.703 - ETA: 14:49 - loss: 0.8859 - accuracy: 0.699 - ETA: 14:32 - loss: 0.8830 - accuracy: 0.700 - ETA: 14:15 - loss: 0.8761 - accuracy: 0.702 - ETA: 13:57 - loss: 0.8822 - accuracy: 0.701 - ETA: 13:40 - loss: 0.8814 - accuracy: 0.701 - ETA: 13:23 - loss: 0.8825 - accuracy: 0.700 - ETA: 13:06 - loss: 0.8776 - accuracy: 0.702 - ETA: 12:48 - loss: 0.8719 - accuracy: 0.705 - ETA: 12:31 - loss: 0.8770 - accuracy: 0.704 - ETA: 12:14 - loss: 0.8759 - accuracy: 0.705 - ETA: 11:56 - loss: 0.8708 - accuracy: 0.706 - ETA: 11:39 - loss: 0.8805 - accuracy: 0.705 - ETA: 11:22 - loss: 0.8778 - accuracy: 0.705 - ETA: 11:04 - loss: 0.8813 - accuracy: 0.704 - ETA: 10:47 - loss: 0.8819 - accuracy: 0.702 - ETA: 10:30 - loss: 0.8819 - accuracy: 0.702 - ETA: 10:12 - loss: 0.8814 - accuracy: 0.701 - ETA: 9:55 - loss: 0.8802 - accuracy: 0.699 - ETA: 9:37 - loss: 0.8779 - accuracy: 0.70 - ETA: 9:20 - loss: 0.8773 - accuracy: 0.69 - ETA: 9:02 - loss: 0.8727 - accuracy: 0.70 - ETA: 8:45 - loss: 0.8748 - accuracy: 0.70 - ETA: 8:28 - loss: 0.8726 - accuracy: 0.70 - ETA: 8:10 - loss: 0.8736 - accuracy: 0.69 - ETA: 7:53 - loss: 0.8727 - accuracy: 0.70 - ETA: 7:35 - loss: 0.8684 - accuracy: 0.70 - ETA: 7:18 - loss: 0.8658 - accuracy: 0.70 - ETA: 7:00 - loss: 0.8650 - accuracy: 0.70 - ETA: 6:43 - loss: 0.8645 - accuracy: 0.70 - ETA: 6:25 - loss: 0.8609 - accuracy: 0.70 - ETA: 6:08 - loss: 0.8612 - accuracy: 0.70 - ETA: 5:50 - loss: 0.8606 - accuracy: 0.70 - ETA: 5:33 - loss: 0.8597 - accuracy: 0.70 - ETA: 5:15 - loss: 0.8579 - accuracy: 0.70 - ETA: 4:58 - loss: 0.8588 - accuracy: 0.70 - ETA: 4:40 - loss: 0.8573 - accuracy: 0.70 - ETA: 4:23 - loss: 0.8543 - accuracy: 0.70 - ETA: 4:05 - loss: 0.8501 - accuracy: 0.70 - ETA: 3:48 - loss: 0.8485 - accuracy: 0.70 - ETA: 3:30 - loss: 0.8503 - accuracy: 0.70 - ETA: 3:13 - loss: 0.8483 - accuracy: 0.70 - ETA: 2:55 - loss: 0.8465 - accuracy: 0.70 - ETA: 2:38 - loss: 0.8450 - accuracy: 0.70 - ETA: 2:20 - loss: 0.8441 - accuracy: 0.70 - ETA: 2:02 - loss: 0.8408 - accuracy: 0.70 - ETA: 1:45 - loss: 0.8373 - accuracy: 0.70 - ETA: 1:27 - loss: 0.8358 - accuracy: 0.70 - ETA: 1:10 - loss: 0.8342 - accuracy: 0.70 - ETA: 52s - loss: 0.8373 - accuracy: 0.7083 - ETA: 35s - loss: 0.8390 - accuracy: 0.709 - ETA: 17s - loss: 0.8394 - accuracy: 0.708 - ETA: 0s - loss: 0.8393 - accuracy: 0.708 - 1831s 18s/step - loss: 0.8393 - accuracy: 0.7083 - val_loss: 1.3052 - val_accuracy: 0.5815\n",
      "Epoch 18/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.7053 - accuracy: 0.75 - ETA: 14:53 - loss: 0.9631 - accuracy: 0.687 - ETA: 19:37 - loss: 0.8936 - accuracy: 0.687 - ETA: 21:47 - loss: 0.8508 - accuracy: 0.710 - ETA: 23:03 - loss: 0.8115 - accuracy: 0.718 - ETA: 23:46 - loss: 0.7750 - accuracy: 0.729 - ETA: 24:14 - loss: 0.7574 - accuracy: 0.741 - ETA: 24:29 - loss: 0.7614 - accuracy: 0.730 - ETA: 24:39 - loss: 0.7552 - accuracy: 0.725 - ETA: 24:41 - loss: 0.7641 - accuracy: 0.728 - ETA: 24:40 - loss: 0.7595 - accuracy: 0.733 - ETA: 24:36 - loss: 0.7990 - accuracy: 0.724 - ETA: 24:31 - loss: 0.8078 - accuracy: 0.718 - ETA: 24:23 - loss: 0.8228 - accuracy: 0.714 - ETA: 24:13 - loss: 0.8174 - accuracy: 0.706 - ETA: 24:04 - loss: 0.8019 - accuracy: 0.712 - ETA: 23:52 - loss: 0.8198 - accuracy: 0.707 - ETA: 23:40 - loss: 0.8143 - accuracy: 0.713 - ETA: 23:28 - loss: 0.8106 - accuracy: 0.715 - ETA: 23:15 - loss: 0.8070 - accuracy: 0.718 - ETA: 23:01 - loss: 0.8103 - accuracy: 0.718 - ETA: 22:47 - loss: 0.8087 - accuracy: 0.715 - ETA: 22:33 - loss: 0.8152 - accuracy: 0.716 - ETA: 22:18 - loss: 0.8105 - accuracy: 0.716 - ETA: 22:04 - loss: 0.8197 - accuracy: 0.713 - ETA: 21:49 - loss: 0.8113 - accuracy: 0.717 - ETA: 21:34 - loss: 0.8193 - accuracy: 0.715 - ETA: 21:18 - loss: 0.8069 - accuracy: 0.722 - ETA: 21:03 - loss: 0.8093 - accuracy: 0.719 - ETA: 20:48 - loss: 0.8121 - accuracy: 0.716 - ETA: 20:32 - loss: 0.8060 - accuracy: 0.717 - ETA: 20:16 - loss: 0.8049 - accuracy: 0.717 - ETA: 20:00 - loss: 0.8032 - accuracy: 0.717 - ETA: 19:44 - loss: 0.8044 - accuracy: 0.715 - ETA: 19:28 - loss: 0.8027 - accuracy: 0.717 - ETA: 19:12 - loss: 0.7993 - accuracy: 0.721 - ETA: 18:55 - loss: 0.7920 - accuracy: 0.724 - ETA: 18:39 - loss: 0.7916 - accuracy: 0.721 - ETA: 18:22 - loss: 0.7860 - accuracy: 0.724 - ETA: 18:06 - loss: 0.7828 - accuracy: 0.725 - ETA: 17:50 - loss: 0.7730 - accuracy: 0.730 - ETA: 17:33 - loss: 0.7685 - accuracy: 0.730 - ETA: 17:16 - loss: 0.7612 - accuracy: 0.732 - ETA: 17:00 - loss: 0.7562 - accuracy: 0.734 - ETA: 16:43 - loss: 0.9240 - accuracy: 0.732 - ETA: 16:26 - loss: 0.9245 - accuracy: 0.730 - ETA: 16:09 - loss: 0.9211 - accuracy: 0.728 - ETA: 15:53 - loss: 0.9260 - accuracy: 0.729 - ETA: 15:36 - loss: 1.1893 - accuracy: 0.729 - ETA: 15:19 - loss: 1.1839 - accuracy: 0.728 - ETA: 15:02 - loss: 1.1748 - accuracy: 0.729 - ETA: 14:45 - loss: 1.1610 - accuracy: 0.730 - ETA: 14:28 - loss: 1.1665 - accuracy: 0.729 - ETA: 14:11 - loss: 1.1589 - accuracy: 0.727 - ETA: 13:54 - loss: 1.1518 - accuracy: 0.726 - ETA: 13:37 - loss: 1.1438 - accuracy: 0.727 - ETA: 13:20 - loss: 1.1387 - accuracy: 0.726 - ETA: 13:03 - loss: 1.1346 - accuracy: 0.724 - ETA: 12:45 - loss: 1.1258 - accuracy: 0.726 - ETA: 12:28 - loss: 1.1213 - accuracy: 0.725 - ETA: 12:11 - loss: 1.1219 - accuracy: 0.722 - ETA: 11:54 - loss: 1.1170 - accuracy: 0.723 - ETA: 11:37 - loss: 1.1188 - accuracy: 0.720 - ETA: 11:19 - loss: 1.1162 - accuracy: 0.719 - ETA: 11:02 - loss: 1.1514 - accuracy: 0.718 - ETA: 10:45 - loss: 1.1459 - accuracy: 0.719 - ETA: 10:27 - loss: 1.1398 - accuracy: 0.719 - ETA: 10:10 - loss: 1.1364 - accuracy: 0.717 - ETA: 9:53 - loss: 1.1303 - accuracy: 0.717 - ETA: 9:36 - loss: 1.1305 - accuracy: 0.71 - ETA: 9:18 - loss: 1.1301 - accuracy: 0.71 - ETA: 9:01 - loss: 1.1290 - accuracy: 0.71 - ETA: 8:43 - loss: 1.1270 - accuracy: 0.71 - ETA: 8:26 - loss: 1.1206 - accuracy: 0.71 - ETA: 8:08 - loss: 1.1200 - accuracy: 0.71 - ETA: 7:51 - loss: 1.1140 - accuracy: 0.71 - ETA: 7:34 - loss: 1.1119 - accuracy: 0.71 - ETA: 7:16 - loss: 1.1081 - accuracy: 0.71 - ETA: 6:59 - loss: 1.1016 - accuracy: 0.71 - ETA: 6:41 - loss: 1.0953 - accuracy: 0.71 - ETA: 6:24 - loss: 1.0933 - accuracy: 0.71 - ETA: 6:07 - loss: 1.0939 - accuracy: 0.71 - ETA: 5:49 - loss: 1.1028 - accuracy: 0.71 - ETA: 5:32 - loss: 1.1041 - accuracy: 0.70 - ETA: 5:14 - loss: 1.1065 - accuracy: 0.70 - ETA: 4:57 - loss: 1.1044 - accuracy: 0.70 - ETA: 4:39 - loss: 1.1016 - accuracy: 0.70 - ETA: 4:22 - loss: 1.0979 - accuracy: 0.70 - ETA: 4:04 - loss: 1.0954 - accuracy: 0.70 - ETA: 3:47 - loss: 1.0928 - accuracy: 0.70 - ETA: 3:29 - loss: 1.0914 - accuracy: 0.70 - ETA: 3:12 - loss: 1.0879 - accuracy: 0.70 - ETA: 2:55 - loss: 1.0851 - accuracy: 0.70 - ETA: 2:37 - loss: 1.0831 - accuracy: 0.70 - ETA: 2:20 - loss: 1.0829 - accuracy: 0.70 - ETA: 2:02 - loss: 1.0815 - accuracy: 0.70 - ETA: 1:45 - loss: 1.0770 - accuracy: 0.70 - ETA: 1:27 - loss: 1.0723 - accuracy: 0.70 - ETA: 1:10 - loss: 1.0673 - accuracy: 0.70 - ETA: 52s - loss: 1.0650 - accuracy: 0.7042 - ETA: 35s - loss: 1.0629 - accuracy: 0.703 - ETA: 17s - loss: 1.0580 - accuracy: 0.704 - ETA: 0s - loss: 1.0586 - accuracy: 0.704 - 1826s 18s/step - loss: 1.0586 - accuracy: 0.7040 - val_loss: 2288.9880 - val_accuracy: 0.5598\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.5364 - accuracy: 0.84 - ETA: 14:53 - loss: 0.7129 - accuracy: 0.796 - ETA: 19:41 - loss: 0.9522 - accuracy: 0.750 - ETA: 21:55 - loss: 0.9651 - accuracy: 0.726 - ETA: 23:21 - loss: 0.9872 - accuracy: 0.712 - ETA: 24:02 - loss: 1.0179 - accuracy: 0.708 - ETA: 24:28 - loss: 0.9728 - accuracy: 0.718 - ETA: 24:41 - loss: 1.1331 - accuracy: 0.703 - ETA: 24:48 - loss: 1.1093 - accuracy: 0.697 - ETA: 24:50 - loss: 1.0830 - accuracy: 0.696 - ETA: 24:48 - loss: 1.0411 - accuracy: 0.693 - ETA: 24:44 - loss: 0.9989 - accuracy: 0.700 - ETA: 24:38 - loss: 0.9889 - accuracy: 0.704 - ETA: 24:30 - loss: 0.9791 - accuracy: 0.709 - ETA: 24:20 - loss: 0.9852 - accuracy: 0.708 - ETA: 24:08 - loss: 0.9904 - accuracy: 0.714 - ETA: 23:58 - loss: 0.9926 - accuracy: 0.720 - ETA: 23:46 - loss: 1.1216 - accuracy: 0.717 - ETA: 23:33 - loss: 1.1382 - accuracy: 0.705 - ETA: 23:20 - loss: 1.1690 - accuracy: 0.698 - ETA: 23:07 - loss: 1.2051 - accuracy: 0.690 - ETA: 22:52 - loss: 1.2493 - accuracy: 0.677 - ETA: 22:38 - loss: 1.2583 - accuracy: 0.671 - ETA: 22:25 - loss: 1.3213 - accuracy: 0.660 - ETA: 22:10 - loss: 1.3062 - accuracy: 0.658 - ETA: 21:55 - loss: 1.2895 - accuracy: 0.657 - ETA: 21:39 - loss: 1.2747 - accuracy: 0.656 - ETA: 21:24 - loss: 1.2600 - accuracy: 0.656 - ETA: 21:08 - loss: 1.2528 - accuracy: 0.650 - ETA: 20:53 - loss: 1.2525 - accuracy: 0.642 - ETA: 20:37 - loss: 1.3510 - accuracy: 0.635 - ETA: 20:21 - loss: 1.3358 - accuracy: 0.635 - ETA: 20:04 - loss: 1.3302 - accuracy: 0.636 - ETA: 19:49 - loss: 1.3358 - accuracy: 0.636 - ETA: 19:32 - loss: 1.3160 - accuracy: 0.639 - ETA: 19:16 - loss: 1.3047 - accuracy: 0.639 - ETA: 19:00 - loss: 1.2968 - accuracy: 0.639 - ETA: 18:43 - loss: 1.2848 - accuracy: 0.639 - ETA: 18:27 - loss: 1.2703 - accuracy: 0.642 - ETA: 18:10 - loss: 1.2549 - accuracy: 0.646 - ETA: 17:54 - loss: 1.2390 - accuracy: 0.650 - ETA: 17:37 - loss: 1.2325 - accuracy: 0.651 - ETA: 17:20 - loss: 1.2248 - accuracy: 0.653 - ETA: 17:03 - loss: 1.2269 - accuracy: 0.652 - ETA: 16:46 - loss: 1.2192 - accuracy: 0.652 - ETA: 16:29 - loss: 1.2097 - accuracy: 0.650 - ETA: 16:13 - loss: 1.2109 - accuracy: 0.649 - ETA: 15:56 - loss: 1.2056 - accuracy: 0.650 - ETA: 15:39 - loss: 1.1981 - accuracy: 0.651 - ETA: 15:22 - loss: 1.1875 - accuracy: 0.654 - ETA: 15:05 - loss: 1.1800 - accuracy: 0.653 - ETA: 14:48 - loss: 1.1732 - accuracy: 0.655 - ETA: 14:31 - loss: 1.1634 - accuracy: 0.656 - ETA: 14:14 - loss: 1.1585 - accuracy: 0.658 - ETA: 13:57 - loss: 1.1577 - accuracy: 0.656 - ETA: 13:39 - loss: 1.1500 - accuracy: 0.657 - ETA: 13:22 - loss: 1.1419 - accuracy: 0.659 - ETA: 13:05 - loss: 1.1362 - accuracy: 0.658 - ETA: 12:47 - loss: 1.1299 - accuracy: 0.659 - ETA: 12:30 - loss: 1.1242 - accuracy: 0.660 - ETA: 12:13 - loss: 1.1202 - accuracy: 0.660 - ETA: 11:56 - loss: 1.1233 - accuracy: 0.657 - ETA: 11:38 - loss: 1.1186 - accuracy: 0.658 - ETA: 11:21 - loss: 1.1126 - accuracy: 0.660 - ETA: 11:04 - loss: 1.1073 - accuracy: 0.660 - ETA: 10:46 - loss: 1.1001 - accuracy: 0.661 - ETA: 10:29 - loss: 1.0951 - accuracy: 0.662 - ETA: 10:11 - loss: 1.0928 - accuracy: 0.661 - ETA: 9:54 - loss: 1.0871 - accuracy: 0.662 - ETA: 9:37 - loss: 1.0830 - accuracy: 0.66 - ETA: 9:19 - loss: 1.0770 - accuracy: 0.66 - ETA: 9:01 - loss: 1.0722 - accuracy: 0.66 - ETA: 8:44 - loss: 1.0726 - accuracy: 0.66 - ETA: 8:27 - loss: 1.0672 - accuracy: 0.66 - ETA: 8:09 - loss: 1.0616 - accuracy: 0.66 - ETA: 7:52 - loss: 1.0545 - accuracy: 0.67 - ETA: 7:34 - loss: 1.0505 - accuracy: 0.67 - ETA: 7:17 - loss: 1.0501 - accuracy: 0.67 - ETA: 7:00 - loss: 1.0465 - accuracy: 0.67 - ETA: 6:42 - loss: 1.0422 - accuracy: 0.67 - ETA: 6:25 - loss: 1.0384 - accuracy: 0.67 - ETA: 6:07 - loss: 1.0384 - accuracy: 0.67 - ETA: 5:50 - loss: 1.0336 - accuracy: 0.67 - ETA: 5:32 - loss: 1.0295 - accuracy: 0.67 - ETA: 5:15 - loss: 1.0278 - accuracy: 0.67 - ETA: 4:57 - loss: 1.0278 - accuracy: 0.67 - ETA: 4:40 - loss: 1.0244 - accuracy: 0.67 - ETA: 4:22 - loss: 1.0243 - accuracy: 0.67 - ETA: 4:05 - loss: 1.0239 - accuracy: 0.67 - ETA: 3:47 - loss: 1.0208 - accuracy: 0.67 - ETA: 3:30 - loss: 1.0164 - accuracy: 0.67 - ETA: 3:12 - loss: 1.0120 - accuracy: 0.67 - ETA: 2:55 - loss: 1.0067 - accuracy: 0.67 - ETA: 2:37 - loss: 1.0022 - accuracy: 0.67 - ETA: 2:20 - loss: 1.0045 - accuracy: 0.67 - ETA: 2:02 - loss: 1.0024 - accuracy: 0.67 - ETA: 1:45 - loss: 1.0002 - accuracy: 0.67 - ETA: 1:27 - loss: 0.9975 - accuracy: 0.67 - ETA: 1:10 - loss: 0.9958 - accuracy: 0.67 - ETA: 52s - loss: 0.9942 - accuracy: 0.6782 - ETA: 35s - loss: 0.9886 - accuracy: 0.679 - ETA: 17s - loss: 0.9850 - accuracy: 0.680 - ETA: 0s - loss: 0.9829 - accuracy: 0.681 - 1829s 18s/step - loss: 0.9829 - accuracy: 0.6812 - val_loss: 0.8935 - val_accuracy: 0.6957\n",
      "Epoch 20/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.9442 - accuracy: 0.71 - ETA: 15:00 - loss: 0.6089 - accuracy: 0.828 - ETA: 19:41 - loss: 0.6767 - accuracy: 0.791 - ETA: 21:57 - loss: 0.7080 - accuracy: 0.773 - ETA: 23:07 - loss: 0.7096 - accuracy: 0.762 - ETA: 23:49 - loss: 0.7323 - accuracy: 0.760 - ETA: 24:15 - loss: 0.7401 - accuracy: 0.745 - ETA: 24:30 - loss: 0.7589 - accuracy: 0.726 - ETA: 24:37 - loss: 0.7480 - accuracy: 0.725 - ETA: 24:40 - loss: 0.7640 - accuracy: 0.718 - ETA: 24:40 - loss: 0.7479 - accuracy: 0.733 - ETA: 24:35 - loss: 0.7639 - accuracy: 0.726 - ETA: 24:29 - loss: 0.7683 - accuracy: 0.733 - ETA: 24:22 - loss: 0.7708 - accuracy: 0.734 - ETA: 24:13 - loss: 0.7714 - accuracy: 0.725 - ETA: 24:03 - loss: 0.7599 - accuracy: 0.730 - ETA: 23:52 - loss: 0.7519 - accuracy: 0.729 - ETA: 23:41 - loss: 0.7431 - accuracy: 0.727 - ETA: 23:29 - loss: 0.7439 - accuracy: 0.727 - ETA: 23:16 - loss: 0.7403 - accuracy: 0.729 - ETA: 23:03 - loss: 0.7458 - accuracy: 0.726 - ETA: 22:49 - loss: 0.7473 - accuracy: 0.725 - ETA: 22:35 - loss: 0.7476 - accuracy: 0.722 - ETA: 22:21 - loss: 0.7444 - accuracy: 0.724 - ETA: 22:06 - loss: 0.7492 - accuracy: 0.720 - ETA: 21:51 - loss: 0.7439 - accuracy: 0.722 - ETA: 21:36 - loss: 0.7468 - accuracy: 0.721 - ETA: 21:21 - loss: 0.7420 - accuracy: 0.724 - ETA: 21:06 - loss: 0.7315 - accuracy: 0.728 - ETA: 20:50 - loss: 0.7193 - accuracy: 0.733 - ETA: 20:34 - loss: 0.7211 - accuracy: 0.732 - ETA: 20:18 - loss: 0.7238 - accuracy: 0.734 - ETA: 20:02 - loss: 0.7307 - accuracy: 0.731 - ETA: 19:46 - loss: 0.7243 - accuracy: 0.731 - ETA: 19:30 - loss: 0.7256 - accuracy: 0.731 - ETA: 19:14 - loss: 0.7302 - accuracy: 0.730 - ETA: 18:57 - loss: 0.7287 - accuracy: 0.730 - ETA: 18:41 - loss: 0.7310 - accuracy: 0.731 - ETA: 18:24 - loss: 0.7384 - accuracy: 0.730 - ETA: 18:08 - loss: 0.7348 - accuracy: 0.732 - ETA: 17:52 - loss: 0.7290 - accuracy: 0.735 - ETA: 17:35 - loss: 0.7323 - accuracy: 0.734 - ETA: 17:18 - loss: 0.7304 - accuracy: 0.734 - ETA: 17:01 - loss: 0.7278 - accuracy: 0.735 - ETA: 16:45 - loss: 0.7266 - accuracy: 0.736 - ETA: 16:29 - loss: 0.7317 - accuracy: 0.733 - ETA: 16:11 - loss: 0.7335 - accuracy: 0.732 - ETA: 15:55 - loss: 0.7320 - accuracy: 0.732 - ETA: 15:36 - loss: 0.7348 - accuracy: 0.731 - ETA: 15:19 - loss: 0.7309 - accuracy: 0.732 - ETA: 15:02 - loss: 0.7344 - accuracy: 0.729 - ETA: 14:45 - loss: 0.7315 - accuracy: 0.729 - ETA: 14:28 - loss: 0.7337 - accuracy: 0.729 - ETA: 14:11 - loss: 0.7300 - accuracy: 0.729 - ETA: 13:54 - loss: 0.7293 - accuracy: 0.729 - ETA: 13:37 - loss: 0.7376 - accuracy: 0.727 - ETA: 13:20 - loss: 0.7419 - accuracy: 0.726 - ETA: 13:03 - loss: 0.7461 - accuracy: 0.726 - ETA: 12:45 - loss: 0.7529 - accuracy: 0.723 - ETA: 12:28 - loss: 0.7604 - accuracy: 0.721 - ETA: 12:11 - loss: 0.7573 - accuracy: 0.723 - ETA: 11:54 - loss: 0.7586 - accuracy: 0.721 - ETA: 11:37 - loss: 0.7595 - accuracy: 0.720 - ETA: 11:19 - loss: 0.7590 - accuracy: 0.721 - ETA: 11:02 - loss: 0.7599 - accuracy: 0.721 - ETA: 10:45 - loss: 0.7586 - accuracy: 0.722 - ETA: 10:27 - loss: 0.7567 - accuracy: 0.723 - ETA: 10:10 - loss: 0.7646 - accuracy: 0.720 - ETA: 9:53 - loss: 0.7636 - accuracy: 0.721 - ETA: 9:36 - loss: 0.7596 - accuracy: 0.72 - ETA: 9:18 - loss: 0.7583 - accuracy: 0.72 - ETA: 9:01 - loss: 0.7593 - accuracy: 0.72 - ETA: 8:44 - loss: 0.7580 - accuracy: 0.72 - ETA: 8:26 - loss: 0.7556 - accuracy: 0.72 - ETA: 8:09 - loss: 0.7543 - accuracy: 0.72 - ETA: 7:51 - loss: 0.7553 - accuracy: 0.72 - ETA: 7:34 - loss: 0.7554 - accuracy: 0.72 - ETA: 7:16 - loss: 0.7551 - accuracy: 0.72 - ETA: 6:59 - loss: 0.7528 - accuracy: 0.72 - ETA: 6:42 - loss: 0.7539 - accuracy: 0.72 - ETA: 6:24 - loss: 0.7522 - accuracy: 0.72 - ETA: 6:07 - loss: 0.7495 - accuracy: 0.72 - ETA: 5:49 - loss: 0.7502 - accuracy: 0.72 - ETA: 5:32 - loss: 0.7512 - accuracy: 0.72 - ETA: 5:15 - loss: 0.7532 - accuracy: 0.72 - ETA: 4:57 - loss: 0.7521 - accuracy: 0.72 - ETA: 4:40 - loss: 0.7503 - accuracy: 0.72 - ETA: 4:22 - loss: 0.7496 - accuracy: 0.72 - ETA: 4:05 - loss: 0.7503 - accuracy: 0.72 - ETA: 3:47 - loss: 0.7519 - accuracy: 0.72 - ETA: 3:30 - loss: 0.7536 - accuracy: 0.72 - ETA: 3:12 - loss: 0.7528 - accuracy: 0.72 - ETA: 2:55 - loss: 0.7505 - accuracy: 0.72 - ETA: 2:37 - loss: 0.7496 - accuracy: 0.72 - ETA: 2:20 - loss: 0.7483 - accuracy: 0.72 - ETA: 2:02 - loss: 0.7448 - accuracy: 0.72 - ETA: 1:45 - loss: 0.7440 - accuracy: 0.72 - ETA: 1:27 - loss: 0.7437 - accuracy: 0.72 - ETA: 1:10 - loss: 0.7436 - accuracy: 0.72 - ETA: 52s - loss: 0.7414 - accuracy: 0.7295 - ETA: 35s - loss: 0.7416 - accuracy: 0.729 - ETA: 17s - loss: 0.7408 - accuracy: 0.729 - ETA: 0s - loss: 0.7390 - accuracy: 0.730 - 1828s 18s/step - loss: 0.7390 - accuracy: 0.7304 - val_loss: 0.7659 - val_accuracy: 0.7201\n"
     ]
    }
   ],
   "source": [
    "r1 = model121.fit(train_set, validation_data=test_set, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model121.save('model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=r1\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(resnet.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(5, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5)            501765      flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,089,477\n",
      "Trainable params: 24,036,357\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model123 = Model(inputs = resnet.inputs, outputs = prediction)\n",
    "model123.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model123.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 2.5294 - accuracy: 0.25 - ETA: 11:21 - loss: 11.1138 - accuracy: 0.39 - ETA: 15:00 - loss: 11.0776 - accuracy: 0.47 - ETA: 16:44 - loss: 10.9318 - accuracy: 0.45 - ETA: 17:40 - loss: 9.0603 - accuracy: 0.4812 - ETA: 18:17 - loss: 7.8769 - accuracy: 0.484 - ETA: 18:38 - loss: 7.2738 - accuracy: 0.500 - ETA: 18:50 - loss: 6.5510 - accuracy: 0.503 - ETA: 18:56 - loss: 5.9075 - accuracy: 0.531 - ETA: 18:58 - loss: 5.4101 - accuracy: 0.543 - ETA: 18:57 - loss: 5.3556 - accuracy: 0.556 - ETA: 18:54 - loss: 5.8034 - accuracy: 0.557 - ETA: 18:49 - loss: 5.5368 - accuracy: 0.560 - ETA: 18:43 - loss: 5.9331 - accuracy: 0.562 - ETA: 18:37 - loss: 5.6263 - accuracy: 0.568 - ETA: 18:29 - loss: 5.4443 - accuracy: 0.558 - ETA: 18:21 - loss: 5.1753 - accuracy: 0.568 - ETA: 18:12 - loss: 4.9449 - accuracy: 0.569 - ETA: 18:03 - loss: 4.7312 - accuracy: 0.574 - ETA: 17:54 - loss: 4.5566 - accuracy: 0.579 - ETA: 17:44 - loss: 4.3781 - accuracy: 0.587 - ETA: 17:33 - loss: 4.2414 - accuracy: 0.585 - ETA: 17:23 - loss: 4.0900 - accuracy: 0.593 - ETA: 17:15 - loss: 3.9620 - accuracy: 0.592 - ETA: 17:04 - loss: 3.8406 - accuracy: 0.592 - ETA: 16:52 - loss: 3.8025 - accuracy: 0.586 - ETA: 16:40 - loss: 3.7082 - accuracy: 0.588 - ETA: 16:28 - loss: 3.8106 - accuracy: 0.584 - ETA: 16:16 - loss: 3.7293 - accuracy: 0.583 - ETA: 16:04 - loss: 3.6410 - accuracy: 0.582 - ETA: 15:52 - loss: 3.7307 - accuracy: 0.583 - ETA: 15:39 - loss: 3.6591 - accuracy: 0.583 - ETA: 15:27 - loss: 3.9078 - accuracy: 0.581 - ETA: 15:14 - loss: 3.8265 - accuracy: 0.582 - ETA: 15:02 - loss: 3.7449 - accuracy: 0.586 - ETA: 14:49 - loss: 3.8295 - accuracy: 0.589 - ETA: 14:37 - loss: 3.7685 - accuracy: 0.590 - ETA: 14:24 - loss: 3.6956 - accuracy: 0.592 - ETA: 14:11 - loss: 3.6257 - accuracy: 0.594 - ETA: 13:58 - loss: 3.5599 - accuracy: 0.599 - ETA: 13:46 - loss: 3.4946 - accuracy: 0.598 - ETA: 13:33 - loss: 3.4366 - accuracy: 0.599 - ETA: 13:20 - loss: 3.3818 - accuracy: 0.602 - ETA: 13:07 - loss: 3.3408 - accuracy: 0.603 - ETA: 12:54 - loss: 3.2991 - accuracy: 0.598 - ETA: 12:42 - loss: 3.2690 - accuracy: 0.600 - ETA: 12:29 - loss: 3.2225 - accuracy: 0.601 - ETA: 12:16 - loss: 3.1751 - accuracy: 0.603 - ETA: 12:02 - loss: 3.1309 - accuracy: 0.605 - ETA: 11:49 - loss: 3.0940 - accuracy: 0.606 - ETA: 11:36 - loss: 3.0507 - accuracy: 0.606 - ETA: 11:23 - loss: 3.0099 - accuracy: 0.608 - ETA: 11:10 - loss: 2.9701 - accuracy: 0.609 - ETA: 10:57 - loss: 2.9336 - accuracy: 0.610 - ETA: 10:44 - loss: 2.9020 - accuracy: 0.608 - ETA: 10:31 - loss: 2.8648 - accuracy: 0.611 - ETA: 10:17 - loss: 2.8283 - accuracy: 0.613 - ETA: 10:04 - loss: 2.7990 - accuracy: 0.613 - ETA: 9:51 - loss: 2.7659 - accuracy: 0.614 - ETA: 9:37 - loss: 2.7419 - accuracy: 0.61 - ETA: 9:24 - loss: 2.7124 - accuracy: 0.61 - ETA: 9:11 - loss: 2.6921 - accuracy: 0.61 - ETA: 8:58 - loss: 2.7046 - accuracy: 0.61 - ETA: 8:44 - loss: 2.6784 - accuracy: 0.61 - ETA: 8:31 - loss: 2.6475 - accuracy: 0.62 - ETA: 8:17 - loss: 2.6357 - accuracy: 0.61 - ETA: 8:04 - loss: 2.6883 - accuracy: 0.61 - ETA: 7:51 - loss: 2.6647 - accuracy: 0.61 - ETA: 7:37 - loss: 2.6401 - accuracy: 0.61 - ETA: 7:24 - loss: 2.6156 - accuracy: 0.61 - ETA: 7:11 - loss: 2.5914 - accuracy: 0.62 - ETA: 6:57 - loss: 2.5667 - accuracy: 0.62 - ETA: 6:43 - loss: 2.5464 - accuracy: 0.62 - ETA: 6:31 - loss: 2.5255 - accuracy: 0.62 - ETA: 6:17 - loss: 2.4992 - accuracy: 0.62 - ETA: 6:04 - loss: 2.4771 - accuracy: 0.62 - ETA: 5:51 - loss: 2.4532 - accuracy: 0.62 - ETA: 5:38 - loss: 2.4335 - accuracy: 0.62 - ETA: 5:25 - loss: 2.4135 - accuracy: 0.62 - ETA: 5:11 - loss: 2.3950 - accuracy: 0.62 - ETA: 4:58 - loss: 2.3756 - accuracy: 0.63 - ETA: 4:45 - loss: 2.6931 - accuracy: 0.63 - ETA: 4:31 - loss: 2.6695 - accuracy: 0.63 - ETA: 4:18 - loss: 2.6492 - accuracy: 0.63 - ETA: 4:04 - loss: 2.7567 - accuracy: 0.63 - ETA: 3:51 - loss: 2.7314 - accuracy: 0.63 - ETA: 3:38 - loss: 2.7133 - accuracy: 0.63 - ETA: 3:24 - loss: 2.6920 - accuracy: 0.63 - ETA: 3:10 - loss: 2.6747 - accuracy: 0.63 - ETA: 2:57 - loss: 2.6592 - accuracy: 0.63 - ETA: 2:43 - loss: 2.6919 - accuracy: 0.63 - ETA: 2:30 - loss: 2.6742 - accuracy: 0.63 - ETA: 2:16 - loss: 2.6534 - accuracy: 0.63 - ETA: 2:03 - loss: 2.6489 - accuracy: 0.63 - ETA: 1:49 - loss: 2.9674 - accuracy: 0.63 - ETA: 1:35 - loss: 2.9787 - accuracy: 0.63 - ETA: 1:22 - loss: 2.9579 - accuracy: 0.63 - ETA: 1:08 - loss: 2.9435 - accuracy: 0.63 - ETA: 54s - loss: 2.9775 - accuracy: 0.6298 - ETA: 41s - loss: 3.0050 - accuracy: 0.630 - ETA: 27s - loss: 2.9871 - accuracy: 0.629 - ETA: 13s - loss: 2.9696 - accuracy: 0.628 - ETA: 0s - loss: 2.9583 - accuracy: 0.628 - 1431s 14s/step - loss: 2.9583 - accuracy: 0.6287 - val_loss: 2288845.0000 - val_accuracy: 0.4918\n",
      "Epoch 2/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.9503 - accuracy: 0.81 - ETA: 11:50 - loss: 0.9472 - accuracy: 0.718 - ETA: 15:38 - loss: 1.0141 - accuracy: 0.708 - ETA: 17:25 - loss: 1.0396 - accuracy: 0.664 - ETA: 18:22 - loss: 1.0721 - accuracy: 0.662 - ETA: 19:00 - loss: 1.0578 - accuracy: 0.656 - ETA: 19:20 - loss: 1.0288 - accuracy: 0.660 - ETA: 19:32 - loss: 1.0184 - accuracy: 0.664 - ETA: 19:39 - loss: 0.9909 - accuracy: 0.670 - ETA: 19:41 - loss: 0.9858 - accuracy: 0.675 - ETA: 19:41 - loss: 0.9872 - accuracy: 0.673 - ETA: 19:40 - loss: 0.9760 - accuracy: 0.682 - ETA: 19:35 - loss: 0.9592 - accuracy: 0.680 - ETA: 19:29 - loss: 1.0191 - accuracy: 0.671 - ETA: 19:24 - loss: 1.0291 - accuracy: 0.664 - ETA: 19:16 - loss: 1.0354 - accuracy: 0.662 - ETA: 19:08 - loss: 1.0256 - accuracy: 0.661 - ETA: 18:58 - loss: 1.0208 - accuracy: 0.663 - ETA: 18:47 - loss: 1.0189 - accuracy: 0.662 - ETA: 18:37 - loss: 1.0079 - accuracy: 0.664 - ETA: 18:25 - loss: 1.1701 - accuracy: 0.660 - ETA: 18:14 - loss: 1.5744 - accuracy: 0.654 - ETA: 18:01 - loss: 1.5605 - accuracy: 0.649 - ETA: 17:47 - loss: 1.5364 - accuracy: 0.652 - ETA: 17:34 - loss: 1.5154 - accuracy: 0.653 - ETA: 17:21 - loss: 1.4903 - accuracy: 0.653 - ETA: 17:08 - loss: 1.4884 - accuracy: 0.650 - ETA: 16:54 - loss: 1.6488 - accuracy: 0.650 - ETA: 16:41 - loss: 1.6659 - accuracy: 0.647 - ETA: 16:27 - loss: 1.6329 - accuracy: 0.655 - ETA: 16:14 - loss: 1.6077 - accuracy: 0.660 - ETA: 16:01 - loss: 1.5928 - accuracy: 0.660 - ETA: 15:47 - loss: 1.5708 - accuracy: 0.664 - ETA: 15:34 - loss: 1.5561 - accuracy: 0.660 - ETA: 15:21 - loss: 1.5419 - accuracy: 0.657 - ETA: 15:07 - loss: 1.5420 - accuracy: 0.654 - ETA: 14:54 - loss: 1.6518 - accuracy: 0.656 - ETA: 14:40 - loss: 1.6320 - accuracy: 0.657 - ETA: 14:27 - loss: 1.6166 - accuracy: 0.655 - ETA: 14:13 - loss: 1.6013 - accuracy: 0.654 - ETA: 14:00 - loss: 1.5852 - accuracy: 0.657 - ETA: 13:46 - loss: 2.1832 - accuracy: 0.656 - ETA: 13:33 - loss: 2.1757 - accuracy: 0.654 - ETA: 13:20 - loss: 2.1477 - accuracy: 0.657 - ETA: 13:06 - loss: 2.1261 - accuracy: 0.652 - ETA: 12:53 - loss: 2.0995 - accuracy: 0.652 - ETA: 12:39 - loss: 2.0800 - accuracy: 0.652 - ETA: 12:26 - loss: 2.0561 - accuracy: 0.651 - ETA: 12:12 - loss: 2.0310 - accuracy: 0.652 - ETA: 11:59 - loss: 2.0097 - accuracy: 0.651 - ETA: 11:45 - loss: 1.9909 - accuracy: 0.649 - ETA: 11:32 - loss: 1.9735 - accuracy: 0.647 - ETA: 11:19 - loss: 1.9557 - accuracy: 0.646 - ETA: 11:05 - loss: 1.9380 - accuracy: 0.647 - ETA: 10:51 - loss: 1.9267 - accuracy: 0.645 - ETA: 10:38 - loss: 1.9100 - accuracy: 0.644 - ETA: 10:24 - loss: 1.8926 - accuracy: 0.643 - ETA: 10:11 - loss: 1.8741 - accuracy: 0.644 - ETA: 9:57 - loss: 1.8588 - accuracy: 0.645 - ETA: 9:44 - loss: 1.8417 - accuracy: 0.64 - ETA: 9:30 - loss: 1.8346 - accuracy: 0.64 - ETA: 9:17 - loss: 1.8140 - accuracy: 0.64 - ETA: 9:03 - loss: 1.7976 - accuracy: 0.64 - ETA: 8:50 - loss: 1.7818 - accuracy: 0.65 - ETA: 8:36 - loss: 1.7711 - accuracy: 0.65 - ETA: 8:23 - loss: 1.7604 - accuracy: 0.65 - ETA: 8:10 - loss: 1.7529 - accuracy: 0.65 - ETA: 7:56 - loss: 1.7378 - accuracy: 0.65 - ETA: 7:43 - loss: 1.7259 - accuracy: 0.65 - ETA: 7:29 - loss: 1.7170 - accuracy: 0.65 - ETA: 7:16 - loss: 1.7050 - accuracy: 0.65 - ETA: 7:03 - loss: 1.6944 - accuracy: 0.65 - ETA: 6:49 - loss: 1.6811 - accuracy: 0.65 - ETA: 6:36 - loss: 1.6713 - accuracy: 0.65 - ETA: 6:22 - loss: 1.6604 - accuracy: 0.65 - ETA: 6:09 - loss: 1.6506 - accuracy: 0.65 - ETA: 5:55 - loss: 1.6407 - accuracy: 0.65 - ETA: 5:42 - loss: 1.6294 - accuracy: 0.65 - ETA: 5:28 - loss: 1.9493 - accuracy: 0.65 - ETA: 5:15 - loss: 1.9327 - accuracy: 0.66 - ETA: 5:01 - loss: 1.9210 - accuracy: 0.65 - ETA: 4:48 - loss: 2.5041 - accuracy: 0.65 - ETA: 4:34 - loss: 2.4831 - accuracy: 0.66 - ETA: 4:20 - loss: 2.4798 - accuracy: 0.66 - ETA: 4:07 - loss: 2.4931 - accuracy: 0.65 - ETA: 3:53 - loss: 2.4741 - accuracy: 0.65 - ETA: 3:39 - loss: 2.5184 - accuracy: 0.65 - ETA: 3:26 - loss: 2.4984 - accuracy: 0.65 - ETA: 3:12 - loss: 2.4797 - accuracy: 0.65 - ETA: 2:58 - loss: 2.4635 - accuracy: 0.65 - ETA: 2:44 - loss: 2.4449 - accuracy: 0.65 - ETA: 2:31 - loss: 2.4254 - accuracy: 0.66 - ETA: 2:17 - loss: 2.4584 - accuracy: 0.66 - ETA: 2:03 - loss: 2.4404 - accuracy: 0.66 - ETA: 1:50 - loss: 2.4235 - accuracy: 0.66 - ETA: 1:36 - loss: 2.4084 - accuracy: 0.65 - ETA: 1:22 - loss: 2.3918 - accuracy: 0.66 - ETA: 1:08 - loss: 2.3761 - accuracy: 0.66 - ETA: 55s - loss: 2.3607 - accuracy: 0.6608 - ETA: 41s - loss: 2.3456 - accuracy: 0.661 - ETA: 27s - loss: 2.3300 - accuracy: 0.662 - ETA: 13s - loss: 2.3163 - accuracy: 0.661 - ETA: 0s - loss: 2.3014 - accuracy: 0.662 - 1440s 14s/step - loss: 2.3014 - accuracy: 0.6627 - val_loss: 1.3702 - val_accuracy: 0.4918\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 4.8568 - accuracy: 0.75 - ETA: 11:51 - loss: 2.7695 - accuracy: 0.765 - ETA: 15:38 - loss: 2.8798 - accuracy: 0.760 - ETA: 17:27 - loss: 4.6212 - accuracy: 0.734 - ETA: 18:18 - loss: 4.6701 - accuracy: 0.718 - ETA: 18:45 - loss: 4.0664 - accuracy: 0.708 - ETA: 19:02 - loss: 3.6587 - accuracy: 0.696 - ETA: 19:12 - loss: 3.3015 - accuracy: 0.695 - ETA: 19:15 - loss: 3.0596 - accuracy: 0.680 - ETA: 19:15 - loss: 2.8420 - accuracy: 0.684 - ETA: 19:12 - loss: 2.6740 - accuracy: 0.687 - ETA: 19:07 - loss: 5.3477 - accuracy: 0.677 - ETA: 19:01 - loss: 5.0186 - accuracy: 0.673 - ETA: 18:54 - loss: 4.7217 - accuracy: 0.678 - ETA: 18:46 - loss: 4.4954 - accuracy: 0.685 - ETA: 18:38 - loss: 4.2812 - accuracy: 0.681 - ETA: 18:29 - loss: 4.0798 - accuracy: 0.685 - ETA: 18:20 - loss: 3.9005 - accuracy: 0.691 - ETA: 18:10 - loss: 4.2748 - accuracy: 0.697 - ETA: 17:59 - loss: 4.3817 - accuracy: 0.701 - ETA: 17:49 - loss: 4.2113 - accuracy: 0.703 - ETA: 17:38 - loss: 4.0519 - accuracy: 0.706 - ETA: 17:26 - loss: 3.9160 - accuracy: 0.703 - ETA: 17:15 - loss: 3.8023 - accuracy: 0.703 - ETA: 17:03 - loss: 3.6960 - accuracy: 0.697 - ETA: 16:52 - loss: 3.5993 - accuracy: 0.689 - ETA: 16:41 - loss: 3.4942 - accuracy: 0.693 - ETA: 16:28 - loss: 3.4024 - accuracy: 0.694 - ETA: 16:16 - loss: 3.3156 - accuracy: 0.694 - ETA: 16:04 - loss: 3.2373 - accuracy: 0.691 - ETA: 15:52 - loss: 3.1586 - accuracy: 0.692 - ETA: 15:39 - loss: 3.0877 - accuracy: 0.689 - ETA: 15:27 - loss: 3.0219 - accuracy: 0.689 - ETA: 15:14 - loss: 2.9615 - accuracy: 0.689 - ETA: 15:02 - loss: 2.9019 - accuracy: 0.688 - ETA: 14:49 - loss: 2.8422 - accuracy: 0.690 - ETA: 14:37 - loss: 2.7907 - accuracy: 0.689 - ETA: 14:24 - loss: 2.7391 - accuracy: 0.687 - ETA: 14:11 - loss: 2.6887 - accuracy: 0.688 - ETA: 13:59 - loss: 2.6441 - accuracy: 0.687 - ETA: 13:46 - loss: 2.6032 - accuracy: 0.684 - ETA: 13:33 - loss: 2.5594 - accuracy: 0.684 - ETA: 13:20 - loss: 2.5209 - accuracy: 0.683 - ETA: 13:07 - loss: 2.4842 - accuracy: 0.683 - ETA: 12:54 - loss: 2.4502 - accuracy: 0.682 - ETA: 12:41 - loss: 2.4173 - accuracy: 0.684 - ETA: 12:28 - loss: 2.3865 - accuracy: 0.682 - ETA: 12:15 - loss: 2.3533 - accuracy: 0.684 - ETA: 12:02 - loss: 2.3215 - accuracy: 0.684 - ETA: 11:49 - loss: 2.5294 - accuracy: 0.684 - ETA: 11:36 - loss: 2.4966 - accuracy: 0.683 - ETA: 11:22 - loss: 2.5052 - accuracy: 0.682 - ETA: 11:08 - loss: 2.4971 - accuracy: 0.683 - ETA: 10:55 - loss: 2.7215 - accuracy: 0.683 - ETA: 10:42 - loss: 2.8953 - accuracy: 0.684 - ETA: 10:30 - loss: 3.0473 - accuracy: 0.683 - ETA: 10:16 - loss: 3.1764 - accuracy: 0.685 - ETA: 10:03 - loss: 3.1500 - accuracy: 0.684 - ETA: 9:50 - loss: 3.6175 - accuracy: 0.681 - ETA: 9:37 - loss: 3.5770 - accuracy: 0.68 - ETA: 9:23 - loss: 3.5365 - accuracy: 0.67 - ETA: 9:10 - loss: 3.4960 - accuracy: 0.67 - ETA: 8:57 - loss: 3.4532 - accuracy: 0.67 - ETA: 8:44 - loss: 3.4155 - accuracy: 0.67 - ETA: 8:30 - loss: 3.3758 - accuracy: 0.67 - ETA: 8:17 - loss: 3.3384 - accuracy: 0.67 - ETA: 8:03 - loss: 3.4706 - accuracy: 0.67 - ETA: 7:50 - loss: 3.4875 - accuracy: 0.67 - ETA: 7:37 - loss: 3.4504 - accuracy: 0.66 - ETA: 7:24 - loss: 3.5502 - accuracy: 0.66 - ETA: 7:10 - loss: 3.5139 - accuracy: 0.66 - ETA: 6:57 - loss: 3.4782 - accuracy: 0.66 - ETA: 6:44 - loss: 3.4428 - accuracy: 0.66 - ETA: 6:31 - loss: 3.4089 - accuracy: 0.66 - ETA: 6:18 - loss: 3.3777 - accuracy: 0.66 - ETA: 6:04 - loss: 3.3609 - accuracy: 0.66 - ETA: 5:51 - loss: 3.3308 - accuracy: 0.66 - ETA: 5:38 - loss: 3.2994 - accuracy: 0.66 - ETA: 5:24 - loss: 3.2667 - accuracy: 0.66 - ETA: 5:11 - loss: 3.2375 - accuracy: 0.66 - ETA: 4:58 - loss: 3.2079 - accuracy: 0.66 - ETA: 4:44 - loss: 3.1799 - accuracy: 0.66 - ETA: 4:31 - loss: 3.1539 - accuracy: 0.66 - ETA: 4:17 - loss: 3.1276 - accuracy: 0.66 - ETA: 4:04 - loss: 3.1006 - accuracy: 0.66 - ETA: 3:51 - loss: 3.0761 - accuracy: 0.66 - ETA: 3:37 - loss: 3.0558 - accuracy: 0.66 - ETA: 3:24 - loss: 3.0325 - accuracy: 0.66 - ETA: 3:10 - loss: 3.0094 - accuracy: 0.66 - ETA: 2:56 - loss: 2.9836 - accuracy: 0.66 - ETA: 2:43 - loss: 2.9597 - accuracy: 0.66 - ETA: 2:29 - loss: 2.9405 - accuracy: 0.66 - ETA: 2:16 - loss: 2.9207 - accuracy: 0.66 - ETA: 2:02 - loss: 2.8986 - accuracy: 0.66 - ETA: 1:49 - loss: 2.8773 - accuracy: 0.66 - ETA: 1:35 - loss: 2.8585 - accuracy: 0.66 - ETA: 1:21 - loss: 2.8367 - accuracy: 0.66 - ETA: 1:08 - loss: 2.8159 - accuracy: 0.66 - ETA: 54s - loss: 2.7953 - accuracy: 0.6680 - ETA: 40s - loss: 2.7769 - accuracy: 0.667 - ETA: 27s - loss: 2.7536 - accuracy: 0.669 - ETA: 13s - loss: 2.7346 - accuracy: 0.669 - ETA: 0s - loss: 2.7164 - accuracy: 0.670 - 1422s 14s/step - loss: 2.7164 - accuracy: 0.6700 - val_loss: 1.5839 - val_accuracy: 0.2717\n",
      "Epoch 4/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0162 - accuracy: 0.65 - ETA: 11:31 - loss: 1.1737 - accuracy: 0.625 - ETA: 15:09 - loss: 1.1188 - accuracy: 0.635 - ETA: 16:54 - loss: 1.2110 - accuracy: 0.648 - ETA: 17:51 - loss: 1.3427 - accuracy: 0.668 - ETA: 18:24 - loss: 1.3089 - accuracy: 0.645 - ETA: 18:43 - loss: 1.2317 - accuracy: 0.669 - ETA: 18:54 - loss: 1.2069 - accuracy: 0.656 - ETA: 19:01 - loss: 1.1652 - accuracy: 0.663 - ETA: 19:03 - loss: 1.1331 - accuracy: 0.665 - ETA: 19:01 - loss: 1.0822 - accuracy: 0.679 - ETA: 19:10 - loss: 1.0509 - accuracy: 0.682 - ETA: 19:26 - loss: 1.0791 - accuracy: 0.673 - ETA: 19:33 - loss: 1.0643 - accuracy: 0.674 - ETA: 19:32 - loss: 1.0736 - accuracy: 0.668 - ETA: 19:30 - loss: 1.1028 - accuracy: 0.656 - ETA: 19:13 - loss: 1.0827 - accuracy: 0.660 - ETA: 19:01 - loss: 1.0736 - accuracy: 0.660 - ETA: 18:49 - loss: 1.0547 - accuracy: 0.663 - ETA: 18:36 - loss: 1.0485 - accuracy: 0.664 - ETA: 18:24 - loss: 1.0403 - accuracy: 0.664 - ETA: 18:11 - loss: 1.0399 - accuracy: 0.665 - ETA: 17:58 - loss: 1.0305 - accuracy: 0.670 - ETA: 17:45 - loss: 1.0328 - accuracy: 0.671 - ETA: 17:33 - loss: 1.0282 - accuracy: 0.670 - ETA: 17:20 - loss: 1.0301 - accuracy: 0.666 - ETA: 17:07 - loss: 1.0277 - accuracy: 0.664 - ETA: 16:53 - loss: 1.0457 - accuracy: 0.662 - ETA: 16:40 - loss: 1.0347 - accuracy: 0.665 - ETA: 16:29 - loss: 1.0277 - accuracy: 0.669 - ETA: 16:21 - loss: 1.0224 - accuracy: 0.669 - ETA: 16:09 - loss: 1.0208 - accuracy: 0.667 - ETA: 15:56 - loss: 1.0174 - accuracy: 0.667 - ETA: 15:44 - loss: 1.0156 - accuracy: 0.668 - ETA: 15:31 - loss: 1.0205 - accuracy: 0.667 - ETA: 15:18 - loss: 1.0197 - accuracy: 0.666 - ETA: 15:05 - loss: 1.0192 - accuracy: 0.664 - ETA: 14:52 - loss: 1.0119 - accuracy: 0.665 - ETA: 14:39 - loss: 1.0092 - accuracy: 0.665 - ETA: 14:26 - loss: 1.0138 - accuracy: 0.662 - ETA: 14:13 - loss: 1.0068 - accuracy: 0.663 - ETA: 13:59 - loss: 1.0138 - accuracy: 0.662 - ETA: 13:46 - loss: 1.0112 - accuracy: 0.660 - ETA: 13:33 - loss: 1.0085 - accuracy: 0.660 - ETA: 13:20 - loss: 0.9995 - accuracy: 0.662 - ETA: 13:06 - loss: 0.9933 - accuracy: 0.664 - ETA: 12:53 - loss: 0.9895 - accuracy: 0.664 - ETA: 12:39 - loss: 0.9850 - accuracy: 0.666 - ETA: 12:26 - loss: 0.9804 - accuracy: 0.667 - ETA: 12:13 - loss: 0.9781 - accuracy: 0.667 - ETA: 12:00 - loss: 0.9821 - accuracy: 0.665 - ETA: 11:46 - loss: 0.9856 - accuracy: 0.662 - ETA: 11:33 - loss: 0.9868 - accuracy: 0.665 - ETA: 11:19 - loss: 0.9854 - accuracy: 0.664 - ETA: 11:05 - loss: 0.9838 - accuracy: 0.663 - ETA: 10:52 - loss: 0.9767 - accuracy: 0.665 - ETA: 10:38 - loss: 0.9836 - accuracy: 0.664 - ETA: 10:24 - loss: 0.9897 - accuracy: 0.664 - ETA: 10:11 - loss: 0.9844 - accuracy: 0.665 - ETA: 9:57 - loss: 0.9824 - accuracy: 0.666 - ETA: 9:43 - loss: 0.9812 - accuracy: 0.66 - ETA: 9:30 - loss: 0.9798 - accuracy: 0.66 - ETA: 9:16 - loss: 0.9751 - accuracy: 0.66 - ETA: 9:02 - loss: 0.9763 - accuracy: 0.66 - ETA: 8:48 - loss: 0.9734 - accuracy: 0.66 - ETA: 8:34 - loss: 0.9728 - accuracy: 0.66 - ETA: 8:21 - loss: 0.9737 - accuracy: 0.66 - ETA: 8:07 - loss: 0.9741 - accuracy: 0.66 - ETA: 7:53 - loss: 0.9696 - accuracy: 0.66 - ETA: 7:39 - loss: 0.9719 - accuracy: 0.66 - ETA: 7:25 - loss: 0.9673 - accuracy: 0.66 - ETA: 7:11 - loss: 0.9658 - accuracy: 0.66 - ETA: 6:58 - loss: 1.0411 - accuracy: 0.66 - ETA: 6:44 - loss: 1.0402 - accuracy: 0.66 - ETA: 6:30 - loss: 1.0346 - accuracy: 0.66 - ETA: 6:16 - loss: 1.0393 - accuracy: 0.66 - ETA: 6:02 - loss: 1.0354 - accuracy: 0.66 - ETA: 5:48 - loss: 1.0351 - accuracy: 0.66 - ETA: 5:34 - loss: 1.0514 - accuracy: 0.66 - ETA: 5:20 - loss: 1.0460 - accuracy: 0.66 - ETA: 5:06 - loss: 1.0487 - accuracy: 0.66 - ETA: 4:52 - loss: 1.0483 - accuracy: 0.66 - ETA: 4:38 - loss: 1.0478 - accuracy: 0.66 - ETA: 4:24 - loss: 1.0443 - accuracy: 0.66 - ETA: 4:10 - loss: 1.0434 - accuracy: 0.66 - ETA: 3:56 - loss: 1.0388 - accuracy: 0.66 - ETA: 3:42 - loss: 1.0355 - accuracy: 0.66 - ETA: 3:28 - loss: 1.0323 - accuracy: 0.66 - ETA: 3:14 - loss: 1.0340 - accuracy: 0.66 - ETA: 3:00 - loss: 1.0322 - accuracy: 0.66 - ETA: 2:46 - loss: 1.0326 - accuracy: 0.66 - ETA: 2:32 - loss: 1.0299 - accuracy: 0.66 - ETA: 2:18 - loss: 1.0258 - accuracy: 0.66 - ETA: 2:04 - loss: 1.0200 - accuracy: 0.67 - ETA: 1:50 - loss: 1.0202 - accuracy: 0.67 - ETA: 1:37 - loss: 1.0199 - accuracy: 0.67 - ETA: 1:23 - loss: 1.0199 - accuracy: 0.67 - ETA: 1:09 - loss: 1.0175 - accuracy: 0.67 - ETA: 55s - loss: 1.0411 - accuracy: 0.6728 - ETA: 41s - loss: 1.0384 - accuracy: 0.673 - ETA: 27s - loss: 1.0375 - accuracy: 0.673 - ETA: 13s - loss: 1.0361 - accuracy: 0.672 - ETA: 0s - loss: 1.0675 - accuracy: 0.673 - 1444s 14s/step - loss: 1.0675 - accuracy: 0.6736 - val_loss: 1.5814 - val_accuracy: 0.2717\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.8710 - accuracy: 0.71 - ETA: 11:27 - loss: 0.7891 - accuracy: 0.718 - ETA: 15:07 - loss: 0.8162 - accuracy: 0.697 - ETA: 16:52 - loss: 0.7943 - accuracy: 0.703 - ETA: 17:47 - loss: 0.8181 - accuracy: 0.687 - ETA: 18:19 - loss: 0.8275 - accuracy: 0.692 - ETA: 18:38 - loss: 0.8571 - accuracy: 0.700 - ETA: 18:51 - loss: 1.5435 - accuracy: 0.683 - ETA: 18:57 - loss: 1.4487 - accuracy: 0.691 - ETA: 18:59 - loss: 1.4055 - accuracy: 0.690 - ETA: 18:59 - loss: 1.3591 - accuracy: 0.684 - ETA: 18:59 - loss: 1.3525 - accuracy: 0.671 - ETA: 18:55 - loss: 1.3228 - accuracy: 0.675 - ETA: 18:48 - loss: 1.2859 - accuracy: 0.678 - ETA: 18:41 - loss: 1.2491 - accuracy: 0.683 - ETA: 18:34 - loss: 1.2095 - accuracy: 0.693 - ETA: 18:25 - loss: 1.1867 - accuracy: 0.693 - ETA: 18:15 - loss: 1.1756 - accuracy: 0.691 - ETA: 18:05 - loss: 1.1618 - accuracy: 0.692 - ETA: 17:55 - loss: 1.1655 - accuracy: 0.684 - ETA: 17:45 - loss: 1.1442 - accuracy: 0.687 - ETA: 17:34 - loss: 1.1511 - accuracy: 0.679 - ETA: 17:23 - loss: 1.1478 - accuracy: 0.675 - ETA: 17:12 - loss: 1.1238 - accuracy: 0.682 - ETA: 17:01 - loss: 1.1104 - accuracy: 0.683 - ETA: 16:49 - loss: 1.0989 - accuracy: 0.683 - ETA: 16:38 - loss: 1.0877 - accuracy: 0.686 - ETA: 16:26 - loss: 1.0810 - accuracy: 0.687 - ETA: 16:14 - loss: 1.0853 - accuracy: 0.687 - ETA: 16:02 - loss: 1.0788 - accuracy: 0.686 - ETA: 15:49 - loss: 1.0774 - accuracy: 0.684 - ETA: 15:37 - loss: 1.0713 - accuracy: 0.684 - ETA: 15:25 - loss: 1.0687 - accuracy: 0.681 - ETA: 15:13 - loss: 1.0615 - accuracy: 0.680 - ETA: 15:00 - loss: 1.0591 - accuracy: 0.677 - ETA: 14:48 - loss: 1.0567 - accuracy: 0.677 - ETA: 14:35 - loss: 1.0513 - accuracy: 0.677 - ETA: 14:22 - loss: 1.0473 - accuracy: 0.676 - ETA: 14:09 - loss: 1.0884 - accuracy: 0.676 - ETA: 13:57 - loss: 1.0893 - accuracy: 0.675 - ETA: 13:44 - loss: 1.0831 - accuracy: 0.675 - ETA: 13:31 - loss: 1.0810 - accuracy: 0.673 - ETA: 13:18 - loss: 1.0796 - accuracy: 0.672 - ETA: 13:05 - loss: 1.0753 - accuracy: 0.673 - ETA: 12:52 - loss: 1.0700 - accuracy: 0.672 - ETA: 12:39 - loss: 1.0675 - accuracy: 0.670 - ETA: 12:26 - loss: 1.0612 - accuracy: 0.671 - ETA: 12:13 - loss: 1.0583 - accuracy: 0.671 - ETA: 12:00 - loss: 1.0479 - accuracy: 0.675 - ETA: 11:47 - loss: 1.0378 - accuracy: 0.680 - ETA: 11:34 - loss: 1.0328 - accuracy: 0.680 - ETA: 11:21 - loss: 1.0265 - accuracy: 0.681 - ETA: 11:08 - loss: 1.0217 - accuracy: 0.681 - ETA: 10:55 - loss: 1.0177 - accuracy: 0.682 - ETA: 10:42 - loss: 1.0205 - accuracy: 0.680 - ETA: 10:29 - loss: 1.0152 - accuracy: 0.680 - ETA: 10:15 - loss: 1.0091 - accuracy: 0.682 - ETA: 10:02 - loss: 1.0048 - accuracy: 0.684 - ETA: 9:49 - loss: 1.0028 - accuracy: 0.682 - ETA: 9:36 - loss: 0.9983 - accuracy: 0.68 - ETA: 9:23 - loss: 1.0007 - accuracy: 0.68 - ETA: 9:09 - loss: 0.9967 - accuracy: 0.68 - ETA: 8:55 - loss: 0.9928 - accuracy: 0.68 - ETA: 8:42 - loss: 0.9939 - accuracy: 0.68 - ETA: 8:29 - loss: 0.9905 - accuracy: 0.68 - ETA: 8:16 - loss: 0.9847 - accuracy: 0.68 - ETA: 8:02 - loss: 0.9885 - accuracy: 0.68 - ETA: 7:49 - loss: 0.9857 - accuracy: 0.68 - ETA: 7:36 - loss: 0.9835 - accuracy: 0.68 - ETA: 7:22 - loss: 0.9799 - accuracy: 0.68 - ETA: 7:09 - loss: 0.9790 - accuracy: 0.68 - ETA: 6:56 - loss: 0.9810 - accuracy: 0.68 - ETA: 6:42 - loss: 0.9822 - accuracy: 0.68 - ETA: 6:29 - loss: 0.9783 - accuracy: 0.68 - ETA: 6:16 - loss: 0.9749 - accuracy: 0.68 - ETA: 6:02 - loss: 0.9747 - accuracy: 0.68 - ETA: 5:49 - loss: 0.9732 - accuracy: 0.68 - ETA: 5:36 - loss: 0.9678 - accuracy: 0.68 - ETA: 5:22 - loss: 0.9678 - accuracy: 0.68 - ETA: 5:09 - loss: 0.9637 - accuracy: 0.69 - ETA: 4:55 - loss: 0.9656 - accuracy: 0.68 - ETA: 4:42 - loss: 0.9612 - accuracy: 0.69 - ETA: 4:29 - loss: 0.9565 - accuracy: 0.69 - ETA: 4:15 - loss: 0.9529 - accuracy: 0.69 - ETA: 4:02 - loss: 0.9571 - accuracy: 0.68 - ETA: 3:48 - loss: 0.9543 - accuracy: 0.69 - ETA: 3:35 - loss: 0.9507 - accuracy: 0.69 - ETA: 3:22 - loss: 0.9485 - accuracy: 0.69 - ETA: 3:08 - loss: 0.9487 - accuracy: 0.69 - ETA: 2:55 - loss: 0.9480 - accuracy: 0.69 - ETA: 2:41 - loss: 0.9481 - accuracy: 0.69 - ETA: 2:28 - loss: 0.9464 - accuracy: 0.69 - ETA: 2:14 - loss: 0.9446 - accuracy: 0.69 - ETA: 2:01 - loss: 0.9405 - accuracy: 0.69 - ETA: 1:47 - loss: 0.9396 - accuracy: 0.69 - ETA: 1:34 - loss: 0.9405 - accuracy: 0.69 - ETA: 1:20 - loss: 0.9449 - accuracy: 0.69 - ETA: 1:07 - loss: 0.9440 - accuracy: 0.69 - ETA: 53s - loss: 0.9435 - accuracy: 0.6917 - ETA: 40s - loss: 0.9441 - accuracy: 0.692 - ETA: 26s - loss: 0.9422 - accuracy: 0.692 - ETA: 13s - loss: 0.9410 - accuracy: 0.693 - ETA: 0s - loss: 0.9402 - accuracy: 0.692 - 1407s 14s/step - loss: 0.9402 - accuracy: 0.6928 - val_loss: 1.5821 - val_accuracy: 0.2717\n",
      "Epoch 6/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.0665 - accuracy: 0.65 - ETA: 11:28 - loss: 0.9769 - accuracy: 0.703 - ETA: 15:04 - loss: 1.0315 - accuracy: 0.677 - ETA: 16:46 - loss: 0.9614 - accuracy: 0.679 - ETA: 17:44 - loss: 0.9051 - accuracy: 0.700 - ETA: 18:18 - loss: 0.9077 - accuracy: 0.687 - ETA: 18:39 - loss: 0.8723 - accuracy: 0.696 - ETA: 18:50 - loss: 0.8220 - accuracy: 0.722 - ETA: 18:58 - loss: 0.8396 - accuracy: 0.718 - ETA: 18:59 - loss: 0.8373 - accuracy: 0.721 - ETA: 18:58 - loss: 0.8192 - accuracy: 0.733 - ETA: 18:55 - loss: 0.8206 - accuracy: 0.737 - ETA: 18:51 - loss: 1.3969 - accuracy: 0.730 - ETA: 18:45 - loss: 1.3616 - accuracy: 0.721 - ETA: 18:38 - loss: 1.3103 - accuracy: 0.727 - ETA: 18:30 - loss: 1.2841 - accuracy: 0.726 - ETA: 18:22 - loss: 1.2615 - accuracy: 0.729 - ETA: 18:14 - loss: 1.2404 - accuracy: 0.725 - ETA: 18:04 - loss: 1.2168 - accuracy: 0.725 - ETA: 17:55 - loss: 1.1946 - accuracy: 0.726 - ETA: 17:45 - loss: 1.1881 - accuracy: 0.723 - ETA: 17:34 - loss: 1.1843 - accuracy: 0.715 - ETA: 17:23 - loss: 1.1716 - accuracy: 0.717 - ETA: 17:12 - loss: 1.1815 - accuracy: 0.713 - ETA: 17:01 - loss: 1.1592 - accuracy: 0.718 - ETA: 16:50 - loss: 1.1502 - accuracy: 0.715 - ETA: 16:38 - loss: 1.1367 - accuracy: 0.717 - ETA: 16:26 - loss: 1.1296 - accuracy: 0.715 - ETA: 16:15 - loss: 1.1253 - accuracy: 0.713 - ETA: 16:02 - loss: 1.1125 - accuracy: 0.714 - ETA: 15:50 - loss: 1.1014 - accuracy: 0.714 - ETA: 15:38 - loss: 1.1077 - accuracy: 0.715 - ETA: 15:25 - loss: 1.1085 - accuracy: 0.713 - ETA: 15:13 - loss: 1.1091 - accuracy: 0.708 - ETA: 15:00 - loss: 1.1003 - accuracy: 0.705 - ETA: 14:48 - loss: 1.0939 - accuracy: 0.704 - ETA: 14:35 - loss: 1.0840 - accuracy: 0.702 - ETA: 14:22 - loss: 1.0772 - accuracy: 0.701 - ETA: 14:10 - loss: 1.0696 - accuracy: 0.702 - ETA: 13:57 - loss: 1.0605 - accuracy: 0.704 - ETA: 13:45 - loss: 1.0602 - accuracy: 0.703 - ETA: 13:32 - loss: 1.0504 - accuracy: 0.705 - ETA: 13:19 - loss: 1.0457 - accuracy: 0.706 - ETA: 13:06 - loss: 1.0410 - accuracy: 0.706 - ETA: 12:53 - loss: 1.0423 - accuracy: 0.703 - ETA: 12:41 - loss: 1.0408 - accuracy: 0.703 - ETA: 12:27 - loss: 1.0312 - accuracy: 0.706 - ETA: 12:14 - loss: 1.0296 - accuracy: 0.703 - ETA: 12:01 - loss: 1.0263 - accuracy: 0.702 - ETA: 11:48 - loss: 1.0178 - accuracy: 0.704 - ETA: 11:35 - loss: 1.0140 - accuracy: 0.705 - ETA: 11:22 - loss: 1.0134 - accuracy: 0.704 - ETA: 11:09 - loss: 1.0113 - accuracy: 0.702 - ETA: 10:56 - loss: 1.0121 - accuracy: 0.701 - ETA: 10:42 - loss: 1.0094 - accuracy: 0.699 - ETA: 10:29 - loss: 0.9988 - accuracy: 0.702 - ETA: 10:16 - loss: 1.1350 - accuracy: 0.702 - ETA: 10:03 - loss: 1.1360 - accuracy: 0.700 - ETA: 9:50 - loss: 1.1297 - accuracy: 0.702 - ETA: 9:36 - loss: 1.1246 - accuracy: 0.70 - ETA: 9:23 - loss: 1.1193 - accuracy: 0.70 - ETA: 9:10 - loss: 1.1161 - accuracy: 0.70 - ETA: 8:57 - loss: 1.1131 - accuracy: 0.70 - ETA: 8:43 - loss: 1.1063 - accuracy: 0.70 - ETA: 8:30 - loss: 1.1045 - accuracy: 0.70 - ETA: 8:17 - loss: 1.1067 - accuracy: 0.70 - ETA: 8:03 - loss: 1.1040 - accuracy: 0.69 - ETA: 7:50 - loss: 1.1026 - accuracy: 0.69 - ETA: 7:36 - loss: 1.0989 - accuracy: 0.69 - ETA: 7:23 - loss: 1.1046 - accuracy: 0.69 - ETA: 7:10 - loss: 1.1016 - accuracy: 0.69 - ETA: 6:56 - loss: 1.0981 - accuracy: 0.70 - ETA: 6:43 - loss: 1.0947 - accuracy: 0.70 - ETA: 6:30 - loss: 1.0899 - accuracy: 0.70 - ETA: 6:16 - loss: 1.0852 - accuracy: 0.70 - ETA: 6:03 - loss: 1.0841 - accuracy: 0.70 - ETA: 5:49 - loss: 1.0811 - accuracy: 0.70 - ETA: 5:36 - loss: 1.0765 - accuracy: 0.70 - ETA: 5:23 - loss: 1.0728 - accuracy: 0.70 - ETA: 5:09 - loss: 1.0689 - accuracy: 0.70 - ETA: 4:56 - loss: 1.0717 - accuracy: 0.70 - ETA: 4:42 - loss: 1.0701 - accuracy: 0.70 - ETA: 4:29 - loss: 1.0715 - accuracy: 0.70 - ETA: 4:15 - loss: 1.0693 - accuracy: 0.70 - ETA: 4:02 - loss: 1.0681 - accuracy: 0.69 - ETA: 3:48 - loss: 1.0641 - accuracy: 0.70 - ETA: 3:35 - loss: 1.0610 - accuracy: 0.69 - ETA: 3:22 - loss: 1.1244 - accuracy: 0.69 - ETA: 3:08 - loss: 1.1187 - accuracy: 0.69 - ETA: 2:55 - loss: 1.1145 - accuracy: 0.70 - ETA: 2:41 - loss: 1.1140 - accuracy: 0.69 - ETA: 2:28 - loss: 1.1129 - accuracy: 0.69 - ETA: 2:14 - loss: 1.1093 - accuracy: 0.69 - ETA: 2:01 - loss: 1.1048 - accuracy: 0.69 - ETA: 1:47 - loss: 1.1019 - accuracy: 0.70 - ETA: 1:34 - loss: 1.0977 - accuracy: 0.70 - ETA: 1:20 - loss: 1.0925 - accuracy: 0.70 - ETA: 1:07 - loss: 1.0910 - accuracy: 0.70 - ETA: 53s - loss: 1.0877 - accuracy: 0.7025 - ETA: 40s - loss: 1.0936 - accuracy: 0.702 - ETA: 26s - loss: 1.0890 - accuracy: 0.702 - ETA: 13s - loss: 1.0854 - accuracy: 0.702 - ETA: 0s - loss: 1.0845 - accuracy: 0.702 - 1408s 14s/step - loss: 1.0845 - accuracy: 0.7022 - val_loss: 1.5809 - val_accuracy: 0.2717\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.9282 - accuracy: 0.68 - ETA: 11:31 - loss: 0.7790 - accuracy: 0.734 - ETA: 15:24 - loss: 0.7875 - accuracy: 0.718 - ETA: 17:04 - loss: 0.8857 - accuracy: 0.687 - ETA: 17:56 - loss: 0.8688 - accuracy: 0.693 - ETA: 18:28 - loss: 0.8148 - accuracy: 0.724 - ETA: 18:47 - loss: 0.8531 - accuracy: 0.714 - ETA: 18:57 - loss: 0.8701 - accuracy: 0.710 - ETA: 19:03 - loss: 0.8939 - accuracy: 0.701 - ETA: 19:04 - loss: 0.8879 - accuracy: 0.703 - ETA: 19:03 - loss: 0.8678 - accuracy: 0.707 - ETA: 18:59 - loss: 0.8909 - accuracy: 0.697 - ETA: 18:54 - loss: 0.8953 - accuracy: 0.692 - ETA: 18:48 - loss: 0.9077 - accuracy: 0.680 - ETA: 18:42 - loss: 0.9044 - accuracy: 0.679 - ETA: 18:33 - loss: 0.8993 - accuracy: 0.679 - ETA: 18:25 - loss: 0.8971 - accuracy: 0.680 - ETA: 18:16 - loss: 0.8947 - accuracy: 0.682 - ETA: 18:06 - loss: 0.8879 - accuracy: 0.684 - ETA: 17:56 - loss: 0.8875 - accuracy: 0.687 - ETA: 17:46 - loss: 0.8706 - accuracy: 0.694 - ETA: 17:35 - loss: 0.8626 - accuracy: 0.697 - ETA: 17:24 - loss: 0.8592 - accuracy: 0.701 - ETA: 17:13 - loss: 0.8579 - accuracy: 0.699 - ETA: 17:02 - loss: 0.8546 - accuracy: 0.700 - ETA: 16:51 - loss: 0.8750 - accuracy: 0.699 - ETA: 16:39 - loss: 0.8773 - accuracy: 0.695 - ETA: 16:28 - loss: 0.8780 - accuracy: 0.694 - ETA: 16:16 - loss: 0.8749 - accuracy: 0.694 - ETA: 16:04 - loss: 0.8713 - accuracy: 0.693 - ETA: 15:51 - loss: 0.8790 - accuracy: 0.689 - ETA: 15:39 - loss: 0.8720 - accuracy: 0.692 - ETA: 15:26 - loss: 0.8693 - accuracy: 0.692 - ETA: 15:14 - loss: 0.8660 - accuracy: 0.694 - ETA: 15:01 - loss: 0.8632 - accuracy: 0.694 - ETA: 14:49 - loss: 0.8597 - accuracy: 0.696 - ETA: 14:36 - loss: 0.8668 - accuracy: 0.696 - ETA: 14:23 - loss: 0.8635 - accuracy: 0.698 - ETA: 14:11 - loss: 0.8616 - accuracy: 0.696 - ETA: 13:58 - loss: 0.8694 - accuracy: 0.693 - ETA: 13:45 - loss: 0.8627 - accuracy: 0.697 - ETA: 13:32 - loss: 0.8669 - accuracy: 0.696 - ETA: 13:19 - loss: 0.8680 - accuracy: 0.696 - ETA: 13:06 - loss: 0.8671 - accuracy: 0.694 - ETA: 12:53 - loss: 0.8613 - accuracy: 0.697 - ETA: 12:41 - loss: 0.8629 - accuracy: 0.697 - ETA: 12:28 - loss: 0.8591 - accuracy: 0.698 - ETA: 12:14 - loss: 0.8537 - accuracy: 0.700 - ETA: 12:01 - loss: 0.8513 - accuracy: 0.701 - ETA: 11:48 - loss: 0.8465 - accuracy: 0.703 - ETA: 11:35 - loss: 0.8443 - accuracy: 0.702 - ETA: 11:22 - loss: 0.8448 - accuracy: 0.702 - ETA: 11:09 - loss: 0.8432 - accuracy: 0.702 - ETA: 10:56 - loss: 0.8393 - accuracy: 0.704 - ETA: 10:42 - loss: 0.8344 - accuracy: 0.705 - ETA: 10:29 - loss: 0.8337 - accuracy: 0.705 - ETA: 10:16 - loss: 0.8290 - accuracy: 0.706 - ETA: 10:03 - loss: 0.8295 - accuracy: 0.705 - ETA: 9:49 - loss: 0.8317 - accuracy: 0.705 - ETA: 9:36 - loss: 0.8288 - accuracy: 0.70 - ETA: 9:23 - loss: 0.8302 - accuracy: 0.70 - ETA: 9:10 - loss: 0.8289 - accuracy: 0.70 - ETA: 8:56 - loss: 0.8253 - accuracy: 0.70 - ETA: 8:43 - loss: 0.8254 - accuracy: 0.70 - ETA: 8:30 - loss: 0.8307 - accuracy: 0.70 - ETA: 8:16 - loss: 0.8336 - accuracy: 0.70 - ETA: 8:03 - loss: 0.8336 - accuracy: 0.70 - ETA: 7:50 - loss: 0.8308 - accuracy: 0.70 - ETA: 7:37 - loss: 0.8313 - accuracy: 0.70 - ETA: 7:23 - loss: 0.8328 - accuracy: 0.70 - ETA: 7:10 - loss: 0.8386 - accuracy: 0.70 - ETA: 6:57 - loss: 0.8411 - accuracy: 0.70 - ETA: 6:43 - loss: 0.8714 - accuracy: 0.70 - ETA: 6:30 - loss: 0.8708 - accuracy: 0.70 - ETA: 6:16 - loss: 0.8695 - accuracy: 0.70 - ETA: 6:03 - loss: 0.8663 - accuracy: 0.70 - ETA: 5:50 - loss: 0.8681 - accuracy: 0.70 - ETA: 5:36 - loss: 0.8662 - accuracy: 0.70 - ETA: 5:23 - loss: 0.8630 - accuracy: 0.70 - ETA: 5:09 - loss: 0.8595 - accuracy: 0.70 - ETA: 4:56 - loss: 0.8578 - accuracy: 0.70 - ETA: 4:42 - loss: 0.8597 - accuracy: 0.70 - ETA: 4:29 - loss: 0.8608 - accuracy: 0.70 - ETA: 4:16 - loss: 0.8613 - accuracy: 0.70 - ETA: 4:02 - loss: 0.8602 - accuracy: 0.70 - ETA: 3:49 - loss: 0.8612 - accuracy: 0.70 - ETA: 3:35 - loss: 0.8638 - accuracy: 0.70 - ETA: 3:22 - loss: 0.8632 - accuracy: 0.70 - ETA: 3:08 - loss: 0.8623 - accuracy: 0.70 - ETA: 2:55 - loss: 0.8624 - accuracy: 0.70 - ETA: 2:41 - loss: 0.8619 - accuracy: 0.70 - ETA: 2:28 - loss: 0.8627 - accuracy: 0.70 - ETA: 2:14 - loss: 0.8622 - accuracy: 0.70 - ETA: 2:01 - loss: 0.8610 - accuracy: 0.70 - ETA: 1:47 - loss: 0.8616 - accuracy: 0.70 - ETA: 1:34 - loss: 0.8639 - accuracy: 0.70 - ETA: 1:20 - loss: 0.8661 - accuracy: 0.70 - ETA: 1:07 - loss: 0.8658 - accuracy: 0.70 - ETA: 53s - loss: 0.8691 - accuracy: 0.7021 - ETA: 40s - loss: 0.8672 - accuracy: 0.702 - ETA: 26s - loss: 0.8664 - accuracy: 0.703 - ETA: 13s - loss: 0.8648 - accuracy: 0.703 - ETA: 0s - loss: 0.8645 - accuracy: 0.703 - 1408s 14s/step - loss: 0.8645 - accuracy: 0.7034 - val_loss: 1.5824 - val_accuracy: 0.2717\n",
      "Epoch 8/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.9322 - accuracy: 0.65 - ETA: 11:26 - loss: 0.9960 - accuracy: 0.609 - ETA: 15:13 - loss: 0.9331 - accuracy: 0.635 - ETA: 16:54 - loss: 0.9269 - accuracy: 0.640 - ETA: 17:50 - loss: 0.8505 - accuracy: 0.681 - ETA: 18:22 - loss: 0.8163 - accuracy: 0.692 - ETA: 18:43 - loss: 0.8145 - accuracy: 0.696 - ETA: 18:53 - loss: 0.8006 - accuracy: 0.703 - ETA: 18:59 - loss: 0.8191 - accuracy: 0.697 - ETA: 19:01 - loss: 0.7957 - accuracy: 0.709 - ETA: 19:01 - loss: 0.8261 - accuracy: 0.696 - ETA: 18:58 - loss: 0.8260 - accuracy: 0.697 - ETA: 18:53 - loss: 0.8283 - accuracy: 0.694 - ETA: 18:46 - loss: 0.8328 - accuracy: 0.694 - ETA: 18:39 - loss: 0.8417 - accuracy: 0.693 - ETA: 18:31 - loss: 0.8489 - accuracy: 0.689 - ETA: 18:23 - loss: 0.8437 - accuracy: 0.689 - ETA: 18:14 - loss: 0.8457 - accuracy: 0.687 - ETA: 18:04 - loss: 0.8334 - accuracy: 0.694 - ETA: 17:55 - loss: 0.8222 - accuracy: 0.701 - ETA: 17:45 - loss: 0.8162 - accuracy: 0.703 - ETA: 17:34 - loss: 0.8250 - accuracy: 0.697 - ETA: 17:23 - loss: 0.8317 - accuracy: 0.691 - ETA: 17:12 - loss: 0.8299 - accuracy: 0.695 - ETA: 17:01 - loss: 0.8322 - accuracy: 0.693 - ETA: 16:49 - loss: 0.8194 - accuracy: 0.699 - ETA: 16:37 - loss: 0.8214 - accuracy: 0.697 - ETA: 16:25 - loss: 0.8225 - accuracy: 0.696 - ETA: 16:14 - loss: 0.8194 - accuracy: 0.698 - ETA: 16:01 - loss: 0.8143 - accuracy: 0.700 - ETA: 15:50 - loss: 0.8264 - accuracy: 0.692 - ETA: 15:38 - loss: 0.8164 - accuracy: 0.695 - ETA: 15:26 - loss: 0.8221 - accuracy: 0.692 - ETA: 15:13 - loss: 0.8199 - accuracy: 0.691 - ETA: 15:01 - loss: 0.8133 - accuracy: 0.696 - ETA: 14:48 - loss: 0.8205 - accuracy: 0.694 - ETA: 14:36 - loss: 0.8225 - accuracy: 0.693 - ETA: 14:23 - loss: 0.8237 - accuracy: 0.692 - ETA: 14:11 - loss: 0.8257 - accuracy: 0.693 - ETA: 13:58 - loss: 0.8186 - accuracy: 0.697 - ETA: 13:45 - loss: 0.8251 - accuracy: 0.696 - ETA: 13:32 - loss: 0.8308 - accuracy: 0.695 - ETA: 13:19 - loss: 0.8325 - accuracy: 0.694 - ETA: 13:06 - loss: 0.8306 - accuracy: 0.698 - ETA: 12:53 - loss: 0.8305 - accuracy: 0.697 - ETA: 12:40 - loss: 0.8289 - accuracy: 0.697 - ETA: 12:27 - loss: 0.8326 - accuracy: 0.694 - ETA: 12:14 - loss: 0.8314 - accuracy: 0.695 - ETA: 12:00 - loss: 0.8356 - accuracy: 0.695 - ETA: 11:47 - loss: 0.8376 - accuracy: 0.692 - ETA: 11:34 - loss: 0.8376 - accuracy: 0.692 - ETA: 11:21 - loss: 0.8372 - accuracy: 0.693 - ETA: 11:08 - loss: 0.8389 - accuracy: 0.692 - ETA: 10:55 - loss: 0.8396 - accuracy: 0.692 - ETA: 10:42 - loss: 0.8390 - accuracy: 0.693 - ETA: 10:29 - loss: 0.8370 - accuracy: 0.694 - ETA: 10:16 - loss: 0.8346 - accuracy: 0.695 - ETA: 10:02 - loss: 0.8335 - accuracy: 0.696 - ETA: 9:49 - loss: 0.8318 - accuracy: 0.697 - ETA: 9:36 - loss: 0.8332 - accuracy: 0.69 - ETA: 9:23 - loss: 0.8333 - accuracy: 0.69 - ETA: 9:09 - loss: 0.8322 - accuracy: 0.69 - ETA: 8:56 - loss: 0.8337 - accuracy: 0.69 - ETA: 8:43 - loss: 0.8296 - accuracy: 0.69 - ETA: 8:30 - loss: 0.8257 - accuracy: 0.70 - ETA: 8:16 - loss: 0.8229 - accuracy: 0.70 - ETA: 8:03 - loss: 0.8249 - accuracy: 0.70 - ETA: 7:50 - loss: 0.8271 - accuracy: 0.70 - ETA: 7:36 - loss: 0.8274 - accuracy: 0.69 - ETA: 7:23 - loss: 0.8234 - accuracy: 0.69 - ETA: 7:10 - loss: 0.8212 - accuracy: 0.70 - ETA: 6:56 - loss: 0.8247 - accuracy: 0.69 - ETA: 6:43 - loss: 0.8244 - accuracy: 0.69 - ETA: 6:29 - loss: 0.8241 - accuracy: 0.69 - ETA: 6:16 - loss: 0.8259 - accuracy: 0.70 - ETA: 6:03 - loss: 0.8242 - accuracy: 0.70 - ETA: 5:49 - loss: 0.8253 - accuracy: 0.70 - ETA: 5:36 - loss: 0.8253 - accuracy: 0.70 - ETA: 5:23 - loss: 0.8250 - accuracy: 0.70 - ETA: 5:09 - loss: 0.8267 - accuracy: 0.69 - ETA: 4:56 - loss: 0.8276 - accuracy: 0.70 - ETA: 4:42 - loss: 0.8307 - accuracy: 0.69 - ETA: 4:29 - loss: 0.8297 - accuracy: 0.70 - ETA: 4:15 - loss: 0.8307 - accuracy: 0.70 - ETA: 4:02 - loss: 0.8354 - accuracy: 0.69 - ETA: 3:49 - loss: 0.8357 - accuracy: 0.69 - ETA: 3:35 - loss: 0.8355 - accuracy: 0.70 - ETA: 3:22 - loss: 0.8350 - accuracy: 0.70 - ETA: 3:08 - loss: 0.8359 - accuracy: 0.69 - ETA: 2:55 - loss: 0.8355 - accuracy: 0.70 - ETA: 2:41 - loss: 0.8325 - accuracy: 0.70 - ETA: 2:28 - loss: 0.8312 - accuracy: 0.70 - ETA: 2:14 - loss: 0.8316 - accuracy: 0.70 - ETA: 2:01 - loss: 0.8300 - accuracy: 0.70 - ETA: 1:47 - loss: 0.8292 - accuracy: 0.70 - ETA: 1:34 - loss: 0.8276 - accuracy: 0.70 - ETA: 1:20 - loss: 0.8242 - accuracy: 0.70 - ETA: 1:07 - loss: 0.8245 - accuracy: 0.70 - ETA: 53s - loss: 0.8207 - accuracy: 0.7053 - ETA: 40s - loss: 0.8205 - accuracy: 0.705 - ETA: 27s - loss: 0.8173 - accuracy: 0.706 - ETA: 13s - loss: 0.8166 - accuracy: 0.705 - ETA: 0s - loss: 0.8174 - accuracy: 0.705 - 1408s 14s/step - loss: 0.8174 - accuracy: 0.7058 - val_loss: 1.4978 - val_accuracy: 0.5217\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.7998 - accuracy: 0.68 - ETA: 11:25 - loss: 0.6693 - accuracy: 0.750 - ETA: 15:05 - loss: 0.6896 - accuracy: 0.760 - ETA: 16:52 - loss: 0.6742 - accuracy: 0.757 - ETA: 17:48 - loss: 0.7469 - accuracy: 0.737 - ETA: 18:19 - loss: 0.7374 - accuracy: 0.739 - ETA: 18:40 - loss: 0.7194 - accuracy: 0.741 - ETA: 18:51 - loss: 0.7035 - accuracy: 0.750 - ETA: 18:56 - loss: 0.6858 - accuracy: 0.753 - ETA: 18:58 - loss: 0.7357 - accuracy: 0.734 - ETA: 18:57 - loss: 0.7514 - accuracy: 0.727 - ETA: 18:55 - loss: 0.7946 - accuracy: 0.721 - ETA: 18:51 - loss: 0.7832 - accuracy: 0.730 - ETA: 18:45 - loss: 0.7798 - accuracy: 0.729 - ETA: 18:39 - loss: 0.7773 - accuracy: 0.731 - ETA: 18:31 - loss: 0.7918 - accuracy: 0.722 - ETA: 18:23 - loss: 0.7891 - accuracy: 0.722 - ETA: 18:14 - loss: 0.7717 - accuracy: 0.730 - ETA: 18:04 - loss: 0.7739 - accuracy: 0.727 - ETA: 17:54 - loss: 0.7815 - accuracy: 0.723 - ETA: 17:44 - loss: 0.7762 - accuracy: 0.727 - ETA: 17:34 - loss: 0.7774 - accuracy: 0.727 - ETA: 17:22 - loss: 0.7766 - accuracy: 0.724 - ETA: 17:11 - loss: 0.7740 - accuracy: 0.726 - ETA: 17:00 - loss: 0.7682 - accuracy: 0.728 - ETA: 16:48 - loss: 0.7821 - accuracy: 0.721 - ETA: 16:37 - loss: 0.7864 - accuracy: 0.721 - ETA: 16:25 - loss: 0.7825 - accuracy: 0.721 - ETA: 16:13 - loss: 0.7824 - accuracy: 0.719 - ETA: 16:01 - loss: 0.7826 - accuracy: 0.720 - ETA: 15:49 - loss: 0.7809 - accuracy: 0.719 - ETA: 15:37 - loss: 0.7779 - accuracy: 0.719 - ETA: 15:25 - loss: 0.7834 - accuracy: 0.718 - ETA: 15:13 - loss: 0.7876 - accuracy: 0.718 - ETA: 15:00 - loss: 0.8061 - accuracy: 0.718 - ETA: 14:48 - loss: 0.8004 - accuracy: 0.722 - ETA: 14:35 - loss: 0.8000 - accuracy: 0.723 - ETA: 14:22 - loss: 0.7978 - accuracy: 0.722 - ETA: 14:10 - loss: 0.7965 - accuracy: 0.722 - ETA: 13:57 - loss: 0.8043 - accuracy: 0.723 - ETA: 13:44 - loss: 0.8052 - accuracy: 0.723 - ETA: 13:31 - loss: 0.8014 - accuracy: 0.724 - ETA: 13:18 - loss: 0.8083 - accuracy: 0.721 - ETA: 13:06 - loss: 0.8071 - accuracy: 0.722 - ETA: 12:52 - loss: 0.8039 - accuracy: 0.723 - ETA: 12:39 - loss: 0.8075 - accuracy: 0.719 - ETA: 12:26 - loss: 0.8073 - accuracy: 0.719 - ETA: 12:13 - loss: 0.8030 - accuracy: 0.719 - ETA: 12:00 - loss: 0.8011 - accuracy: 0.720 - ETA: 11:47 - loss: 0.8018 - accuracy: 0.717 - ETA: 11:34 - loss: 0.7978 - accuracy: 0.719 - ETA: 11:21 - loss: 0.7933 - accuracy: 0.721 - ETA: 11:08 - loss: 0.7898 - accuracy: 0.721 - ETA: 10:54 - loss: 0.7871 - accuracy: 0.722 - ETA: 10:41 - loss: 0.7884 - accuracy: 0.721 - ETA: 10:28 - loss: 0.7849 - accuracy: 0.724 - ETA: 10:15 - loss: 0.7874 - accuracy: 0.723 - ETA: 10:02 - loss: 0.7880 - accuracy: 0.723 - ETA: 9:49 - loss: 0.7896 - accuracy: 0.723 - ETA: 9:36 - loss: 0.7931 - accuracy: 0.72 - ETA: 9:23 - loss: 0.7927 - accuracy: 0.72 - ETA: 9:09 - loss: 0.7908 - accuracy: 0.72 - ETA: 8:56 - loss: 0.7964 - accuracy: 0.72 - ETA: 8:43 - loss: 0.7965 - accuracy: 0.72 - ETA: 8:30 - loss: 0.7942 - accuracy: 0.72 - ETA: 8:16 - loss: 0.7951 - accuracy: 0.72 - ETA: 8:03 - loss: 0.7998 - accuracy: 0.72 - ETA: 7:50 - loss: 0.8005 - accuracy: 0.71 - ETA: 7:36 - loss: 0.8005 - accuracy: 0.71 - ETA: 7:23 - loss: 0.8008 - accuracy: 0.71 - ETA: 7:10 - loss: 0.7995 - accuracy: 0.71 - ETA: 6:56 - loss: 0.7964 - accuracy: 0.72 - ETA: 6:43 - loss: 0.8019 - accuracy: 0.71 - ETA: 6:30 - loss: 0.8021 - accuracy: 0.71 - ETA: 6:16 - loss: 0.7999 - accuracy: 0.71 - ETA: 6:03 - loss: 0.7984 - accuracy: 0.72 - ETA: 5:49 - loss: 0.7997 - accuracy: 0.71 - ETA: 5:36 - loss: 0.8021 - accuracy: 0.71 - ETA: 5:23 - loss: 0.8072 - accuracy: 0.71 - ETA: 5:09 - loss: 0.8109 - accuracy: 0.71 - ETA: 4:56 - loss: 0.8098 - accuracy: 0.71 - ETA: 4:42 - loss: 0.8137 - accuracy: 0.71 - ETA: 4:29 - loss: 0.8167 - accuracy: 0.71 - ETA: 4:16 - loss: 0.8180 - accuracy: 0.71 - ETA: 4:02 - loss: 0.8195 - accuracy: 0.71 - ETA: 3:49 - loss: 0.8200 - accuracy: 0.71 - ETA: 3:35 - loss: 0.8204 - accuracy: 0.71 - ETA: 3:22 - loss: 0.8182 - accuracy: 0.71 - ETA: 3:08 - loss: 0.8183 - accuracy: 0.71 - ETA: 2:55 - loss: 0.8167 - accuracy: 0.71 - ETA: 2:41 - loss: 0.8299 - accuracy: 0.71 - ETA: 2:28 - loss: 0.8294 - accuracy: 0.71 - ETA: 2:14 - loss: 0.8271 - accuracy: 0.71 - ETA: 2:01 - loss: 0.8248 - accuracy: 0.71 - ETA: 1:47 - loss: 0.8244 - accuracy: 0.71 - ETA: 1:34 - loss: 0.8238 - accuracy: 0.71 - ETA: 1:20 - loss: 0.8235 - accuracy: 0.71 - ETA: 1:07 - loss: 0.8233 - accuracy: 0.71 - ETA: 53s - loss: 0.8216 - accuracy: 0.7173 - ETA: 40s - loss: 0.8212 - accuracy: 0.717 - ETA: 26s - loss: 0.8216 - accuracy: 0.716 - ETA: 13s - loss: 0.8256 - accuracy: 0.714 - ETA: 0s - loss: 0.8219 - accuracy: 0.716 - 1408s 14s/step - loss: 0.8219 - accuracy: 0.7165 - val_loss: 1.3110 - val_accuracy: 0.6359\n",
      "Epoch 10/20\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.5258 - accuracy: 0.81 - ETA: 11:25 - loss: 0.7882 - accuracy: 0.718 - ETA: 15:07 - loss: 0.7795 - accuracy: 0.708 - ETA: 16:52 - loss: 0.8011 - accuracy: 0.703 - ETA: 17:50 - loss: 0.8523 - accuracy: 0.668 - ETA: 18:22 - loss: 0.7926 - accuracy: 0.692 - ETA: 18:40 - loss: 0.7905 - accuracy: 0.700 - ETA: 18:53 - loss: 0.7616 - accuracy: 0.707 - ETA: 19:00 - loss: 0.7363 - accuracy: 0.722 - ETA: 19:01 - loss: 0.7220 - accuracy: 0.734 - ETA: 19:01 - loss: 0.7419 - accuracy: 0.715 - ETA: 18:58 - loss: 0.7353 - accuracy: 0.718 - ETA: 18:53 - loss: 0.7423 - accuracy: 0.711 - ETA: 18:47 - loss: 0.7746 - accuracy: 0.703 - ETA: 18:40 - loss: 0.7628 - accuracy: 0.706 - ETA: 18:32 - loss: 0.7638 - accuracy: 0.703 - ETA: 18:23 - loss: 0.7811 - accuracy: 0.696 - ETA: 18:14 - loss: 0.7965 - accuracy: 0.692 - ETA: 18:04 - loss: 0.7950 - accuracy: 0.692 - ETA: 17:54 - loss: 0.7911 - accuracy: 0.693 - ETA: 17:44 - loss: 0.7869 - accuracy: 0.696 - ETA: 17:35 - loss: 0.8131 - accuracy: 0.691 - ETA: 17:25 - loss: 0.8305 - accuracy: 0.686 - ETA: 17:13 - loss: 0.8242 - accuracy: 0.687 - ETA: 17:02 - loss: 0.8153 - accuracy: 0.692 - ETA: 16:50 - loss: 0.8269 - accuracy: 0.689 - ETA: 16:39 - loss: 0.8235 - accuracy: 0.693 - ETA: 16:26 - loss: 0.8298 - accuracy: 0.689 - ETA: 16:14 - loss: 0.8234 - accuracy: 0.692 - ETA: 16:00 - loss: 0.8172 - accuracy: 0.695 - ETA: 15:48 - loss: 0.8160 - accuracy: 0.694 - ETA: 15:36 - loss: 0.8144 - accuracy: 0.697 - ETA: 15:24 - loss: 0.8152 - accuracy: 0.697 - ETA: 15:11 - loss: 0.8095 - accuracy: 0.699 - ETA: 14:59 - loss: 0.8165 - accuracy: 0.700 - ETA: 14:46 - loss: 0.8151 - accuracy: 0.701 - ETA: 14:34 - loss: 0.8129 - accuracy: 0.702 - ETA: 14:21 - loss: 0.8126 - accuracy: 0.701 - ETA: 14:09 - loss: 0.8132 - accuracy: 0.702 - ETA: 13:56 - loss: 0.8145 - accuracy: 0.701 - ETA: 13:44 - loss: 0.8155 - accuracy: 0.700 - ETA: 13:31 - loss: 0.8161 - accuracy: 0.699 - ETA: 13:19 - loss: 0.8154 - accuracy: 0.700 - ETA: 13:07 - loss: 0.8210 - accuracy: 0.697 - ETA: 12:55 - loss: 0.8143 - accuracy: 0.698 - ETA: 12:43 - loss: 0.8188 - accuracy: 0.698 - ETA: 12:30 - loss: 0.8139 - accuracy: 0.701 - ETA: 12:17 - loss: 0.8127 - accuracy: 0.702 - ETA: 12:05 - loss: 0.8201 - accuracy: 0.698 - ETA: 11:52 - loss: 0.8211 - accuracy: 0.697 - ETA: 11:40 - loss: 0.8223 - accuracy: 0.696 - ETA: 11:27 - loss: 0.8220 - accuracy: 0.697 - ETA: 11:14 - loss: 0.8280 - accuracy: 0.694 - ETA: 11:01 - loss: 0.8310 - accuracy: 0.693 - ETA: 10:48 - loss: 0.8313 - accuracy: 0.694 - ETA: 10:35 - loss: 0.8326 - accuracy: 0.692 - ETA: 10:22 - loss: 0.8310 - accuracy: 0.693 - ETA: 10:09 - loss: 0.8290 - accuracy: 0.695 - ETA: 9:56 - loss: 0.8299 - accuracy: 0.694 - ETA: 9:43 - loss: 0.8287 - accuracy: 0.69 - ETA: 9:30 - loss: 0.8259 - accuracy: 0.69 - ETA: 9:17 - loss: 0.8276 - accuracy: 0.69 - ETA: 9:03 - loss: 0.8251 - accuracy: 0.69 - ETA: 8:50 - loss: 0.8245 - accuracy: 0.69 - ETA: 8:36 - loss: 0.8239 - accuracy: 0.69 - ETA: 8:23 - loss: 0.8240 - accuracy: 0.69 - ETA: 8:09 - loss: 0.8246 - accuracy: 0.69 - ETA: 7:56 - loss: 0.8288 - accuracy: 0.69 - ETA: 7:42 - loss: 0.8268 - accuracy: 0.69 - ETA: 7:28 - loss: 0.8230 - accuracy: 0.69 - ETA: 7:15 - loss: 0.8245 - accuracy: 0.69 - ETA: 7:01 - loss: 0.8248 - accuracy: 0.69 - ETA: 6:48 - loss: 0.8222 - accuracy: 0.69 - ETA: 6:34 - loss: 0.8511 - accuracy: 0.70 - ETA: 6:21 - loss: 0.8744 - accuracy: 0.69 - ETA: 6:07 - loss: 0.8727 - accuracy: 0.70 - ETA: 5:53 - loss: 0.8715 - accuracy: 0.70 - ETA: 5:40 - loss: 0.8679 - accuracy: 0.70 - ETA: 5:26 - loss: 0.8632 - accuracy: 0.70 - ETA: 5:13 - loss: 0.8640 - accuracy: 0.70 - ETA: 4:59 - loss: 0.8648 - accuracy: 0.70 - ETA: 4:45 - loss: 0.8676 - accuracy: 0.70 - ETA: 4:32 - loss: 0.8664 - accuracy: 0.70 - ETA: 4:18 - loss: 0.8663 - accuracy: 0.70 - ETA: 4:05 - loss: 0.8618 - accuracy: 0.70 - ETA: 3:51 - loss: 0.8581 - accuracy: 0.70 - ETA: 3:37 - loss: 0.8600 - accuracy: 0.70 - ETA: 3:24 - loss: 0.8645 - accuracy: 0.70 - ETA: 3:10 - loss: 0.8630 - accuracy: 0.70 - ETA: 2:56 - loss: 0.8591 - accuracy: 0.70 - ETA: 2:43 - loss: 0.8558 - accuracy: 0.70 - ETA: 2:29 - loss: 0.8583 - accuracy: 0.70 - ETA: 2:16 - loss: 0.8567 - accuracy: 0.70 - ETA: 2:02 - loss: 0.8565 - accuracy: 0.70 - ETA: 1:48 - loss: 0.8573 - accuracy: 0.70 - ETA: 1:35 - loss: 0.8568 - accuracy: 0.70 - ETA: 1:21 - loss: 0.8586 - accuracy: 0.70 - ETA: 1:08 - loss: 0.8572 - accuracy: 0.70 - ETA: 54s - loss: 0.8558 - accuracy: 0.7063 - ETA: 40s - loss: 0.8553 - accuracy: 0.705 - ETA: 27s - loss: 0.8565 - accuracy: 0.705 - ETA: 13s - loss: 0.8583 - accuracy: 0.705 - ETA: 0s - loss: 0.8565 - accuracy: 0.705 - 1420s 14s/step - loss: 0.8565 - accuracy: 0.7058 - val_loss: 1.1770 - val_accuracy: 0.6440\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - ETA: 0s - loss: 0.7367 - accuracy: 0.68 - ETA: 11:28 - loss: 0.8023 - accuracy: 0.718 - ETA: 15:07 - loss: 0.8447 - accuracy: 0.697 - ETA: 16:50 - loss: 0.7751 - accuracy: 0.726 - ETA: 17:46 - loss: 0.7331 - accuracy: 0.743 - ETA: 18:22 - loss: 0.7318 - accuracy: 0.750 - ETA: 18:42 - loss: 0.7082 - accuracy: 0.758 - ETA: 18:52 - loss: 0.7166 - accuracy: 0.750 - ETA: 18:58 - loss: 0.7013 - accuracy: 0.760 - ETA: 18:59 - loss: 0.7324 - accuracy: 0.750 - ETA: 18:58 - loss: 0.7185 - accuracy: 0.758 - ETA: 18:55 - loss: 0.7031 - accuracy: 0.763 - ETA: 18:50 - loss: 0.7220 - accuracy: 0.750 - ETA: 18:45 - loss: 0.7288 - accuracy: 0.745 - ETA: 18:38 - loss: 0.7494 - accuracy: 0.739 - ETA: 18:31 - loss: 0.7625 - accuracy: 0.732 - ETA: 18:22 - loss: 0.7720 - accuracy: 0.724 - ETA: 18:09 - loss: 0.7767 - accuracy: 0.726 - ETA: 18:00 - loss: 0.7891 - accuracy: 0.719 - ETA: 17:50 - loss: 0.8016 - accuracy: 0.716 - ETA: 17:39 - loss: 0.8050 - accuracy: 0.713 - ETA: 17:29 - loss: 0.7957 - accuracy: 0.717 - ETA: 17:19 - loss: 0.8036 - accuracy: 0.713 - ETA: 17:08 - loss: 0.8017 - accuracy: 0.714 - ETA: 16:57 - loss: 0.8024 - accuracy: 0.713 - ETA: 16:45 - loss: 0.7920 - accuracy: 0.719 - ETA: 16:34 - loss: 0.7878 - accuracy: 0.721 - ETA: 16:23 - loss: 0.7821 - accuracy: 0.723 - ETA: 16:11 - loss: 0.8473 - accuracy: 0.721 - ETA: 15:58 - loss: 0.8387 - accuracy: 0.723 - ETA: 15:47 - loss: 0.8423 - accuracy: 0.719 - ETA: 15:35 - loss: 0.8353 - accuracy: 0.720 - ETA: 15:23 - loss: 0.8345 - accuracy: 0.720 - ETA: 15:10 - loss: 0.8315 - accuracy: 0.721 - ETA: 14:58 - loss: 0.8303 - accuracy: 0.722 - ETA: 14:45 - loss: 0.8289 - accuracy: 0.721 - ETA: 14:33 - loss: 0.8213 - accuracy: 0.724 - ETA: 14:21 - loss: 0.8151 - accuracy: 0.726 - ETA: 14:08 - loss: 0.8151 - accuracy: 0.725 - ETA: 13:55 - loss: 0.8166 - accuracy: 0.722 - ETA: 13:43 - loss: 0.8112 - accuracy: 0.724 - ETA: 13:30 - loss: 0.8169 - accuracy: 0.721 - ETA: 13:17 - loss: 0.8217 - accuracy: 0.718 - ETA: 13:04 - loss: 0.8183 - accuracy: 0.720 - ETA: 12:51 - loss: 0.8151 - accuracy: 0.721 - ETA: 12:39 - loss: 0.8111 - accuracy: 0.721 - ETA: 12:26 - loss: 0.8112 - accuracy: 0.721 - ETA: 12:13 - loss: 0.8125 - accuracy: 0.719 - ETA: 12:00 - loss: 0.8114 - accuracy: 0.720 - ETA: 11:47 - loss: 0.8189 - accuracy: 0.717 - ETA: 11:34 - loss: 0.8183 - accuracy: 0.717 - ETA: 11:21 - loss: 0.8206 - accuracy: 0.717 - ETA: 11:08 - loss: 0.8200 - accuracy: 0.718 - ETA: 10:55 - loss: 0.8184 - accuracy: 0.719 - ETA: 10:42 - loss: 0.8186 - accuracy: 0.718 - ETA: 10:28 - loss: 0.8163 - accuracy: 0.718 - ETA: 10:15 - loss: 0.8207 - accuracy: 0.716 - ETA: 10:02 - loss: 0.8209 - accuracy: 0.717 - ETA: 9:49 - loss: 0.8197 - accuracy: 0.716 - ETA: 9:35 - loss: 0.8199 - accuracy: 0.71 - ETA: 9:22 - loss: 0.8165 - accuracy: 0.71 - ETA: 9:09 - loss: 0.8218 - accuracy: 0.71 - ETA: 8:56 - loss: 0.8246 - accuracy: 0.71 - ETA: 8:42 - loss: 0.8276 - accuracy: 0.71 - ETA: 8:29 - loss: 0.8279 - accuracy: 0.70 - ETA: 8:16 - loss: 0.8239 - accuracy: 0.71 - ETA: 8:03 - loss: 0.8249 - accuracy: 0.71 - ETA: 7:49 - loss: 0.8221 - accuracy: 0.71 - ETA: 7:36 - loss: 0.8251 - accuracy: 0.71 - ETA: 7:23 - loss: 0.8234 - accuracy: 0.71 - ETA: 7:09 - loss: 0.8258 - accuracy: 0.71 - ETA: 6:56 - loss: 0.8243 - accuracy: 0.71 - ETA: 6:43 - loss: 0.8234 - accuracy: 0.71 - ETA: 6:29 - loss: 0.8211 - accuracy: 0.71 - ETA: 6:16 - loss: 0.8203 - accuracy: 0.71 - ETA: 6:03 - loss: 0.8193 - accuracy: 0.71 - ETA: 5:49 - loss: 0.8176 - accuracy: 0.71 - ETA: 5:36 - loss: 0.8163 - accuracy: 0.71 - ETA: 5:23 - loss: 0.8158 - accuracy: 0.71 - ETA: 5:09 - loss: 0.8145 - accuracy: 0.71 - ETA: 4:56 - loss: 0.8143 - accuracy: 0.71 - ETA: 4:42 - loss: 0.8187 - accuracy: 0.71 - ETA: 4:29 - loss: 0.8196 - accuracy: 0.71 - ETA: 4:15 - loss: 0.8174 - accuracy: 0.71 - ETA: 4:02 - loss: 0.8150 - accuracy: 0.71 - ETA: 3:49 - loss: 0.8141 - accuracy: 0.71 - ETA: 3:35 - loss: 0.8175 - accuracy: 0.71 - ETA: 3:22 - loss: 0.8198 - accuracy: 0.71 - ETA: 3:08 - loss: 0.8194 - accuracy: 0.71 - ETA: 2:55 - loss: 0.8219 - accuracy: 0.71 - ETA: 2:41 - loss: 0.8190 - accuracy: 0.71 - ETA: 2:28 - loss: 0.8208 - accuracy: 0.71 - ETA: 2:14 - loss: 0.8208 - accuracy: 0.71 - ETA: 2:01 - loss: 0.8226 - accuracy: 0.71 - ETA: 1:47 - loss: 0.8223 - accuracy: 0.71 - ETA: 1:34 - loss: 0.8218 - accuracy: 0.71 - ETA: 1:20 - loss: 0.8217 - accuracy: 0.71 - ETA: 1:07 - loss: 0.8212 - accuracy: 0.71 - ETA: 53s - loss: 0.8521 - accuracy: 0.7113 - ETA: 40s - loss: 0.8530 - accuracy: 0.710 - ETA: 27s - loss: 0.8516 - accuracy: 0.711 - ETA: 13s - loss: 0.8513 - accuracy: 0.711 - ETA: 0s - loss: 0.8494 - accuracy: 0.712 - 1409s 14s/step - loss: 0.8494 - accuracy: 0.7128 - val_loss: 0.9875 - val_accuracy: 0.6902\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "hist = model123.fit_generator(train_set, validation_data=test_set, epochs=20, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model123.save('model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=hist\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class ResnetBlock(Model):\n",
    "    \"\"\"\n",
    "    A standard resnet block.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, down_sample=False):\n",
    "        \"\"\"\n",
    "        channels: same as number of convolution kernels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.__channels = channels\n",
    "        self.__down_sample = down_sample\n",
    "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
    "\n",
    "        KERNEL_SIZE = (3, 3)\n",
    "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
    "        INIT_SCHEME = \"he_normal\"\n",
    "\n",
    "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_1 = BatchNormalization()\n",
    "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
    "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
    "        self.bn_2 = BatchNormalization()\n",
    "        self.merge = Add()\n",
    "\n",
    "        if self.__down_sample:\n",
    "            # perform down sampling using stride of 2, according to [1].\n",
    "            self.res_conv = Conv2D(\n",
    "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
    "            self.res_bn = BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        res = inputs\n",
    "\n",
    "        x = self.conv_1(inputs)\n",
    "        x = self.bn_1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "\n",
    "        if self.__down_sample:\n",
    "            res = self.res_conv(res)\n",
    "            res = self.res_bn(res)\n",
    "\n",
    "        # if not perform down sample, then add a shortcut directly\n",
    "        x = self.merge([x, res])\n",
    "        out = tf.nn.relu(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResNet18(Model):\n",
    "\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        \"\"\"\n",
    "            num_classes: number of classes in specific classification task.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
    "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
    "        self.init_bn = BatchNormalization()\n",
    "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
    "        self.res_1_1 = ResnetBlock(64)\n",
    "        self.res_1_2 = ResnetBlock(64)\n",
    "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
    "        self.res_2_2 = ResnetBlock(128)\n",
    "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
    "        self.res_3_2 = ResnetBlock(256)\n",
    "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
    "        self.res_4_2 = ResnetBlock(512)\n",
    "        self.avg_pool = GlobalAveragePooling2D()\n",
    "        self.flat = Flatten()\n",
    "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        out = self.conv_1(inputs)\n",
    "        out = self.init_bn(out)\n",
    "        out = tf.nn.relu(out)\n",
    "        out = self.pool_2(out)\n",
    "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
    "            out = res_block(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.flat(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x000001E2E4774C48>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x000001E2E4774C48>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"res_net18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "resnet_block (ResnetBlock)   multiple                  74368     \n",
      "_________________________________________________________________\n",
      "resnet_block_1 (ResnetBlock) multiple                  74368     \n",
      "_________________________________________________________________\n",
      "resnet_block_2 (ResnetBlock) multiple                  231296    \n",
      "_________________________________________________________________\n",
      "resnet_block_3 (ResnetBlock) multiple                  296192    \n",
      "_________________________________________________________________\n",
      "resnet_block_4 (ResnetBlock) multiple                  921344    \n",
      "_________________________________________________________________\n",
      "resnet_block_5 (ResnetBlock) multiple                  1182208   \n",
      "_________________________________________________________________\n",
      "resnet_block_6 (ResnetBlock) multiple                  3677696   \n",
      "_________________________________________________________________\n",
      "resnet_block_7 (ResnetBlock) multiple                  4723712   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  2565      \n",
      "=================================================================\n",
      "Total params: 11,193,477\n",
      "Trainable params: 11,183,877\n",
      "Non-trainable params: 9,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(5)\n",
    "model.build(input_shape = (None,224,224,3))\n",
    "#use categorical_crossentropy since the label is one-hot encoded\n",
    "from keras.optimizers import SGD\n",
    "# opt = SGD(learning_rate=0.1,momentum=0.9,decay = 1e-04) #parameters suggested by He [1]\n",
    "model.compile(optimizer = \"adam\",loss='categorical_crossentropy', metrics=[\"accuracy\"]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-f4f6658dbe46>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/2\n",
      "103/103 [==============================] - ETA: 0s - loss: 2.0622 - accuracy: 0.09 - ETA: 3:31 - loss: 2.7739 - accuracy: 0.18 - ETA: 4:32 - loss: 3.4568 - accuracy: 0.20 - ETA: 5:03 - loss: 3.7741 - accuracy: 0.22 - ETA: 5:21 - loss: 3.4123 - accuracy: 0.28 - ETA: 5:31 - loss: 3.0262 - accuracy: 0.33 - ETA: 5:39 - loss: 2.7471 - accuracy: 0.36 - ETA: 5:44 - loss: 2.5892 - accuracy: 0.37 - ETA: 5:50 - loss: 2.4801 - accuracy: 0.38 - ETA: 5:52 - loss: 2.3721 - accuracy: 0.39 - ETA: 5:51 - loss: 2.2398 - accuracy: 0.41 - ETA: 5:51 - loss: 2.1820 - accuracy: 0.41 - ETA: 5:53 - loss: 2.1013 - accuracy: 0.43 - ETA: 5:49 - loss: 2.0383 - accuracy: 0.43 - ETA: 5:46 - loss: 1.9682 - accuracy: 0.45 - ETA: 5:44 - loss: 1.9389 - accuracy: 0.46 - ETA: 5:41 - loss: 1.8737 - accuracy: 0.47 - ETA: 5:38 - loss: 1.8180 - accuracy: 0.48 - ETA: 5:36 - loss: 1.7703 - accuracy: 0.50 - ETA: 5:32 - loss: 1.7409 - accuracy: 0.50 - ETA: 5:29 - loss: 1.7233 - accuracy: 0.51 - ETA: 5:25 - loss: 1.6923 - accuracy: 0.52 - ETA: 5:21 - loss: 1.6713 - accuracy: 0.52 - ETA: 5:18 - loss: 1.6642 - accuracy: 0.52 - ETA: 5:14 - loss: 1.6424 - accuracy: 0.53 - ETA: 5:10 - loss: 1.6176 - accuracy: 0.53 - ETA: 5:06 - loss: 1.6077 - accuracy: 0.53 - ETA: 5:02 - loss: 1.5965 - accuracy: 0.53 - ETA: 4:58 - loss: 1.5681 - accuracy: 0.54 - ETA: 4:55 - loss: 1.5510 - accuracy: 0.55 - ETA: 4:51 - loss: 1.5366 - accuracy: 0.55 - ETA: 4:47 - loss: 1.5235 - accuracy: 0.55 - ETA: 4:43 - loss: 1.5105 - accuracy: 0.56 - ETA: 4:39 - loss: 1.5201 - accuracy: 0.55 - ETA: 4:35 - loss: 1.5042 - accuracy: 0.55 - ETA: 4:31 - loss: 1.4873 - accuracy: 0.56 - ETA: 4:27 - loss: 1.4792 - accuracy: 0.56 - ETA: 4:23 - loss: 1.4713 - accuracy: 0.56 - ETA: 4:19 - loss: 1.4633 - accuracy: 0.56 - ETA: 4:15 - loss: 1.4482 - accuracy: 0.57 - ETA: 4:11 - loss: 1.4425 - accuracy: 0.57 - ETA: 4:07 - loss: 1.4311 - accuracy: 0.57 - ETA: 4:03 - loss: 1.4207 - accuracy: 0.57 - ETA: 3:59 - loss: 1.4130 - accuracy: 0.57 - ETA: 3:55 - loss: 1.4041 - accuracy: 0.57 - ETA: 3:51 - loss: 1.3963 - accuracy: 0.57 - ETA: 3:47 - loss: 1.3859 - accuracy: 0.57 - ETA: 3:43 - loss: 1.3762 - accuracy: 0.58 - ETA: 3:39 - loss: 1.3743 - accuracy: 0.58 - ETA: 3:35 - loss: 1.3763 - accuracy: 0.58 - ETA: 3:31 - loss: 1.3685 - accuracy: 0.58 - ETA: 3:27 - loss: 1.3558 - accuracy: 0.58 - ETA: 3:23 - loss: 1.3430 - accuracy: 0.58 - ETA: 3:19 - loss: 1.3304 - accuracy: 0.59 - ETA: 3:15 - loss: 1.3226 - accuracy: 0.59 - ETA: 3:10 - loss: 1.3185 - accuracy: 0.59 - ETA: 3:06 - loss: 1.3059 - accuracy: 0.59 - ETA: 3:02 - loss: 1.3051 - accuracy: 0.60 - ETA: 2:58 - loss: 1.3007 - accuracy: 0.60 - ETA: 2:54 - loss: 1.2974 - accuracy: 0.60 - ETA: 2:50 - loss: 1.3006 - accuracy: 0.60 - ETA: 2:46 - loss: 1.2939 - accuracy: 0.60 - ETA: 2:42 - loss: 1.2900 - accuracy: 0.60 - ETA: 2:38 - loss: 1.2818 - accuracy: 0.60 - ETA: 2:34 - loss: 1.2758 - accuracy: 0.60 - ETA: 2:30 - loss: 1.2725 - accuracy: 0.60 - ETA: 2:26 - loss: 1.2695 - accuracy: 0.60 - ETA: 2:22 - loss: 1.2650 - accuracy: 0.60 - ETA: 2:18 - loss: 1.2591 - accuracy: 0.60 - ETA: 2:14 - loss: 1.2548 - accuracy: 0.60 - ETA: 2:10 - loss: 1.2532 - accuracy: 0.61 - ETA: 2:05 - loss: 1.2493 - accuracy: 0.61 - ETA: 2:01 - loss: 1.2423 - accuracy: 0.61 - ETA: 1:57 - loss: 1.2406 - accuracy: 0.61 - ETA: 1:53 - loss: 1.2367 - accuracy: 0.61 - ETA: 1:49 - loss: 1.2340 - accuracy: 0.61 - ETA: 1:45 - loss: 1.2311 - accuracy: 0.61 - ETA: 1:41 - loss: 1.2307 - accuracy: 0.61 - ETA: 1:37 - loss: 1.2269 - accuracy: 0.61 - ETA: 1:33 - loss: 1.2254 - accuracy: 0.61 - ETA: 1:29 - loss: 1.2198 - accuracy: 0.61 - ETA: 1:25 - loss: 1.2176 - accuracy: 0.61 - ETA: 1:21 - loss: 1.2155 - accuracy: 0.61 - ETA: 1:17 - loss: 1.2146 - accuracy: 0.61 - ETA: 1:13 - loss: 1.2097 - accuracy: 0.61 - ETA: 1:09 - loss: 1.2055 - accuracy: 0.61 - ETA: 1:05 - loss: 1.2013 - accuracy: 0.61 - ETA: 1:01 - loss: 1.1951 - accuracy: 0.62 - ETA: 57s - loss: 1.1905 - accuracy: 0.6216 - ETA: 52s - loss: 1.1832 - accuracy: 0.623 - ETA: 48s - loss: 1.1828 - accuracy: 0.623 - ETA: 44s - loss: 1.1776 - accuracy: 0.625 - ETA: 40s - loss: 1.1731 - accuracy: 0.626 - ETA: 36s - loss: 1.1689 - accuracy: 0.627 - ETA: 32s - loss: 1.1653 - accuracy: 0.628 - ETA: 28s - loss: 1.1595 - accuracy: 0.630 - ETA: 24s - loss: 1.1580 - accuracy: 0.629 - ETA: 20s - loss: 1.1580 - accuracy: 0.629 - ETA: 16s - loss: 1.1565 - accuracy: 0.629 - ETA: 12s - loss: 1.1525 - accuracy: 0.630 - ETA: 8s - loss: 1.1529 - accuracy: 0.629 - ETA: 4s - loss: 1.1490 - accuracy: 0.63 - ETA: 0s - loss: 1.1485 - accuracy: 0.62 - 428s 4s/step - loss: 1.1485 - accuracy: 0.6287 - val_loss: 1.8495 - val_accuracy: 0.2772\n",
      "Epoch 2/2\n",
      "103/103 [==============================] - ETA: 0s - loss: 0.9854 - accuracy: 0.59 - ETA: 3:24 - loss: 0.9860 - accuracy: 0.60 - ETA: 4:30 - loss: 0.9335 - accuracy: 0.64 - ETA: 5:00 - loss: 0.9279 - accuracy: 0.65 - ETA: 5:16 - loss: 0.9201 - accuracy: 0.64 - ETA: 5:25 - loss: 0.9171 - accuracy: 0.65 - ETA: 5:31 - loss: 0.9497 - accuracy: 0.63 - ETA: 5:35 - loss: 0.9271 - accuracy: 0.65 - ETA: 5:37 - loss: 0.9078 - accuracy: 0.66 - ETA: 5:43 - loss: 0.8805 - accuracy: 0.68 - ETA: 5:48 - loss: 0.8731 - accuracy: 0.68 - ETA: 5:48 - loss: 0.8866 - accuracy: 0.67 - ETA: 5:48 - loss: 0.8828 - accuracy: 0.68 - ETA: 5:45 - loss: 0.8979 - accuracy: 0.68 - ETA: 5:42 - loss: 0.8955 - accuracy: 0.68 - ETA: 5:38 - loss: 0.8913 - accuracy: 0.68 - ETA: 5:34 - loss: 0.9154 - accuracy: 0.67 - ETA: 5:30 - loss: 0.9014 - accuracy: 0.68 - ETA: 5:27 - loss: 0.9297 - accuracy: 0.67 - ETA: 5:24 - loss: 0.9355 - accuracy: 0.67 - ETA: 5:20 - loss: 0.9334 - accuracy: 0.67 - ETA: 5:17 - loss: 0.9361 - accuracy: 0.67 - ETA: 5:13 - loss: 0.9269 - accuracy: 0.67 - ETA: 5:09 - loss: 0.9249 - accuracy: 0.67 - ETA: 5:06 - loss: 0.9263 - accuracy: 0.67 - ETA: 5:02 - loss: 0.9176 - accuracy: 0.68 - ETA: 4:59 - loss: 0.9148 - accuracy: 0.67 - ETA: 4:55 - loss: 0.9154 - accuracy: 0.68 - ETA: 4:51 - loss: 0.9073 - accuracy: 0.68 - ETA: 4:47 - loss: 0.8971 - accuracy: 0.68 - ETA: 4:43 - loss: 0.8991 - accuracy: 0.68 - ETA: 4:40 - loss: 0.9015 - accuracy: 0.68 - ETA: 4:36 - loss: 0.9028 - accuracy: 0.68 - ETA: 4:32 - loss: 0.9057 - accuracy: 0.68 - ETA: 4:28 - loss: 0.9107 - accuracy: 0.68 - ETA: 4:24 - loss: 0.9100 - accuracy: 0.68 - ETA: 4:20 - loss: 0.9073 - accuracy: 0.68 - ETA: 4:16 - loss: 0.9088 - accuracy: 0.67 - ETA: 4:13 - loss: 0.9054 - accuracy: 0.68 - ETA: 4:09 - loss: 0.8961 - accuracy: 0.68 - ETA: 4:05 - loss: 0.8991 - accuracy: 0.68 - ETA: 4:01 - loss: 0.9031 - accuracy: 0.68 - ETA: 3:57 - loss: 0.9058 - accuracy: 0.68 - ETA: 3:53 - loss: 0.9146 - accuracy: 0.68 - ETA: 3:49 - loss: 0.9085 - accuracy: 0.68 - ETA: 3:45 - loss: 0.9111 - accuracy: 0.68 - ETA: 3:41 - loss: 0.9150 - accuracy: 0.68 - ETA: 3:37 - loss: 0.9132 - accuracy: 0.68 - ETA: 3:34 - loss: 0.9089 - accuracy: 0.68 - ETA: 3:30 - loss: 0.9085 - accuracy: 0.68 - ETA: 3:26 - loss: 0.9070 - accuracy: 0.68 - ETA: 3:22 - loss: 0.9014 - accuracy: 0.68 - ETA: 3:18 - loss: 0.9032 - accuracy: 0.68 - ETA: 3:14 - loss: 0.9052 - accuracy: 0.68 - ETA: 3:10 - loss: 0.9050 - accuracy: 0.68 - ETA: 3:06 - loss: 0.9073 - accuracy: 0.68 - ETA: 3:02 - loss: 0.9061 - accuracy: 0.68 - ETA: 2:58 - loss: 0.9040 - accuracy: 0.68 - ETA: 2:54 - loss: 0.9000 - accuracy: 0.68 - ETA: 2:50 - loss: 0.8967 - accuracy: 0.69 - ETA: 2:46 - loss: 0.8967 - accuracy: 0.69 - ETA: 2:42 - loss: 0.8960 - accuracy: 0.69 - ETA: 2:38 - loss: 0.8935 - accuracy: 0.69 - ETA: 2:34 - loss: 0.8889 - accuracy: 0.69 - ETA: 2:30 - loss: 0.8877 - accuracy: 0.69 - ETA: 2:27 - loss: 0.8885 - accuracy: 0.69 - ETA: 2:23 - loss: 0.8859 - accuracy: 0.69 - ETA: 2:19 - loss: 0.8916 - accuracy: 0.69 - ETA: 2:15 - loss: 0.8922 - accuracy: 0.69 - ETA: 2:11 - loss: 0.8948 - accuracy: 0.69 - ETA: 2:07 - loss: 0.8935 - accuracy: 0.69 - ETA: 2:03 - loss: 0.8923 - accuracy: 0.69 - ETA: 1:59 - loss: 0.8951 - accuracy: 0.68 - ETA: 1:55 - loss: 0.8975 - accuracy: 0.68 - ETA: 1:51 - loss: 0.8991 - accuracy: 0.68 - ETA: 1:47 - loss: 0.9001 - accuracy: 0.68 - ETA: 1:43 - loss: 0.8980 - accuracy: 0.68 - ETA: 1:39 - loss: 0.8986 - accuracy: 0.68 - ETA: 1:35 - loss: 0.8965 - accuracy: 0.68 - ETA: 1:31 - loss: 0.8975 - accuracy: 0.68 - ETA: 1:27 - loss: 0.8976 - accuracy: 0.68 - ETA: 1:23 - loss: 0.8965 - accuracy: 0.68 - ETA: 1:19 - loss: 0.8969 - accuracy: 0.68 - ETA: 1:15 - loss: 0.9015 - accuracy: 0.68 - ETA: 1:11 - loss: 0.9032 - accuracy: 0.68 - ETA: 1:07 - loss: 0.9041 - accuracy: 0.68 - ETA: 1:03 - loss: 0.9026 - accuracy: 0.68 - ETA: 59s - loss: 0.9042 - accuracy: 0.6851 - ETA: 55s - loss: 0.9051 - accuracy: 0.685 - ETA: 51s - loss: 0.9028 - accuracy: 0.685 - ETA: 47s - loss: 0.9058 - accuracy: 0.683 - ETA: 43s - loss: 0.9064 - accuracy: 0.682 - ETA: 39s - loss: 0.9084 - accuracy: 0.682 - ETA: 35s - loss: 0.9081 - accuracy: 0.682 - ETA: 31s - loss: 0.9052 - accuracy: 0.684 - ETA: 27s - loss: 0.9041 - accuracy: 0.686 - ETA: 23s - loss: 0.9051 - accuracy: 0.686 - ETA: 19s - loss: 0.9039 - accuracy: 0.687 - ETA: 15s - loss: 0.9067 - accuracy: 0.687 - ETA: 11s - loss: 0.9066 - accuracy: 0.686 - ETA: 7s - loss: 0.9053 - accuracy: 0.687 - ETA: 3s - loss: 0.9033 - accuracy: 0.68 - ETA: 0s - loss: 0.9038 - accuracy: 0.68 - 418s 4s/step - loss: 0.9038 - accuracy: 0.6885 - val_loss: 2.0091 - val_accuracy: 0.2853\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience= 8, restore_best_weights=True, monitor=\"val_acc\")\n",
    "#I did not use cross validation, so the validate performance is not accurate.\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "hist = model.fit_generator(train_set, validation_data=test_set, epochs=2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=hist\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(224,224,3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_90 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 54, 54, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 12, 12, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 12, 12, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 20485     \n",
      "=================================================================\n",
      "Total params: 46,772,997\n",
      "Trainable params: 46,770,245\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "103/103 [==============================] - ETA: 0s - loss: 3.7181 - accuracy: 0.18 - ETA: 1:24 - loss: 32.3230 - accuracy: 0.328 - ETA: 1:51 - loss: 56.9272 - accuracy: 0.291 - ETA: 2:04 - loss: 49.7390 - accuracy: 0.257 - ETA: 2:13 - loss: 41.7521 - accuracy: 0.312 - ETA: 2:17 - loss: 36.6014 - accuracy: 0.343 - ETA: 2:20 - loss: 32.8324 - accuracy: 0.375 - ETA: 2:22 - loss: 29.6979 - accuracy: 0.371 - ETA: 2:22 - loss: 27.3431 - accuracy: 0.368 - ETA: 2:23 - loss: 24.9209 - accuracy: 0.387 - ETA: 2:24 - loss: 23.0630 - accuracy: 0.392 - ETA: 2:23 - loss: 21.6292 - accuracy: 0.398 - ETA: 2:23 - loss: 20.3428 - accuracy: 0.413 - ETA: 2:22 - loss: 19.1609 - accuracy: 0.415 - ETA: 2:22 - loss: 18.1032 - accuracy: 0.418 - ETA: 2:21 - loss: 17.1843 - accuracy: 0.425 - ETA: 2:20 - loss: 16.3711 - accuracy: 0.433 - ETA: 2:19 - loss: 15.8151 - accuracy: 0.430 - ETA: 2:18 - loss: 15.1542 - accuracy: 0.435 - ETA: 2:17 - loss: 14.6150 - accuracy: 0.437 - ETA: 2:16 - loss: 14.0222 - accuracy: 0.446 - ETA: 2:15 - loss: 13.5196 - accuracy: 0.448 - ETA: 2:14 - loss: 13.0269 - accuracy: 0.459 - ETA: 2:13 - loss: 12.6582 - accuracy: 0.463 - ETA: 2:11 - loss: 12.3389 - accuracy: 0.456 - ETA: 2:10 - loss: 11.9917 - accuracy: 0.456 - ETA: 2:09 - loss: 11.6774 - accuracy: 0.459 - ETA: 2:07 - loss: 11.3441 - accuracy: 0.460 - ETA: 2:06 - loss: 11.1626 - accuracy: 0.456 - ETA: 2:04 - loss: 10.8606 - accuracy: 0.460 - ETA: 2:02 - loss: 10.5723 - accuracy: 0.464 - ETA: 2:00 - loss: 10.3527 - accuracy: 0.466 - ETA: 1:59 - loss: 10.1069 - accuracy: 0.469 - ETA: 1:57 - loss: 9.9842 - accuracy: 0.468 - ETA: 1:55 - loss: 9.7673 - accuracy: 0.46 - ETA: 1:54 - loss: 9.5694 - accuracy: 0.46 - ETA: 1:52 - loss: 9.3771 - accuracy: 0.46 - ETA: 1:50 - loss: 9.1987 - accuracy: 0.46 - ETA: 1:48 - loss: 9.0210 - accuracy: 0.46 - ETA: 1:47 - loss: 8.8345 - accuracy: 0.46 - ETA: 1:45 - loss: 8.6708 - accuracy: 0.46 - ETA: 1:43 - loss: 8.4971 - accuracy: 0.47 - ETA: 1:42 - loss: 8.3446 - accuracy: 0.47 - ETA: 1:40 - loss: 8.1935 - accuracy: 0.47 - ETA: 1:38 - loss: 8.0526 - accuracy: 0.47 - ETA: 1:37 - loss: 7.9109 - accuracy: 0.47 - ETA: 1:35 - loss: 7.7843 - accuracy: 0.47 - ETA: 1:33 - loss: 7.6578 - accuracy: 0.47 - ETA: 1:31 - loss: 7.5269 - accuracy: 0.47 - ETA: 1:30 - loss: 7.3945 - accuracy: 0.48 - ETA: 1:28 - loss: 7.2807 - accuracy: 0.48 - ETA: 1:26 - loss: 7.1770 - accuracy: 0.48 - ETA: 1:25 - loss: 7.0736 - accuracy: 0.48 - ETA: 1:23 - loss: 6.9664 - accuracy: 0.48 - ETA: 1:21 - loss: 6.8653 - accuracy: 0.48 - ETA: 1:19 - loss: 6.7760 - accuracy: 0.48 - ETA: 1:18 - loss: 6.6883 - accuracy: 0.48 - ETA: 1:16 - loss: 6.5929 - accuracy: 0.48 - ETA: 1:14 - loss: 6.5053 - accuracy: 0.48 - ETA: 1:13 - loss: 6.4163 - accuracy: 0.49 - ETA: 1:11 - loss: 6.3298 - accuracy: 0.49 - ETA: 1:09 - loss: 6.2526 - accuracy: 0.49 - ETA: 1:07 - loss: 6.1863 - accuracy: 0.49 - ETA: 1:06 - loss: 6.1150 - accuracy: 0.49 - ETA: 1:04 - loss: 6.0471 - accuracy: 0.49 - ETA: 1:02 - loss: 5.9839 - accuracy: 0.49 - ETA: 1:01 - loss: 5.9112 - accuracy: 0.49 - ETA: 59s - loss: 5.8489 - accuracy: 0.4972 - ETA: 57s - loss: 5.7794 - accuracy: 0.498 - ETA: 56s - loss: 5.7180 - accuracy: 0.499 - ETA: 54s - loss: 5.6472 - accuracy: 0.503 - ETA: 52s - loss: 5.5922 - accuracy: 0.503 - ETA: 50s - loss: 5.5326 - accuracy: 0.506 - ETA: 49s - loss: 5.4780 - accuracy: 0.506 - ETA: 47s - loss: 5.4266 - accuracy: 0.505 - ETA: 45s - loss: 5.3694 - accuracy: 0.507 - ETA: 44s - loss: 5.3160 - accuracy: 0.508 - ETA: 42s - loss: 5.2693 - accuracy: 0.505 - ETA: 40s - loss: 5.2142 - accuracy: 0.507 - ETA: 39s - loss: 5.1598 - accuracy: 0.509 - ETA: 37s - loss: 5.1099 - accuracy: 0.511 - ETA: 35s - loss: 5.0606 - accuracy: 0.512 - ETA: 34s - loss: 5.0116 - accuracy: 0.514 - ETA: 32s - loss: 4.9774 - accuracy: 0.514 - ETA: 30s - loss: 4.9355 - accuracy: 0.516 - ETA: 28s - loss: 4.8939 - accuracy: 0.517 - ETA: 27s - loss: 4.8535 - accuracy: 0.517 - ETA: 25s - loss: 4.8133 - accuracy: 0.518 - ETA: 23s - loss: 4.7710 - accuracy: 0.519 - ETA: 22s - loss: 4.7364 - accuracy: 0.519 - ETA: 20s - loss: 4.6956 - accuracy: 0.519 - ETA: 18s - loss: 4.6585 - accuracy: 0.520 - ETA: 17s - loss: 4.6206 - accuracy: 0.520 - ETA: 15s - loss: 4.5831 - accuracy: 0.522 - ETA: 13s - loss: 4.5439 - accuracy: 0.524 - ETA: 11s - loss: 4.5095 - accuracy: 0.526 - ETA: 10s - loss: 4.4776 - accuracy: 0.526 - ETA: 8s - loss: 4.4532 - accuracy: 0.526 - ETA: 6s - loss: 4.4189 - accuracy: 0.52 - ETA: 5s - loss: 4.3878 - accuracy: 0.52 - ETA: 3s - loss: 4.3577 - accuracy: 0.52 - ETA: 1s - loss: 4.3379 - accuracy: 0.52 - ETA: 0s - loss: 4.3083 - accuracy: 0.52 - 178s 2s/step - loss: 4.3083 - accuracy: 0.5261 - val_loss: 1.7452 - val_accuracy: 0.2772\n",
      "Epoch 2/2\n",
      "103/103 [==============================] - ETA: 0s - loss: 1.8353 - accuracy: 0.43 - ETA: 1:27 - loss: 1.5909 - accuracy: 0.46 - ETA: 1:53 - loss: 1.4872 - accuracy: 0.47 - ETA: 2:05 - loss: 1.4096 - accuracy: 0.52 - ETA: 2:13 - loss: 1.4245 - accuracy: 0.52 - ETA: 2:17 - loss: 1.5029 - accuracy: 0.51 - ETA: 2:19 - loss: 1.5403 - accuracy: 0.50 - ETA: 2:21 - loss: 1.4722 - accuracy: 0.52 - ETA: 2:22 - loss: 1.4592 - accuracy: 0.54 - ETA: 2:22 - loss: 1.4280 - accuracy: 0.55 - ETA: 2:22 - loss: 1.3820 - accuracy: 0.56 - ETA: 2:22 - loss: 1.4053 - accuracy: 0.54 - ETA: 2:21 - loss: 1.4079 - accuracy: 0.53 - ETA: 2:21 - loss: 1.3911 - accuracy: 0.53 - ETA: 2:20 - loss: 1.3530 - accuracy: 0.53 - ETA: 2:19 - loss: 1.3409 - accuracy: 0.54 - ETA: 2:18 - loss: 1.3217 - accuracy: 0.54 - ETA: 2:17 - loss: 1.3087 - accuracy: 0.54 - ETA: 2:16 - loss: 1.3206 - accuracy: 0.54 - ETA: 2:15 - loss: 1.3497 - accuracy: 0.54 - ETA: 2:13 - loss: 1.3341 - accuracy: 0.54 - ETA: 2:11 - loss: 1.3269 - accuracy: 0.54 - ETA: 2:10 - loss: 1.3084 - accuracy: 0.55 - ETA: 2:09 - loss: 1.2947 - accuracy: 0.55 - ETA: 2:08 - loss: 1.2896 - accuracy: 0.55 - ETA: 2:06 - loss: 1.2908 - accuracy: 0.55 - ETA: 2:05 - loss: 1.2866 - accuracy: 0.55 - ETA: 2:03 - loss: 1.2661 - accuracy: 0.56 - ETA: 2:02 - loss: 1.2512 - accuracy: 0.57 - ETA: 2:00 - loss: 1.2436 - accuracy: 0.57 - ETA: 1:59 - loss: 1.2382 - accuracy: 0.57 - ETA: 1:57 - loss: 1.2222 - accuracy: 0.57 - ETA: 1:56 - loss: 1.2213 - accuracy: 0.57 - ETA: 1:54 - loss: 1.2115 - accuracy: 0.57 - ETA: 1:52 - loss: 1.2095 - accuracy: 0.57 - ETA: 1:51 - loss: 1.2229 - accuracy: 0.57 - ETA: 1:49 - loss: 1.2113 - accuracy: 0.57 - ETA: 1:48 - loss: 1.2158 - accuracy: 0.57 - ETA: 1:46 - loss: 1.2079 - accuracy: 0.57 - ETA: 1:45 - loss: 1.2048 - accuracy: 0.57 - ETA: 1:43 - loss: 1.2028 - accuracy: 0.57 - ETA: 1:41 - loss: 1.1913 - accuracy: 0.58 - ETA: 1:40 - loss: 1.1875 - accuracy: 0.57 - ETA: 1:38 - loss: 1.1826 - accuracy: 0.58 - ETA: 1:37 - loss: 1.1850 - accuracy: 0.57 - ETA: 1:35 - loss: 1.1872 - accuracy: 0.57 - ETA: 1:33 - loss: 1.1815 - accuracy: 0.57 - ETA: 1:32 - loss: 1.1758 - accuracy: 0.57 - ETA: 1:30 - loss: 1.1713 - accuracy: 0.57 - ETA: 1:28 - loss: 1.1772 - accuracy: 0.57 - ETA: 1:27 - loss: 1.1892 - accuracy: 0.57 - ETA: 1:25 - loss: 1.1915 - accuracy: 0.57 - ETA: 1:23 - loss: 1.1943 - accuracy: 0.57 - ETA: 1:22 - loss: 1.1886 - accuracy: 0.57 - ETA: 1:20 - loss: 1.1842 - accuracy: 0.57 - ETA: 1:18 - loss: 1.1841 - accuracy: 0.57 - ETA: 1:17 - loss: 1.1828 - accuracy: 0.57 - ETA: 1:15 - loss: 1.1777 - accuracy: 0.57 - ETA: 1:13 - loss: 1.1766 - accuracy: 0.58 - ETA: 1:12 - loss: 1.1779 - accuracy: 0.58 - ETA: 1:10 - loss: 1.1715 - accuracy: 0.58 - ETA: 1:08 - loss: 1.1670 - accuracy: 0.58 - ETA: 1:07 - loss: 1.1658 - accuracy: 0.58 - ETA: 1:05 - loss: 1.1647 - accuracy: 0.58 - ETA: 1:04 - loss: 1.1592 - accuracy: 0.59 - ETA: 1:02 - loss: 1.1585 - accuracy: 0.59 - ETA: 1:00 - loss: 1.1635 - accuracy: 0.59 - ETA: 59s - loss: 1.1594 - accuracy: 0.5920 - ETA: 57s - loss: 1.1654 - accuracy: 0.591 - ETA: 55s - loss: 1.1618 - accuracy: 0.591 - ETA: 53s - loss: 1.1611 - accuracy: 0.590 - ETA: 52s - loss: 1.1618 - accuracy: 0.591 - ETA: 50s - loss: 1.1645 - accuracy: 0.590 - ETA: 48s - loss: 1.1628 - accuracy: 0.591 - ETA: 47s - loss: 1.1654 - accuracy: 0.590 - ETA: 45s - loss: 1.1599 - accuracy: 0.593 - ETA: 43s - loss: 1.1590 - accuracy: 0.593 - ETA: 42s - loss: 1.1571 - accuracy: 0.594 - ETA: 40s - loss: 1.1526 - accuracy: 0.596 - ETA: 38s - loss: 1.1490 - accuracy: 0.597 - ETA: 37s - loss: 1.1469 - accuracy: 0.598 - ETA: 35s - loss: 1.1409 - accuracy: 0.601 - ETA: 33s - loss: 1.1456 - accuracy: 0.598 - ETA: 32s - loss: 1.1437 - accuracy: 0.599 - ETA: 30s - loss: 1.1447 - accuracy: 0.600 - ETA: 28s - loss: 1.1433 - accuracy: 0.601 - ETA: 27s - loss: 1.1411 - accuracy: 0.602 - ETA: 25s - loss: 1.1449 - accuracy: 0.600 - ETA: 23s - loss: 1.1422 - accuracy: 0.601 - ETA: 21s - loss: 1.1415 - accuracy: 0.601 - ETA: 20s - loss: 1.1450 - accuracy: 0.600 - ETA: 18s - loss: 1.1455 - accuracy: 0.602 - ETA: 16s - loss: 1.1491 - accuracy: 0.599 - ETA: 15s - loss: 1.1457 - accuracy: 0.601 - ETA: 13s - loss: 1.1470 - accuracy: 0.600 - ETA: 11s - loss: 1.1461 - accuracy: 0.600 - ETA: 10s - loss: 1.1439 - accuracy: 0.600 - ETA: 8s - loss: 1.1427 - accuracy: 0.600 - ETA: 6s - loss: 1.1395 - accuracy: 0.60 - ETA: 5s - loss: 1.1421 - accuracy: 0.60 - ETA: 3s - loss: 1.1422 - accuracy: 0.60 - ETA: 1s - loss: 1.1402 - accuracy: 0.60 - ETA: 0s - loss: 1.1361 - accuracy: 0.60 - 177s 2s/step - loss: 1.1361 - accuracy: 0.6029 - val_loss: 1.5580 - val_accuracy: 0.3125\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience= 8, restore_best_weights=True, monitor=\"val_acc\")\n",
    "#I did not use cross validation, so the validate performance is not accurate.\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "hist = model.fit_generator(train_set, validation_data=test_set, epochs=2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=hist\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
